{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c782ab3",
   "metadata": {},
   "source": [
    "<h1> Importing libraries </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "993e8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d23636",
   "metadata": {},
   "source": [
    "<h1> Load dataset </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "95a1b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0    1    1   0         0     0    0        1        2      0      1.0      2   \n",
      "1    1    1   0         1     0    1        0        1      1      3.1      0   \n",
      "2    2    1   0         1     0    0        1        1      1      2.6      0   \n",
      "3    1    1   0         1     0    0        1        2      0      0.0      2   \n",
      "4    2    0   0         1     1    1        1        0      0      1.9      1   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   2     3       0  \n",
      "1   0     3       0  \n",
      "2   0     3       0  \n",
      "3   1     3       0  \n",
      "4   3     2       0  \n"
     ]
    }
   ],
   "source": [
    "#Load dataset\n",
    "dataset = pd.read_csv(\"heart_preprocessed.csv\")\n",
    "\n",
    "\n",
    "#Display dataset\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b45de0",
   "metadata": {},
   "source": [
    "<h1>Preprocess Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "cc658529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex   cp  trestbps  chol  fbs  restecg  thalach  exang   oldpeak  \\\n",
      "0  0.5  1.0  0.0       0.0   0.0  0.0      0.5      1.0    0.0  0.161290   \n",
      "1  0.5  1.0  0.0       0.5   0.0  1.0      0.0      0.5    1.0  0.500000   \n",
      "2  1.0  1.0  0.0       0.5   0.0  0.0      0.5      0.5    1.0  0.419355   \n",
      "3  0.5  1.0  0.0       0.5   0.0  0.0      0.5      1.0    0.0  0.000000   \n",
      "4  1.0  0.0  0.0       0.5   0.5  1.0      0.5      0.0    0.0  0.306452   \n",
      "\n",
      "   slope    ca      thal  \n",
      "0    1.0  0.50  1.000000  \n",
      "1    0.0  0.00  1.000000  \n",
      "2    0.0  0.00  1.000000  \n",
      "3    1.0  0.25  1.000000  \n",
      "4    0.5  0.75  0.666667  \n",
      "X_train shape :  (717, 13)\n",
      "X_test shape :  (308, 13)\n",
      "Y_train shape :  (717,)\n",
      "Y_test shape :  (308,)\n"
     ]
    }
   ],
   "source": [
    "#Read target column as y\n",
    "y=dataset.target\n",
    "\n",
    "#Take all of column and drop target column as x\n",
    "x=dataset.drop('target',axis=1)\n",
    "\n",
    "#Normalizing data to value from 0-1\n",
    "min_max_scaler = preprocessing.MinMaxScaler() \n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "#Display normalized data\n",
    "df = pd.DataFrame(x_scaled, columns = ['age','sex','cp', 'trestbps', 'chol', 'fbs','restecg' , 'thalach', 'exang', 'oldpeak' , 'slope' , 'ca' , 'thal'])\n",
    "print(df.head())\n",
    "\n",
    "# Split data into training and test \n",
    "X_train,X_test,y_train,y_test=train_test_split(x_scaled,y,test_size=0.3,random_state=4)\n",
    "\n",
    "print(\"X_train shape : \" , X_train.shape)\n",
    "print(\"X_test shape : \" , X_test.shape)\n",
    "print(\"Y_train shape : \" , y_train.shape)\n",
    "print(\"Y_test shape : \" , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "e3f5a3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2517 - accuracy: 0.5216 - val_loss: 0.2522 - val_accuracy: 0.4935\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.5286 - val_loss: 0.2453 - val_accuracy: 0.5227\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2400 - accuracy: 0.6332 - val_loss: 0.2399 - val_accuracy: 0.6721\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2357 - accuracy: 0.7001 - val_loss: 0.2352 - val_accuracy: 0.7175\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.7266 - val_loss: 0.2309 - val_accuracy: 0.7240\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2271 - accuracy: 0.7336 - val_loss: 0.2265 - val_accuracy: 0.7468\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.7406 - val_loss: 0.2227 - val_accuracy: 0.7435\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.7462 - val_loss: 0.2188 - val_accuracy: 0.7727\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.7517 - val_loss: 0.2148 - val_accuracy: 0.7695\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2114 - accuracy: 0.7657 - val_loss: 0.2106 - val_accuracy: 0.8019\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.7810 - val_loss: 0.2068 - val_accuracy: 0.8052\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.7950 - val_loss: 0.2029 - val_accuracy: 0.7922\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.7922 - val_loss: 0.1992 - val_accuracy: 0.7922\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.7950 - val_loss: 0.1956 - val_accuracy: 0.8149\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.7950 - val_loss: 0.1921 - val_accuracy: 0.8084\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.7964 - val_loss: 0.1887 - val_accuracy: 0.8084\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7908 - val_loss: 0.1850 - val_accuracy: 0.7987\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7936 - val_loss: 0.1819 - val_accuracy: 0.8117\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.7936 - val_loss: 0.1786 - val_accuracy: 0.8084\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.7922 - val_loss: 0.1755 - val_accuracy: 0.8084\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1731 - accuracy: 0.7908 - val_loss: 0.1726 - val_accuracy: 0.8084\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1701 - accuracy: 0.7936 - val_loss: 0.1695 - val_accuracy: 0.7987\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.7922 - val_loss: 0.1669 - val_accuracy: 0.7987\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.7922 - val_loss: 0.1643 - val_accuracy: 0.7987\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.7922 - val_loss: 0.1621 - val_accuracy: 0.7987\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.7922 - val_loss: 0.1596 - val_accuracy: 0.8019\n",
      "Epoch 27/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.7992 - val_loss: 0.1576 - val_accuracy: 0.8019\n",
      "Epoch 28/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1554 - accuracy: 0.7964 - val_loss: 0.1555 - val_accuracy: 0.8019\n",
      "Epoch 29/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.7950 - val_loss: 0.1535 - val_accuracy: 0.8019\n",
      "Epoch 30/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.7950 - val_loss: 0.1518 - val_accuracy: 0.8019\n",
      "Epoch 31/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1496 - accuracy: 0.7950 - val_loss: 0.1501 - val_accuracy: 0.8019\n",
      "Epoch 32/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.7950 - val_loss: 0.1485 - val_accuracy: 0.8019\n",
      "Epoch 33/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.7950 - val_loss: 0.1471 - val_accuracy: 0.8019\n",
      "Epoch 34/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.7936 - val_loss: 0.1455 - val_accuracy: 0.7987\n",
      "Epoch 35/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.7936 - val_loss: 0.1444 - val_accuracy: 0.8019\n",
      "Epoch 36/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.7950 - val_loss: 0.1432 - val_accuracy: 0.8019\n",
      "Epoch 37/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.7992 - val_loss: 0.1419 - val_accuracy: 0.8019\n",
      "Epoch 38/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.8006 - val_loss: 0.1408 - val_accuracy: 0.8019\n",
      "Epoch 39/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.7992 - val_loss: 0.1397 - val_accuracy: 0.8019\n",
      "Epoch 40/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.8047 - val_loss: 0.1389 - val_accuracy: 0.8019\n",
      "Epoch 41/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.8047 - val_loss: 0.1380 - val_accuracy: 0.8019\n",
      "Epoch 42/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.8061 - val_loss: 0.1371 - val_accuracy: 0.8019\n",
      "Epoch 43/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.8103 - val_loss: 0.1363 - val_accuracy: 0.8052\n",
      "Epoch 44/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.8103 - val_loss: 0.1355 - val_accuracy: 0.8117\n",
      "Epoch 45/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1331 - accuracy: 0.8089 - val_loss: 0.1349 - val_accuracy: 0.8052\n",
      "Epoch 46/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.8117 - val_loss: 0.1341 - val_accuracy: 0.8149\n",
      "Epoch 47/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.8103 - val_loss: 0.1336 - val_accuracy: 0.8117\n",
      "Epoch 48/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.8131 - val_loss: 0.1332 - val_accuracy: 0.8052\n",
      "Epoch 49/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.8131 - val_loss: 0.1324 - val_accuracy: 0.8117\n",
      "Epoch 50/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.8145 - val_loss: 0.1319 - val_accuracy: 0.8117\n",
      "Epoch 51/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.8159 - val_loss: 0.1315 - val_accuracy: 0.8117\n",
      "Epoch 52/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.8243 - val_loss: 0.1308 - val_accuracy: 0.8214\n",
      "Epoch 53/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.8285 - val_loss: 0.1304 - val_accuracy: 0.8214\n",
      "Epoch 54/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.8312 - val_loss: 0.1299 - val_accuracy: 0.8214\n",
      "Epoch 55/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.8354 - val_loss: 0.1295 - val_accuracy: 0.8214\n",
      "Epoch 56/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.8312 - val_loss: 0.1292 - val_accuracy: 0.8214\n",
      "Epoch 57/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.8257 - val_loss: 0.1288 - val_accuracy: 0.8247\n",
      "Epoch 58/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.8326 - val_loss: 0.1283 - val_accuracy: 0.8247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.8298 - val_loss: 0.1280 - val_accuracy: 0.8182\n",
      "Epoch 60/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.8326 - val_loss: 0.1277 - val_accuracy: 0.8214\n",
      "Epoch 61/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.8340 - val_loss: 0.1273 - val_accuracy: 0.8214\n",
      "Epoch 62/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.8312 - val_loss: 0.1271 - val_accuracy: 0.8377\n",
      "Epoch 63/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.8368 - val_loss: 0.1266 - val_accuracy: 0.8214\n",
      "Epoch 64/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.8368 - val_loss: 0.1265 - val_accuracy: 0.8377\n",
      "Epoch 65/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.8326 - val_loss: 0.1261 - val_accuracy: 0.8247\n",
      "Epoch 66/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.8382 - val_loss: 0.1258 - val_accuracy: 0.8247\n",
      "Epoch 67/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.8424 - val_loss: 0.1256 - val_accuracy: 0.8247\n",
      "Epoch 68/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.8410 - val_loss: 0.1254 - val_accuracy: 0.8377\n",
      "Epoch 69/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.8382 - val_loss: 0.1251 - val_accuracy: 0.8247\n",
      "Epoch 70/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.8438 - val_loss: 0.1249 - val_accuracy: 0.8247\n",
      "Epoch 71/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.8452 - val_loss: 0.1246 - val_accuracy: 0.8279\n",
      "Epoch 72/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.8438 - val_loss: 0.1244 - val_accuracy: 0.8377\n",
      "Epoch 73/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.8438 - val_loss: 0.1242 - val_accuracy: 0.8377\n",
      "Epoch 74/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.8466 - val_loss: 0.1239 - val_accuracy: 0.8377\n",
      "Epoch 75/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.8480 - val_loss: 0.1237 - val_accuracy: 0.8377\n",
      "Epoch 76/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.8466 - val_loss: 0.1236 - val_accuracy: 0.8377\n",
      "Epoch 77/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.8480 - val_loss: 0.1233 - val_accuracy: 0.8377\n",
      "Epoch 78/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.8494 - val_loss: 0.1231 - val_accuracy: 0.8377\n",
      "Epoch 79/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.8480 - val_loss: 0.1230 - val_accuracy: 0.8377\n",
      "Epoch 80/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.8480 - val_loss: 0.1228 - val_accuracy: 0.8344\n",
      "Epoch 81/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.8494 - val_loss: 0.1227 - val_accuracy: 0.8377\n",
      "Epoch 82/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.8522 - val_loss: 0.1225 - val_accuracy: 0.8377\n",
      "Epoch 83/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.8494 - val_loss: 0.1224 - val_accuracy: 0.8442\n",
      "Epoch 84/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.8508 - val_loss: 0.1222 - val_accuracy: 0.8442\n",
      "Epoch 85/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.8508 - val_loss: 0.1219 - val_accuracy: 0.8409\n",
      "Epoch 86/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.8494 - val_loss: 0.1219 - val_accuracy: 0.8409\n",
      "Epoch 87/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.8452 - val_loss: 0.1216 - val_accuracy: 0.8279\n",
      "Epoch 88/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.8480 - val_loss: 0.1215 - val_accuracy: 0.8344\n",
      "Epoch 89/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.8480 - val_loss: 0.1214 - val_accuracy: 0.8344\n",
      "Epoch 90/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.8522 - val_loss: 0.1214 - val_accuracy: 0.8506\n",
      "Epoch 91/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.8522 - val_loss: 0.1212 - val_accuracy: 0.8474\n",
      "Epoch 92/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.8508 - val_loss: 0.1210 - val_accuracy: 0.8474\n",
      "Epoch 93/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.8508 - val_loss: 0.1209 - val_accuracy: 0.8474\n",
      "Epoch 94/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1166 - accuracy: 0.8494 - val_loss: 0.1207 - val_accuracy: 0.8377\n",
      "Epoch 95/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.8508 - val_loss: 0.1206 - val_accuracy: 0.8377\n",
      "Epoch 96/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.8508 - val_loss: 0.1205 - val_accuracy: 0.8506\n",
      "Epoch 97/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.8466 - val_loss: 0.1204 - val_accuracy: 0.8377\n",
      "Epoch 98/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.8536 - val_loss: 0.1203 - val_accuracy: 0.8506\n",
      "Epoch 99/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.8522 - val_loss: 0.1202 - val_accuracy: 0.8377\n",
      "Epoch 100/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.8508 - val_loss: 0.1201 - val_accuracy: 0.8442\n",
      "Epoch 101/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.8508 - val_loss: 0.1200 - val_accuracy: 0.8442\n",
      "Epoch 102/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.8522 - val_loss: 0.1199 - val_accuracy: 0.8442\n",
      "Epoch 103/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.8522 - val_loss: 0.1199 - val_accuracy: 0.8442\n",
      "Epoch 104/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.8466 - val_loss: 0.1197 - val_accuracy: 0.8377\n",
      "Epoch 105/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.8424 - val_loss: 0.1195 - val_accuracy: 0.8377\n",
      "Epoch 106/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.8480 - val_loss: 0.1195 - val_accuracy: 0.8442\n",
      "Epoch 107/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.8480 - val_loss: 0.1194 - val_accuracy: 0.8442\n",
      "Epoch 108/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.8438 - val_loss: 0.1192 - val_accuracy: 0.8377\n",
      "Epoch 109/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.8466 - val_loss: 0.1192 - val_accuracy: 0.8442\n",
      "Epoch 110/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.8424 - val_loss: 0.1191 - val_accuracy: 0.8377\n",
      "Epoch 111/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.8424 - val_loss: 0.1190 - val_accuracy: 0.8344\n",
      "Epoch 112/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.8494 - val_loss: 0.1190 - val_accuracy: 0.8474\n",
      "Epoch 113/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.8508 - val_loss: 0.1189 - val_accuracy: 0.8474\n",
      "Epoch 114/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.8563 - val_loss: 0.1188 - val_accuracy: 0.8474\n",
      "Epoch 115/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.8382 - val_loss: 0.1186 - val_accuracy: 0.8344\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.8354 - val_loss: 0.1185 - val_accuracy: 0.8344\n",
      "Epoch 117/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.8354 - val_loss: 0.1184 - val_accuracy: 0.8344\n",
      "Epoch 118/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1144 - accuracy: 0.8354 - val_loss: 0.1184 - val_accuracy: 0.8344\n",
      "Epoch 119/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1144 - accuracy: 0.8452 - val_loss: 0.1184 - val_accuracy: 0.8506\n",
      "Epoch 120/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.8396 - val_loss: 0.1182 - val_accuracy: 0.8344\n",
      "Epoch 121/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.8354 - val_loss: 0.1182 - val_accuracy: 0.8377\n",
      "Epoch 122/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.8522 - val_loss: 0.1183 - val_accuracy: 0.8506\n",
      "Epoch 123/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.8550 - val_loss: 0.1182 - val_accuracy: 0.8506\n",
      "Epoch 124/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8382 - val_loss: 0.1180 - val_accuracy: 0.8344\n",
      "Epoch 125/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.8396 - val_loss: 0.1180 - val_accuracy: 0.8377\n",
      "Epoch 126/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.8382 - val_loss: 0.1179 - val_accuracy: 0.8377\n",
      "Epoch 127/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.8410 - val_loss: 0.1178 - val_accuracy: 0.8377\n",
      "Epoch 128/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.8396 - val_loss: 0.1177 - val_accuracy: 0.8377\n",
      "Epoch 129/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.8396 - val_loss: 0.1177 - val_accuracy: 0.8377\n",
      "Epoch 130/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.8396 - val_loss: 0.1176 - val_accuracy: 0.8377\n",
      "Epoch 131/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.8438 - val_loss: 0.1176 - val_accuracy: 0.8409\n",
      "Epoch 132/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.8452 - val_loss: 0.1174 - val_accuracy: 0.8409\n",
      "Epoch 133/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.8494 - val_loss: 0.1174 - val_accuracy: 0.8377\n",
      "Epoch 134/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.8382 - val_loss: 0.1173 - val_accuracy: 0.8377\n",
      "Epoch 135/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.8382 - val_loss: 0.1173 - val_accuracy: 0.8377\n",
      "Epoch 136/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.8382 - val_loss: 0.1172 - val_accuracy: 0.8377\n",
      "Epoch 137/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.8382 - val_loss: 0.1172 - val_accuracy: 0.8409\n",
      "Epoch 138/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.8382 - val_loss: 0.1171 - val_accuracy: 0.8377\n",
      "Epoch 139/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.8396 - val_loss: 0.1171 - val_accuracy: 0.8377\n",
      "Epoch 140/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.8326 - val_loss: 0.1170 - val_accuracy: 0.8377\n",
      "Epoch 141/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.8424 - val_loss: 0.1170 - val_accuracy: 0.8409\n",
      "Epoch 142/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.8410 - val_loss: 0.1169 - val_accuracy: 0.8409\n",
      "Epoch 143/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.8382 - val_loss: 0.1169 - val_accuracy: 0.8377\n",
      "Epoch 144/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.8466 - val_loss: 0.1169 - val_accuracy: 0.8506\n",
      "Epoch 145/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.8396 - val_loss: 0.1168 - val_accuracy: 0.8377\n",
      "Epoch 146/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.8382 - val_loss: 0.1168 - val_accuracy: 0.8377\n",
      "Epoch 147/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.8438 - val_loss: 0.1167 - val_accuracy: 0.8409\n",
      "Epoch 148/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.8396 - val_loss: 0.1167 - val_accuracy: 0.8377\n",
      "Epoch 149/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.8354 - val_loss: 0.1166 - val_accuracy: 0.8377\n",
      "Epoch 150/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.8312 - val_loss: 0.1166 - val_accuracy: 0.8377\n",
      "Epoch 151/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.8396 - val_loss: 0.1166 - val_accuracy: 0.8506\n",
      "Epoch 152/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.8424 - val_loss: 0.1165 - val_accuracy: 0.8442\n",
      "Epoch 153/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.8452 - val_loss: 0.1165 - val_accuracy: 0.8506\n",
      "Epoch 154/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.8438 - val_loss: 0.1164 - val_accuracy: 0.8442\n",
      "Epoch 155/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.8368 - val_loss: 0.1164 - val_accuracy: 0.8442\n",
      "Epoch 156/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.8424 - val_loss: 0.1164 - val_accuracy: 0.8442\n",
      "Epoch 157/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.8354 - val_loss: 0.1163 - val_accuracy: 0.8409\n",
      "Epoch 158/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.8452 - val_loss: 0.1163 - val_accuracy: 0.8506\n",
      "Epoch 159/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.8452 - val_loss: 0.1163 - val_accuracy: 0.8442\n",
      "Epoch 160/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.8438 - val_loss: 0.1162 - val_accuracy: 0.8442\n",
      "Epoch 161/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.8424 - val_loss: 0.1162 - val_accuracy: 0.8442\n",
      "Epoch 162/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.8368 - val_loss: 0.1161 - val_accuracy: 0.8409\n",
      "Epoch 163/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.8438 - val_loss: 0.1161 - val_accuracy: 0.8442\n",
      "Epoch 164/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.8312 - val_loss: 0.1161 - val_accuracy: 0.8344\n",
      "Epoch 165/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.8326 - val_loss: 0.1160 - val_accuracy: 0.8377\n",
      "Epoch 166/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.8438 - val_loss: 0.1161 - val_accuracy: 0.8571\n",
      "Epoch 167/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.8480 - val_loss: 0.1160 - val_accuracy: 0.8442\n",
      "Epoch 168/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.8438 - val_loss: 0.1159 - val_accuracy: 0.8442\n",
      "Epoch 169/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.8298 - val_loss: 0.1159 - val_accuracy: 0.8312\n",
      "Epoch 170/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.8326 - val_loss: 0.1159 - val_accuracy: 0.8377\n",
      "Epoch 171/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.8452 - val_loss: 0.1159 - val_accuracy: 0.8506\n",
      "Epoch 172/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.8438 - val_loss: 0.1158 - val_accuracy: 0.8442\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.8340 - val_loss: 0.1158 - val_accuracy: 0.8344\n",
      "Epoch 174/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.8354 - val_loss: 0.1158 - val_accuracy: 0.8442\n",
      "Epoch 175/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.8438 - val_loss: 0.1157 - val_accuracy: 0.8442\n",
      "Epoch 176/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.8480 - val_loss: 0.1157 - val_accuracy: 0.8571\n",
      "Epoch 177/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.8410 - val_loss: 0.1156 - val_accuracy: 0.8377\n",
      "Epoch 178/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.8326 - val_loss: 0.1156 - val_accuracy: 0.8377\n",
      "Epoch 179/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.8340 - val_loss: 0.1156 - val_accuracy: 0.8344\n",
      "Epoch 180/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.8326 - val_loss: 0.1156 - val_accuracy: 0.8344\n",
      "Epoch 181/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.8424 - val_loss: 0.1155 - val_accuracy: 0.8571\n",
      "Epoch 182/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.8438 - val_loss: 0.1155 - val_accuracy: 0.8344\n",
      "Epoch 183/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.8410 - val_loss: 0.1154 - val_accuracy: 0.8571\n",
      "Epoch 184/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.8354 - val_loss: 0.1154 - val_accuracy: 0.8377\n",
      "Epoch 185/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.8340 - val_loss: 0.1153 - val_accuracy: 0.8442\n",
      "Epoch 186/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.8410 - val_loss: 0.1153 - val_accuracy: 0.8571\n",
      "Epoch 187/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.8452 - val_loss: 0.1153 - val_accuracy: 0.8571\n",
      "Epoch 188/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.8396 - val_loss: 0.1153 - val_accuracy: 0.8377\n",
      "Epoch 189/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.8326 - val_loss: 0.1152 - val_accuracy: 0.8442\n",
      "Epoch 190/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.8452 - val_loss: 0.1153 - val_accuracy: 0.8571\n",
      "Epoch 191/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.8466 - val_loss: 0.1152 - val_accuracy: 0.8442\n",
      "Epoch 192/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.8382 - val_loss: 0.1152 - val_accuracy: 0.8506\n",
      "Epoch 193/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.8410 - val_loss: 0.1151 - val_accuracy: 0.8571\n",
      "Epoch 194/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.8424 - val_loss: 0.1152 - val_accuracy: 0.8571\n",
      "Epoch 195/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.8494 - val_loss: 0.1151 - val_accuracy: 0.8571\n",
      "Epoch 196/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.8410 - val_loss: 0.1151 - val_accuracy: 0.8409\n",
      "Epoch 197/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.8424 - val_loss: 0.1151 - val_accuracy: 0.8571\n",
      "Epoch 198/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.8354 - val_loss: 0.1150 - val_accuracy: 0.8409\n",
      "Epoch 199/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.8396 - val_loss: 0.1149 - val_accuracy: 0.8442\n",
      "Epoch 200/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.8396 - val_loss: 0.1149 - val_accuracy: 0.8506\n",
      "Epoch 201/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.8396 - val_loss: 0.1149 - val_accuracy: 0.8506\n",
      "Epoch 202/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.8382 - val_loss: 0.1149 - val_accuracy: 0.8506\n",
      "Epoch 203/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.8466 - val_loss: 0.1148 - val_accuracy: 0.8506\n",
      "Epoch 204/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.8410 - val_loss: 0.1149 - val_accuracy: 0.8442\n",
      "Epoch 205/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.8382 - val_loss: 0.1149 - val_accuracy: 0.8377\n",
      "Epoch 206/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.8410 - val_loss: 0.1148 - val_accuracy: 0.8506\n",
      "Epoch 207/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.8452 - val_loss: 0.1148 - val_accuracy: 0.8571\n",
      "Epoch 208/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.8480 - val_loss: 0.1148 - val_accuracy: 0.8506\n",
      "Epoch 209/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.8452 - val_loss: 0.1148 - val_accuracy: 0.8571\n",
      "Epoch 210/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.8494 - val_loss: 0.1148 - val_accuracy: 0.8571\n",
      "Epoch 211/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8480 - val_loss: 0.1147 - val_accuracy: 0.8506\n",
      "Epoch 212/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.8382 - val_loss: 0.1147 - val_accuracy: 0.8442\n",
      "Epoch 213/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8424 - val_loss: 0.1147 - val_accuracy: 0.8539\n",
      "Epoch 214/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8410 - val_loss: 0.1147 - val_accuracy: 0.8506\n",
      "Epoch 215/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8410 - val_loss: 0.1146 - val_accuracy: 0.8506\n",
      "Epoch 216/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8424 - val_loss: 0.1146 - val_accuracy: 0.8539\n",
      "Epoch 217/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8438 - val_loss: 0.1146 - val_accuracy: 0.8506\n",
      "Epoch 218/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.8410 - val_loss: 0.1145 - val_accuracy: 0.8506\n",
      "Epoch 219/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.8452 - val_loss: 0.1145 - val_accuracy: 0.8539\n",
      "Epoch 220/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.8424 - val_loss: 0.1144 - val_accuracy: 0.8539\n",
      "Epoch 221/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8452 - val_loss: 0.1144 - val_accuracy: 0.8474\n",
      "Epoch 222/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.8452 - val_loss: 0.1144 - val_accuracy: 0.8539\n",
      "Epoch 223/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.8494 - val_loss: 0.1144 - val_accuracy: 0.8571\n",
      "Epoch 224/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.8438 - val_loss: 0.1144 - val_accuracy: 0.8539\n",
      "Epoch 225/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.8452 - val_loss: 0.1144 - val_accuracy: 0.8539\n",
      "Epoch 226/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.8452 - val_loss: 0.1144 - val_accuracy: 0.8539\n",
      "Epoch 227/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.8410 - val_loss: 0.1144 - val_accuracy: 0.8474\n",
      "Epoch 228/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.8452 - val_loss: 0.1143 - val_accuracy: 0.8539\n",
      "Epoch 229/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.8396 - val_loss: 0.1143 - val_accuracy: 0.8442\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.8424 - val_loss: 0.1144 - val_accuracy: 0.8539\n",
      "Epoch 231/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.8452 - val_loss: 0.1143 - val_accuracy: 0.8474\n",
      "Epoch 232/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.8424 - val_loss: 0.1143 - val_accuracy: 0.8539\n",
      "Epoch 233/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.8452 - val_loss: 0.1142 - val_accuracy: 0.8539\n",
      "Epoch 234/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.8452 - val_loss: 0.1142 - val_accuracy: 0.8539\n",
      "Epoch 235/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.8438 - val_loss: 0.1142 - val_accuracy: 0.8539\n",
      "Epoch 236/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.8396 - val_loss: 0.1142 - val_accuracy: 0.8539\n",
      "Epoch 237/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.8452 - val_loss: 0.1142 - val_accuracy: 0.8539\n",
      "Epoch 238/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.8452 - val_loss: 0.1141 - val_accuracy: 0.8539\n",
      "Epoch 239/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.8410 - val_loss: 0.1141 - val_accuracy: 0.8539\n",
      "Epoch 240/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.8438 - val_loss: 0.1140 - val_accuracy: 0.8539\n",
      "Epoch 241/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.8410 - val_loss: 0.1140 - val_accuracy: 0.8442\n",
      "Epoch 242/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.8452 - val_loss: 0.1140 - val_accuracy: 0.8539\n",
      "Epoch 243/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.8452 - val_loss: 0.1140 - val_accuracy: 0.8539\n",
      "Epoch 244/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.8452 - val_loss: 0.1140 - val_accuracy: 0.8539\n",
      "Epoch 245/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.8466 - val_loss: 0.1140 - val_accuracy: 0.8506\n",
      "Epoch 246/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.8452 - val_loss: 0.1140 - val_accuracy: 0.8539\n",
      "Epoch 247/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.8452 - val_loss: 0.1140 - val_accuracy: 0.8539\n",
      "Epoch 248/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.8410 - val_loss: 0.1140 - val_accuracy: 0.8442\n",
      "Epoch 249/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.8424 - val_loss: 0.1140 - val_accuracy: 0.8539\n",
      "Epoch 250/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.8452 - val_loss: 0.1139 - val_accuracy: 0.8539\n",
      "Epoch 251/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.8480 - val_loss: 0.1139 - val_accuracy: 0.8539\n",
      "Epoch 252/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.8452 - val_loss: 0.1138 - val_accuracy: 0.8539\n",
      "Epoch 253/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.8438 - val_loss: 0.1139 - val_accuracy: 0.8506\n",
      "Epoch 254/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.8396 - val_loss: 0.1139 - val_accuracy: 0.8506\n",
      "Epoch 255/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.8480 - val_loss: 0.1139 - val_accuracy: 0.8604\n",
      "Epoch 256/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.8494 - val_loss: 0.1139 - val_accuracy: 0.8539\n",
      "Epoch 257/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.8452 - val_loss: 0.1138 - val_accuracy: 0.8539\n",
      "Epoch 258/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.8452 - val_loss: 0.1138 - val_accuracy: 0.8539\n",
      "Epoch 259/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.8452 - val_loss: 0.1138 - val_accuracy: 0.8539\n",
      "Epoch 260/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.8452 - val_loss: 0.1138 - val_accuracy: 0.8539\n",
      "Epoch 261/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.8438 - val_loss: 0.1138 - val_accuracy: 0.8539\n",
      "Epoch 262/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.8452 - val_loss: 0.1138 - val_accuracy: 0.8539\n",
      "Epoch 263/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.8452 - val_loss: 0.1138 - val_accuracy: 0.8539\n",
      "Epoch 264/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.8410 - val_loss: 0.1138 - val_accuracy: 0.8506\n",
      "Epoch 265/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.8452 - val_loss: 0.1137 - val_accuracy: 0.8539\n",
      "Epoch 266/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.8438 - val_loss: 0.1137 - val_accuracy: 0.8539\n",
      "Epoch 267/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.8452 - val_loss: 0.1137 - val_accuracy: 0.8539\n",
      "Epoch 268/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.8452 - val_loss: 0.1137 - val_accuracy: 0.8539\n",
      "Epoch 269/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.8438 - val_loss: 0.1137 - val_accuracy: 0.8539\n",
      "Epoch 270/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.8396 - val_loss: 0.1137 - val_accuracy: 0.8442\n",
      "Epoch 271/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.8466 - val_loss: 0.1137 - val_accuracy: 0.8604\n",
      "Epoch 272/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.8424 - val_loss: 0.1137 - val_accuracy: 0.8506\n",
      "Epoch 273/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.8424 - val_loss: 0.1137 - val_accuracy: 0.8442\n",
      "Epoch 274/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.8452 - val_loss: 0.1136 - val_accuracy: 0.8539\n",
      "Epoch 275/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.8452 - val_loss: 0.1136 - val_accuracy: 0.8539\n",
      "Epoch 276/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.8424 - val_loss: 0.1136 - val_accuracy: 0.8442\n",
      "Epoch 277/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.8396 - val_loss: 0.1136 - val_accuracy: 0.8506\n",
      "Epoch 278/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.8424 - val_loss: 0.1135 - val_accuracy: 0.8539\n",
      "Epoch 279/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.8410 - val_loss: 0.1135 - val_accuracy: 0.8539\n",
      "Epoch 280/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.8452 - val_loss: 0.1135 - val_accuracy: 0.8539\n",
      "Epoch 281/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.8452 - val_loss: 0.1135 - val_accuracy: 0.8539\n",
      "Epoch 282/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.8452 - val_loss: 0.1135 - val_accuracy: 0.8539\n",
      "Epoch 283/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.8452 - val_loss: 0.1135 - val_accuracy: 0.8539\n",
      "Epoch 284/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.8424 - val_loss: 0.1135 - val_accuracy: 0.8442\n",
      "Epoch 285/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.8452 - val_loss: 0.1135 - val_accuracy: 0.8539\n",
      "Epoch 286/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.8452 - val_loss: 0.1134 - val_accuracy: 0.8539\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.8452 - val_loss: 0.1134 - val_accuracy: 0.8539\n",
      "Epoch 288/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.8424 - val_loss: 0.1133 - val_accuracy: 0.8539\n",
      "Epoch 289/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.8424 - val_loss: 0.1133 - val_accuracy: 0.8539\n",
      "Epoch 290/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.8452 - val_loss: 0.1134 - val_accuracy: 0.8539\n",
      "Epoch 291/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.8438 - val_loss: 0.1133 - val_accuracy: 0.8539\n",
      "Epoch 292/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.8452 - val_loss: 0.1133 - val_accuracy: 0.8539\n",
      "Epoch 293/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.8396 - val_loss: 0.1133 - val_accuracy: 0.8539\n",
      "Epoch 294/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.8424 - val_loss: 0.1133 - val_accuracy: 0.8604\n",
      "Epoch 295/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.8452 - val_loss: 0.1133 - val_accuracy: 0.8539\n",
      "Epoch 296/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.8452 - val_loss: 0.1133 - val_accuracy: 0.8539\n",
      "Epoch 297/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.8424 - val_loss: 0.1133 - val_accuracy: 0.8506\n",
      "Epoch 298/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.8424 - val_loss: 0.1133 - val_accuracy: 0.8539\n",
      "Epoch 299/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.8438 - val_loss: 0.1133 - val_accuracy: 0.8506\n",
      "Epoch 300/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.8410 - val_loss: 0.1133 - val_accuracy: 0.8506\n",
      "Epoch 301/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.8424 - val_loss: 0.1132 - val_accuracy: 0.8539\n",
      "Epoch 302/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.8424 - val_loss: 0.1133 - val_accuracy: 0.8506\n",
      "Epoch 303/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.8438 - val_loss: 0.1133 - val_accuracy: 0.8539\n",
      "Epoch 304/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.8382 - val_loss: 0.1133 - val_accuracy: 0.8604\n",
      "Epoch 305/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.8410 - val_loss: 0.1133 - val_accuracy: 0.8442\n",
      "Epoch 306/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.8424 - val_loss: 0.1133 - val_accuracy: 0.8506\n",
      "Epoch 307/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.8438 - val_loss: 0.1132 - val_accuracy: 0.8604\n",
      "Epoch 308/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.8438 - val_loss: 0.1132 - val_accuracy: 0.8539\n",
      "Epoch 309/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.8396 - val_loss: 0.1133 - val_accuracy: 0.8442\n",
      "Epoch 310/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.8410 - val_loss: 0.1132 - val_accuracy: 0.8539\n",
      "Epoch 311/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.8452 - val_loss: 0.1132 - val_accuracy: 0.8539\n",
      "Epoch 312/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.8424 - val_loss: 0.1132 - val_accuracy: 0.8506\n",
      "Epoch 313/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.8452 - val_loss: 0.1132 - val_accuracy: 0.8506\n",
      "Epoch 314/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.8396 - val_loss: 0.1132 - val_accuracy: 0.8571\n",
      "Epoch 315/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.8396 - val_loss: 0.1131 - val_accuracy: 0.8539\n",
      "Epoch 316/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.8452 - val_loss: 0.1132 - val_accuracy: 0.8539\n",
      "Epoch 317/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.8396 - val_loss: 0.1131 - val_accuracy: 0.8539\n",
      "Epoch 318/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.8438 - val_loss: 0.1131 - val_accuracy: 0.8539\n",
      "Epoch 319/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.8424 - val_loss: 0.1131 - val_accuracy: 0.8506\n",
      "Epoch 320/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.8368 - val_loss: 0.1131 - val_accuracy: 0.8539\n",
      "Epoch 321/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.8410 - val_loss: 0.1130 - val_accuracy: 0.8506\n",
      "Epoch 322/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.8382 - val_loss: 0.1130 - val_accuracy: 0.8506\n",
      "Epoch 323/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.8424 - val_loss: 0.1130 - val_accuracy: 0.8539\n",
      "Epoch 324/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.8424 - val_loss: 0.1131 - val_accuracy: 0.8506\n",
      "Epoch 325/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.8410 - val_loss: 0.1130 - val_accuracy: 0.8442\n",
      "Epoch 326/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.8396 - val_loss: 0.1130 - val_accuracy: 0.8506\n",
      "Epoch 327/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.8410 - val_loss: 0.1130 - val_accuracy: 0.8474\n",
      "Epoch 328/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.8340 - val_loss: 0.1130 - val_accuracy: 0.8506\n",
      "Epoch 329/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.8424 - val_loss: 0.1130 - val_accuracy: 0.8539\n",
      "Epoch 330/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.8424 - val_loss: 0.1129 - val_accuracy: 0.8506\n",
      "Epoch 331/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.8354 - val_loss: 0.1128 - val_accuracy: 0.8506\n",
      "Epoch 332/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.8424 - val_loss: 0.1129 - val_accuracy: 0.8506\n",
      "Epoch 333/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.8382 - val_loss: 0.1128 - val_accuracy: 0.8506\n",
      "Epoch 334/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.8410 - val_loss: 0.1128 - val_accuracy: 0.8539\n",
      "Epoch 335/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.8368 - val_loss: 0.1129 - val_accuracy: 0.8506\n",
      "Epoch 336/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.8368 - val_loss: 0.1129 - val_accuracy: 0.8506\n",
      "Epoch 337/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.8424 - val_loss: 0.1129 - val_accuracy: 0.8506\n",
      "Epoch 338/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.8410 - val_loss: 0.1128 - val_accuracy: 0.8506\n",
      "Epoch 339/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.8438 - val_loss: 0.1128 - val_accuracy: 0.8539\n",
      "Epoch 340/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.8368 - val_loss: 0.1128 - val_accuracy: 0.8506\n",
      "Epoch 341/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.8396 - val_loss: 0.1128 - val_accuracy: 0.8571\n",
      "Epoch 342/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.8368 - val_loss: 0.1127 - val_accuracy: 0.8506\n",
      "Epoch 343/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.8410 - val_loss: 0.1127 - val_accuracy: 0.8506\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.8438 - val_loss: 0.1127 - val_accuracy: 0.8506\n",
      "Epoch 345/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.8354 - val_loss: 0.1127 - val_accuracy: 0.8506\n",
      "Epoch 346/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.8438 - val_loss: 0.1126 - val_accuracy: 0.8539\n",
      "Epoch 347/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.8368 - val_loss: 0.1126 - val_accuracy: 0.8506\n",
      "Epoch 348/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.8326 - val_loss: 0.1126 - val_accuracy: 0.8539\n",
      "Epoch 349/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.8452 - val_loss: 0.1126 - val_accuracy: 0.8539\n",
      "Epoch 350/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.8368 - val_loss: 0.1125 - val_accuracy: 0.8506\n",
      "Epoch 351/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.8396 - val_loss: 0.1125 - val_accuracy: 0.8506\n",
      "Epoch 352/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.8382 - val_loss: 0.1125 - val_accuracy: 0.8442\n",
      "Epoch 353/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.8382 - val_loss: 0.1125 - val_accuracy: 0.8506\n",
      "Epoch 354/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.8368 - val_loss: 0.1125 - val_accuracy: 0.8506\n",
      "Epoch 355/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.8340 - val_loss: 0.1125 - val_accuracy: 0.8506\n",
      "Epoch 356/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.8382 - val_loss: 0.1125 - val_accuracy: 0.8442\n",
      "Epoch 357/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.8326 - val_loss: 0.1124 - val_accuracy: 0.8442\n",
      "Epoch 358/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.8340 - val_loss: 0.1125 - val_accuracy: 0.8506\n",
      "Epoch 359/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.8326 - val_loss: 0.1124 - val_accuracy: 0.8506\n",
      "Epoch 360/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.8410 - val_loss: 0.1124 - val_accuracy: 0.8506\n",
      "Epoch 361/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.8368 - val_loss: 0.1124 - val_accuracy: 0.8539\n",
      "Epoch 362/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.8452 - val_loss: 0.1124 - val_accuracy: 0.8539\n",
      "Epoch 363/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.8466 - val_loss: 0.1124 - val_accuracy: 0.8539\n",
      "Epoch 364/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.8368 - val_loss: 0.1124 - val_accuracy: 0.8506\n",
      "Epoch 365/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.8340 - val_loss: 0.1124 - val_accuracy: 0.8506\n",
      "Epoch 366/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.8438 - val_loss: 0.1123 - val_accuracy: 0.8604\n",
      "Epoch 367/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.8368 - val_loss: 0.1123 - val_accuracy: 0.8506\n",
      "Epoch 368/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.8354 - val_loss: 0.1123 - val_accuracy: 0.8506\n",
      "Epoch 369/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.8424 - val_loss: 0.1123 - val_accuracy: 0.8604\n",
      "Epoch 370/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.8382 - val_loss: 0.1123 - val_accuracy: 0.8506\n",
      "Epoch 371/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.8410 - val_loss: 0.1122 - val_accuracy: 0.8539\n",
      "Epoch 372/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.8466 - val_loss: 0.1122 - val_accuracy: 0.8539\n",
      "Epoch 373/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.8438 - val_loss: 0.1122 - val_accuracy: 0.8474\n",
      "Epoch 374/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.8396 - val_loss: 0.1122 - val_accuracy: 0.8506\n",
      "Epoch 375/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.8410 - val_loss: 0.1121 - val_accuracy: 0.8571\n",
      "Epoch 376/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.8340 - val_loss: 0.1121 - val_accuracy: 0.8506\n",
      "Epoch 377/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.8396 - val_loss: 0.1121 - val_accuracy: 0.8442\n",
      "Epoch 378/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.8396 - val_loss: 0.1121 - val_accuracy: 0.8506\n",
      "Epoch 379/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.8368 - val_loss: 0.1121 - val_accuracy: 0.8474\n",
      "Epoch 380/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.8424 - val_loss: 0.1120 - val_accuracy: 0.8571\n",
      "Epoch 381/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.8424 - val_loss: 0.1120 - val_accuracy: 0.8571\n",
      "Epoch 382/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.8410 - val_loss: 0.1120 - val_accuracy: 0.8506\n",
      "Epoch 383/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.8368 - val_loss: 0.1119 - val_accuracy: 0.8506\n",
      "Epoch 384/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.8424 - val_loss: 0.1119 - val_accuracy: 0.8506\n",
      "Epoch 385/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.8410 - val_loss: 0.1119 - val_accuracy: 0.8506\n",
      "Epoch 386/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.8396 - val_loss: 0.1119 - val_accuracy: 0.8506\n",
      "Epoch 387/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.8354 - val_loss: 0.1119 - val_accuracy: 0.8506\n",
      "Epoch 388/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.8438 - val_loss: 0.1118 - val_accuracy: 0.8506\n",
      "Epoch 389/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.8466 - val_loss: 0.1118 - val_accuracy: 0.8604\n",
      "Epoch 390/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.8368 - val_loss: 0.1118 - val_accuracy: 0.8539\n",
      "Epoch 391/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.8452 - val_loss: 0.1118 - val_accuracy: 0.8604\n",
      "Epoch 392/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.8438 - val_loss: 0.1118 - val_accuracy: 0.8539\n",
      "Epoch 393/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.8452 - val_loss: 0.1117 - val_accuracy: 0.8539\n",
      "Epoch 394/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.8452 - val_loss: 0.1117 - val_accuracy: 0.8539\n",
      "Epoch 395/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.8466 - val_loss: 0.1117 - val_accuracy: 0.8604\n",
      "Epoch 396/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.8410 - val_loss: 0.1117 - val_accuracy: 0.8506\n",
      "Epoch 397/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.8424 - val_loss: 0.1117 - val_accuracy: 0.8539\n",
      "Epoch 398/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.8452 - val_loss: 0.1117 - val_accuracy: 0.8539\n",
      "Epoch 399/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.8452 - val_loss: 0.1116 - val_accuracy: 0.8604\n",
      "Epoch 400/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.8452 - val_loss: 0.1117 - val_accuracy: 0.8506\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.8452 - val_loss: 0.1117 - val_accuracy: 0.8506\n",
      "Epoch 402/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.8466 - val_loss: 0.1116 - val_accuracy: 0.8539\n",
      "Epoch 403/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.8410 - val_loss: 0.1116 - val_accuracy: 0.8506\n",
      "Epoch 404/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.8438 - val_loss: 0.1116 - val_accuracy: 0.8506\n",
      "Epoch 405/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.8452 - val_loss: 0.1116 - val_accuracy: 0.8539\n",
      "Epoch 406/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.8452 - val_loss: 0.1116 - val_accuracy: 0.8604\n",
      "Epoch 407/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.8466 - val_loss: 0.1116 - val_accuracy: 0.8604\n",
      "Epoch 408/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.8452 - val_loss: 0.1115 - val_accuracy: 0.8539\n",
      "Epoch 409/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.8438 - val_loss: 0.1115 - val_accuracy: 0.8539\n",
      "Epoch 410/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.8480 - val_loss: 0.1115 - val_accuracy: 0.8539\n",
      "Epoch 411/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.8452 - val_loss: 0.1115 - val_accuracy: 0.8539\n",
      "Epoch 412/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.8452 - val_loss: 0.1115 - val_accuracy: 0.8539\n",
      "Epoch 413/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.8480 - val_loss: 0.1115 - val_accuracy: 0.8539\n",
      "Epoch 414/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.8452 - val_loss: 0.1115 - val_accuracy: 0.8539\n",
      "Epoch 415/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.8466 - val_loss: 0.1114 - val_accuracy: 0.8604\n",
      "Epoch 416/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.8466 - val_loss: 0.1114 - val_accuracy: 0.8539\n",
      "Epoch 417/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.8466 - val_loss: 0.1113 - val_accuracy: 0.8539\n",
      "Epoch 418/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.8438 - val_loss: 0.1113 - val_accuracy: 0.8539\n",
      "Epoch 419/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.8480 - val_loss: 0.1113 - val_accuracy: 0.8539\n",
      "Epoch 420/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.8480 - val_loss: 0.1113 - val_accuracy: 0.8539\n",
      "Epoch 421/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.8466 - val_loss: 0.1113 - val_accuracy: 0.8539\n",
      "Epoch 422/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.8480 - val_loss: 0.1113 - val_accuracy: 0.8539\n",
      "Epoch 423/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.8480 - val_loss: 0.1112 - val_accuracy: 0.8539\n",
      "Epoch 424/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.8480 - val_loss: 0.1112 - val_accuracy: 0.8539\n",
      "Epoch 425/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.8480 - val_loss: 0.1112 - val_accuracy: 0.8539\n",
      "Epoch 426/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.8480 - val_loss: 0.1112 - val_accuracy: 0.8539\n",
      "Epoch 427/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.8466 - val_loss: 0.1112 - val_accuracy: 0.8506\n",
      "Epoch 428/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.8494 - val_loss: 0.1111 - val_accuracy: 0.8539\n",
      "Epoch 429/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.8480 - val_loss: 0.1111 - val_accuracy: 0.8539\n",
      "Epoch 430/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.8480 - val_loss: 0.1110 - val_accuracy: 0.8539\n",
      "Epoch 431/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.8480 - val_loss: 0.1110 - val_accuracy: 0.8539\n",
      "Epoch 432/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.8438 - val_loss: 0.1110 - val_accuracy: 0.8539\n",
      "Epoch 433/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.8452 - val_loss: 0.1110 - val_accuracy: 0.8636\n",
      "Epoch 434/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.8522 - val_loss: 0.1110 - val_accuracy: 0.8604\n",
      "Epoch 435/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.8480 - val_loss: 0.1109 - val_accuracy: 0.8539\n",
      "Epoch 436/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.8480 - val_loss: 0.1109 - val_accuracy: 0.8539\n",
      "Epoch 437/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.8480 - val_loss: 0.1108 - val_accuracy: 0.8539\n",
      "Epoch 438/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.8494 - val_loss: 0.1109 - val_accuracy: 0.8474\n",
      "Epoch 439/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.8508 - val_loss: 0.1109 - val_accuracy: 0.8636\n",
      "Epoch 440/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.8438 - val_loss: 0.1108 - val_accuracy: 0.8539\n",
      "Epoch 441/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.8466 - val_loss: 0.1108 - val_accuracy: 0.8539\n",
      "Epoch 442/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.8494 - val_loss: 0.1107 - val_accuracy: 0.8539\n",
      "Epoch 443/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.8480 - val_loss: 0.1107 - val_accuracy: 0.8539\n",
      "Epoch 444/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.8480 - val_loss: 0.1107 - val_accuracy: 0.8539\n",
      "Epoch 445/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.8480 - val_loss: 0.1107 - val_accuracy: 0.8539\n",
      "Epoch 446/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.8508 - val_loss: 0.1106 - val_accuracy: 0.8571\n",
      "Epoch 447/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.8480 - val_loss: 0.1106 - val_accuracy: 0.8539\n",
      "Epoch 448/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.8508 - val_loss: 0.1106 - val_accuracy: 0.8571\n",
      "Epoch 449/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.8480 - val_loss: 0.1106 - val_accuracy: 0.8474\n",
      "Epoch 450/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.8522 - val_loss: 0.1105 - val_accuracy: 0.8701\n",
      "Epoch 451/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.8480 - val_loss: 0.1105 - val_accuracy: 0.8474\n",
      "Epoch 452/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.8466 - val_loss: 0.1105 - val_accuracy: 0.8474\n",
      "Epoch 453/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.8466 - val_loss: 0.1105 - val_accuracy: 0.8539\n",
      "Epoch 454/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.8550 - val_loss: 0.1104 - val_accuracy: 0.8636\n",
      "Epoch 455/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.8536 - val_loss: 0.1104 - val_accuracy: 0.8636\n",
      "Epoch 456/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.8480 - val_loss: 0.1104 - val_accuracy: 0.8474\n",
      "Epoch 457/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.8480 - val_loss: 0.1103 - val_accuracy: 0.8636\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.8508 - val_loss: 0.1103 - val_accuracy: 0.8474\n",
      "Epoch 459/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.8508 - val_loss: 0.1103 - val_accuracy: 0.8636\n",
      "Epoch 460/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.8494 - val_loss: 0.1103 - val_accuracy: 0.8636\n",
      "Epoch 461/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.8522 - val_loss: 0.1102 - val_accuracy: 0.8636\n",
      "Epoch 462/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.8480 - val_loss: 0.1102 - val_accuracy: 0.8604\n",
      "Epoch 463/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.8508 - val_loss: 0.1102 - val_accuracy: 0.8636\n",
      "Epoch 464/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.8550 - val_loss: 0.1102 - val_accuracy: 0.8636\n",
      "Epoch 465/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.8536 - val_loss: 0.1102 - val_accuracy: 0.8636\n",
      "Epoch 466/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.8536 - val_loss: 0.1102 - val_accuracy: 0.8636\n",
      "Epoch 467/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.8522 - val_loss: 0.1101 - val_accuracy: 0.8539\n",
      "Epoch 468/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.8522 - val_loss: 0.1101 - val_accuracy: 0.8636\n",
      "Epoch 469/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.8480 - val_loss: 0.1102 - val_accuracy: 0.8474\n",
      "Epoch 470/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.8508 - val_loss: 0.1101 - val_accuracy: 0.8636\n",
      "Epoch 471/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.8508 - val_loss: 0.1100 - val_accuracy: 0.8571\n",
      "Epoch 472/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.8494 - val_loss: 0.1100 - val_accuracy: 0.8539\n",
      "Epoch 473/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.8508 - val_loss: 0.1100 - val_accuracy: 0.8604\n",
      "Epoch 474/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.8536 - val_loss: 0.1099 - val_accuracy: 0.8636\n",
      "Epoch 475/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.8550 - val_loss: 0.1099 - val_accuracy: 0.8604\n",
      "Epoch 476/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.8550 - val_loss: 0.1098 - val_accuracy: 0.8636\n",
      "Epoch 477/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.8508 - val_loss: 0.1098 - val_accuracy: 0.8571\n",
      "Epoch 478/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.8522 - val_loss: 0.1098 - val_accuracy: 0.8636\n",
      "Epoch 479/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.8522 - val_loss: 0.1098 - val_accuracy: 0.8571\n",
      "Epoch 480/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.8508 - val_loss: 0.1097 - val_accuracy: 0.8636\n",
      "Epoch 481/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.8550 - val_loss: 0.1097 - val_accuracy: 0.8636\n",
      "Epoch 482/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.8508 - val_loss: 0.1097 - val_accuracy: 0.8571\n",
      "Epoch 483/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.8522 - val_loss: 0.1097 - val_accuracy: 0.8571\n",
      "Epoch 484/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.8536 - val_loss: 0.1096 - val_accuracy: 0.8636\n",
      "Epoch 485/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.8508 - val_loss: 0.1097 - val_accuracy: 0.8571\n",
      "Epoch 486/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.8508 - val_loss: 0.1096 - val_accuracy: 0.8636\n",
      "Epoch 487/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.8563 - val_loss: 0.1096 - val_accuracy: 0.8604\n",
      "Epoch 488/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.8536 - val_loss: 0.1095 - val_accuracy: 0.8636\n",
      "Epoch 489/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.8550 - val_loss: 0.1094 - val_accuracy: 0.8636\n",
      "Epoch 490/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.8508 - val_loss: 0.1094 - val_accuracy: 0.8571\n",
      "Epoch 491/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.8536 - val_loss: 0.1094 - val_accuracy: 0.8571\n",
      "Epoch 492/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.8508 - val_loss: 0.1093 - val_accuracy: 0.8571\n",
      "Epoch 493/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.8550 - val_loss: 0.1093 - val_accuracy: 0.8636\n",
      "Epoch 494/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.8522 - val_loss: 0.1093 - val_accuracy: 0.8636\n",
      "Epoch 495/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.8522 - val_loss: 0.1093 - val_accuracy: 0.8571\n",
      "Epoch 496/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.8563 - val_loss: 0.1093 - val_accuracy: 0.8604\n",
      "Epoch 497/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.8522 - val_loss: 0.1092 - val_accuracy: 0.8571\n",
      "Epoch 498/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.8508 - val_loss: 0.1092 - val_accuracy: 0.8571\n",
      "Epoch 499/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.8508 - val_loss: 0.1092 - val_accuracy: 0.8571\n",
      "Epoch 500/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1042 - accuracy: 0.8508 - val_loss: 0.1092 - val_accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "# Input layer consists 13 neuron\n",
    "# Hidden layer consists 10 neuron\n",
    "# Output layer consists 1 neuron\n",
    "# Activation function : sigmoid\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=13, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "trained = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "3a7900a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 10.42%\n",
      "Train accuracy : 85.50%\n",
      "Test loss : 10.92%\n",
      "Test accuracy : 85.71%\n",
      "Model: \"sequential_177\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_395 (Dense)           (None, 10)                140       \n",
      "                                                                 \n",
      " dense_396 (Dense)           (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "\n",
    "print(\"Train loss : {:.2f}%\".format(train_score[0] *100))\n",
    "print(\"Train accuracy : {:.2f}%\".format(train_score[1] *100))\n",
    "\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss : {:.2f}%\".format(test_score[0] *100))\n",
    "print(\"Test accuracy : {:.2f}%\".format(test_score[1] *100))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae38441",
   "metadata": {},
   "source": [
    "<h1>Loss and Accuracy graph (for training and test data) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "ccc088ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trained.history['loss'])\n",
    "plt.plot(trained.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training Loss' , 'Test Loss'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(trained.history['accuracy'] )\n",
    "plt.plot(trained.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training Accuracy' , 'Test Accuracy'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74db561",
   "metadata": {},
   "source": [
    "<h1>Making prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "8b897d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 445us/step\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  1  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  0  [False]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Predicted Value :  0  Actual Value :  0  [True]\n",
      "Predicted Value :  1  Actual Value :  1  [True]\n",
      "Total of correct prediction :  264\n",
      "Total of false prediction :  44\n",
      "Accuracy of prediction : 85.71%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "hold_test = 0\n",
    "true_pred = 0\n",
    "swap_pred = []\n",
    "false_pred = 0\n",
    "\n",
    "\n",
    "for i in range(308):\n",
    "    if y_pred[i] <= 0.5:\n",
    "        swap_pred.append(0)\n",
    "    else : \n",
    "        swap_pred.append(1)\n",
    "        \n",
    "\n",
    "for i in range(308) :\n",
    "    \n",
    "    if swap_pred[i] == y_test[i] :\n",
    "        print(\"Predicted Value : \" , swap_pred[i] , \" Actual Value : \" , y_test[i] , \" [True]\")\n",
    "        true_pred = true_pred + 1\n",
    "    else : \n",
    "        print(\"Predicted Value : \" , swap_pred[i] , \" Actual Value : \" , y_test[i] , \" [False]\")\n",
    "        false_pred = false_pred + 1\n",
    "        \n",
    "print(\"Total of correct prediction : \" , true_pred)\n",
    "print(\"Total of false prediction : \" , false_pred)\n",
    "print(\"Accuracy of prediction : {:.2f}%\".format(true_pred/308 * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb7210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd8a729e9011353bea70d827c4a883ab4de60514c57adf329a667d269e868491"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
