{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.5112 - val_loss: 0.6855 - val_accuracy: 0.5195\n",
      "Epoch 2/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5140 - val_loss: 0.6816 - val_accuracy: 0.5357\n",
      "Epoch 3/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.6020 - val_loss: 0.6775 - val_accuracy: 0.6818\n",
      "Epoch 4/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.6830 - val_loss: 0.6726 - val_accuracy: 0.7143\n",
      "Epoch 5/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.7444 - val_loss: 0.6678 - val_accuracy: 0.8117\n",
      "Epoch 6/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.7668 - val_loss: 0.6615 - val_accuracy: 0.7727\n",
      "Epoch 7/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.7612 - val_loss: 0.6550 - val_accuracy: 0.8279\n",
      "Epoch 8/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.7696 - val_loss: 0.6477 - val_accuracy: 0.8182\n",
      "Epoch 9/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.7877 - val_loss: 0.6397 - val_accuracy: 0.8539\n",
      "Epoch 10/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6391 - accuracy: 0.8142 - val_loss: 0.6304 - val_accuracy: 0.8506\n",
      "Epoch 11/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.8156 - val_loss: 0.6203 - val_accuracy: 0.8669\n",
      "Epoch 12/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.8198 - val_loss: 0.6096 - val_accuracy: 0.8571\n",
      "Epoch 13/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6098 - accuracy: 0.8212 - val_loss: 0.5984 - val_accuracy: 0.8571\n",
      "Epoch 14/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5987 - accuracy: 0.8170 - val_loss: 0.5860 - val_accuracy: 0.8506\n",
      "Epoch 15/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5870 - accuracy: 0.8184 - val_loss: 0.5731 - val_accuracy: 0.8442\n",
      "Epoch 16/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5750 - accuracy: 0.8338 - val_loss: 0.5602 - val_accuracy: 0.8636\n",
      "Epoch 17/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.8366 - val_loss: 0.5464 - val_accuracy: 0.8539\n",
      "Epoch 18/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5494 - accuracy: 0.8394 - val_loss: 0.5337 - val_accuracy: 0.8539\n",
      "Epoch 19/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.8296 - val_loss: 0.5197 - val_accuracy: 0.8506\n",
      "Epoch 20/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.8254 - val_loss: 0.5064 - val_accuracy: 0.8442\n",
      "Epoch 21/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.8198 - val_loss: 0.4931 - val_accuracy: 0.8442\n",
      "Epoch 22/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.8184 - val_loss: 0.4814 - val_accuracy: 0.8474\n",
      "Epoch 23/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.8198 - val_loss: 0.4700 - val_accuracy: 0.8409\n",
      "Epoch 24/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.8170 - val_loss: 0.4592 - val_accuracy: 0.8409\n",
      "Epoch 25/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.8254 - val_loss: 0.4495 - val_accuracy: 0.8442\n",
      "Epoch 26/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.8142 - val_loss: 0.4392 - val_accuracy: 0.8377\n",
      "Epoch 27/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.8170 - val_loss: 0.4311 - val_accuracy: 0.8409\n",
      "Epoch 28/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.8324 - val_loss: 0.4249 - val_accuracy: 0.8474\n",
      "Epoch 29/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.8240 - val_loss: 0.4165 - val_accuracy: 0.8442\n",
      "Epoch 30/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.8324 - val_loss: 0.4116 - val_accuracy: 0.8474\n",
      "Epoch 31/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.8254 - val_loss: 0.4048 - val_accuracy: 0.8474\n",
      "Epoch 32/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.8352 - val_loss: 0.4010 - val_accuracy: 0.8474\n",
      "Epoch 33/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8282 - val_loss: 0.3950 - val_accuracy: 0.8474\n",
      "Epoch 34/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8366 - val_loss: 0.3933 - val_accuracy: 0.8442\n",
      "Epoch 35/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8212 - val_loss: 0.3856 - val_accuracy: 0.8474\n",
      "Epoch 36/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8296 - val_loss: 0.3845 - val_accuracy: 0.8442\n",
      "Epoch 37/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4032 - accuracy: 0.8310 - val_loss: 0.3807 - val_accuracy: 0.8506\n",
      "Epoch 38/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4007 - accuracy: 0.8324 - val_loss: 0.3781 - val_accuracy: 0.8506\n",
      "Epoch 39/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8366 - val_loss: 0.3765 - val_accuracy: 0.8506\n",
      "Epoch 40/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8338 - val_loss: 0.3751 - val_accuracy: 0.8442\n",
      "Epoch 41/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8352 - val_loss: 0.3731 - val_accuracy: 0.8506\n",
      "Epoch 42/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8366 - val_loss: 0.3686 - val_accuracy: 0.8506\n",
      "Epoch 43/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.8394 - val_loss: 0.3691 - val_accuracy: 0.8506\n",
      "Epoch 44/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3883 - accuracy: 0.8450 - val_loss: 0.3680 - val_accuracy: 0.8442\n",
      "Epoch 45/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3869 - accuracy: 0.8422 - val_loss: 0.3661 - val_accuracy: 0.8442\n",
      "Epoch 46/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3854 - accuracy: 0.8352 - val_loss: 0.3646 - val_accuracy: 0.8474\n",
      "Epoch 47/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8366 - val_loss: 0.3616 - val_accuracy: 0.8474\n",
      "Epoch 48/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8366 - val_loss: 0.3618 - val_accuracy: 0.8442\n",
      "Epoch 49/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8380 - val_loss: 0.3614 - val_accuracy: 0.8377\n",
      "Epoch 50/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.8422 - val_loss: 0.3606 - val_accuracy: 0.8377\n",
      "Epoch 51/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3804 - accuracy: 0.8352 - val_loss: 0.3593 - val_accuracy: 0.8377\n",
      "Epoch 52/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3796 - accuracy: 0.8394 - val_loss: 0.3581 - val_accuracy: 0.8377\n",
      "Epoch 53/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3779 - accuracy: 0.8352 - val_loss: 0.3578 - val_accuracy: 0.8377\n",
      "Epoch 54/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8380 - val_loss: 0.3577 - val_accuracy: 0.8312\n",
      "Epoch 55/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8380 - val_loss: 0.3560 - val_accuracy: 0.8442\n",
      "Epoch 56/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8394 - val_loss: 0.3552 - val_accuracy: 0.8442\n",
      "Epoch 57/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8394 - val_loss: 0.3557 - val_accuracy: 0.8377\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3750 - accuracy: 0.8394 - val_loss: 0.3531 - val_accuracy: 0.8442\n",
      "Epoch 59/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.8436 - val_loss: 0.3538 - val_accuracy: 0.8442\n",
      "Epoch 60/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8422 - val_loss: 0.3533 - val_accuracy: 0.8442\n",
      "Epoch 61/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8506 - val_loss: 0.3537 - val_accuracy: 0.8409\n",
      "Epoch 62/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.8478 - val_loss: 0.3549 - val_accuracy: 0.8442\n",
      "Epoch 63/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8534 - val_loss: 0.3508 - val_accuracy: 0.8442\n",
      "Epoch 64/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8436 - val_loss: 0.3510 - val_accuracy: 0.8409\n",
      "Epoch 65/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8520 - val_loss: 0.3516 - val_accuracy: 0.8409\n",
      "Epoch 66/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8506 - val_loss: 0.3519 - val_accuracy: 0.8409\n",
      "Epoch 67/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8506 - val_loss: 0.3507 - val_accuracy: 0.8409\n",
      "Epoch 68/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8506 - val_loss: 0.3497 - val_accuracy: 0.8409\n",
      "Epoch 69/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8478 - val_loss: 0.3496 - val_accuracy: 0.8409\n",
      "Epoch 70/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8492 - val_loss: 0.3496 - val_accuracy: 0.8409\n",
      "Epoch 71/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8506 - val_loss: 0.3532 - val_accuracy: 0.8442\n",
      "Epoch 72/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.8464 - val_loss: 0.3494 - val_accuracy: 0.8409\n",
      "Epoch 73/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8492 - val_loss: 0.3514 - val_accuracy: 0.8409\n",
      "Epoch 74/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8478 - val_loss: 0.3498 - val_accuracy: 0.8409\n",
      "Epoch 75/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8492 - val_loss: 0.3472 - val_accuracy: 0.8474\n",
      "Epoch 76/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3680 - accuracy: 0.8408 - val_loss: 0.3476 - val_accuracy: 0.8474\n",
      "Epoch 77/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3669 - accuracy: 0.8506 - val_loss: 0.3507 - val_accuracy: 0.8442\n",
      "Epoch 78/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8464 - val_loss: 0.3481 - val_accuracy: 0.8474\n",
      "Epoch 79/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8450 - val_loss: 0.3465 - val_accuracy: 0.8442\n",
      "Epoch 80/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8520 - val_loss: 0.3502 - val_accuracy: 0.8474\n",
      "Epoch 81/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8506 - val_loss: 0.3467 - val_accuracy: 0.8442\n",
      "Epoch 82/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8422 - val_loss: 0.3474 - val_accuracy: 0.8442\n",
      "Epoch 83/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8422 - val_loss: 0.3471 - val_accuracy: 0.8409\n",
      "Epoch 84/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8506 - val_loss: 0.3481 - val_accuracy: 0.8442\n",
      "Epoch 85/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8436 - val_loss: 0.3471 - val_accuracy: 0.8409\n",
      "Epoch 86/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.8422 - val_loss: 0.3446 - val_accuracy: 0.8506\n",
      "Epoch 87/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8436 - val_loss: 0.3463 - val_accuracy: 0.8474\n",
      "Epoch 88/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.8478 - val_loss: 0.3465 - val_accuracy: 0.8474\n",
      "Epoch 89/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8450 - val_loss: 0.3464 - val_accuracy: 0.8506\n",
      "Epoch 90/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8436 - val_loss: 0.3429 - val_accuracy: 0.8506\n",
      "Epoch 91/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.8408 - val_loss: 0.3464 - val_accuracy: 0.8506\n",
      "Epoch 92/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8450 - val_loss: 0.3437 - val_accuracy: 0.8539\n",
      "Epoch 93/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8436 - val_loss: 0.3462 - val_accuracy: 0.8474\n",
      "Epoch 94/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8450 - val_loss: 0.3457 - val_accuracy: 0.8474\n",
      "Epoch 95/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8422 - val_loss: 0.3450 - val_accuracy: 0.8474\n",
      "Epoch 96/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8422 - val_loss: 0.3471 - val_accuracy: 0.8442\n",
      "Epoch 97/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8450 - val_loss: 0.3435 - val_accuracy: 0.8474\n",
      "Epoch 98/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8464 - val_loss: 0.3455 - val_accuracy: 0.8474\n",
      "Epoch 99/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8422 - val_loss: 0.3434 - val_accuracy: 0.8474\n",
      "Epoch 100/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8422 - val_loss: 0.3449 - val_accuracy: 0.8474\n",
      "Epoch 101/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8422 - val_loss: 0.3438 - val_accuracy: 0.8474\n",
      "Epoch 102/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8422 - val_loss: 0.3444 - val_accuracy: 0.8474\n",
      "Epoch 103/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8450 - val_loss: 0.3446 - val_accuracy: 0.8474\n",
      "Epoch 104/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3624 - accuracy: 0.8422 - val_loss: 0.3433 - val_accuracy: 0.8474\n",
      "Epoch 105/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8450 - val_loss: 0.3452 - val_accuracy: 0.8506\n",
      "Epoch 106/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8422 - val_loss: 0.3423 - val_accuracy: 0.8539\n",
      "Epoch 107/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8464 - val_loss: 0.3436 - val_accuracy: 0.8474\n",
      "Epoch 108/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3624 - accuracy: 0.8492 - val_loss: 0.3456 - val_accuracy: 0.8506\n",
      "Epoch 109/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8436 - val_loss: 0.3433 - val_accuracy: 0.8474\n",
      "Epoch 110/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8436 - val_loss: 0.3419 - val_accuracy: 0.8539\n",
      "Epoch 111/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8422 - val_loss: 0.3443 - val_accuracy: 0.8474\n",
      "Epoch 112/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3615 - accuracy: 0.8422 - val_loss: 0.3424 - val_accuracy: 0.8539\n",
      "Epoch 113/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8450 - val_loss: 0.3425 - val_accuracy: 0.8474\n",
      "Epoch 114/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8422 - val_loss: 0.3428 - val_accuracy: 0.8474\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8422 - val_loss: 0.3435 - val_accuracy: 0.8474\n",
      "Epoch 116/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8464 - val_loss: 0.3447 - val_accuracy: 0.8506\n",
      "Epoch 117/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8422 - val_loss: 0.3422 - val_accuracy: 0.8474\n",
      "Epoch 118/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8450 - val_loss: 0.3407 - val_accuracy: 0.8604\n",
      "Epoch 119/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8436 - val_loss: 0.3424 - val_accuracy: 0.8474\n",
      "Epoch 120/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8422 - val_loss: 0.3409 - val_accuracy: 0.8604\n",
      "Epoch 121/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8436 - val_loss: 0.3426 - val_accuracy: 0.8474\n",
      "Epoch 122/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8450 - val_loss: 0.3402 - val_accuracy: 0.8604\n",
      "Epoch 123/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8450 - val_loss: 0.3440 - val_accuracy: 0.8506\n",
      "Epoch 124/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8422 - val_loss: 0.3410 - val_accuracy: 0.8604\n",
      "Epoch 125/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8450 - val_loss: 0.3423 - val_accuracy: 0.8474\n",
      "Epoch 126/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8422 - val_loss: 0.3410 - val_accuracy: 0.8604\n",
      "Epoch 127/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8436 - val_loss: 0.3433 - val_accuracy: 0.8506\n",
      "Epoch 128/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8422 - val_loss: 0.3412 - val_accuracy: 0.8604\n",
      "Epoch 129/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8492 - val_loss: 0.3434 - val_accuracy: 0.8506\n",
      "Epoch 130/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8450 - val_loss: 0.3396 - val_accuracy: 0.8604\n",
      "Epoch 131/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8450 - val_loss: 0.3406 - val_accuracy: 0.8604\n",
      "Epoch 132/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8436 - val_loss: 0.3423 - val_accuracy: 0.8506\n",
      "Epoch 133/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8464 - val_loss: 0.3415 - val_accuracy: 0.8539\n",
      "Epoch 134/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8450 - val_loss: 0.3409 - val_accuracy: 0.8604\n",
      "Epoch 135/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8422 - val_loss: 0.3415 - val_accuracy: 0.8571\n",
      "Epoch 136/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8450 - val_loss: 0.3400 - val_accuracy: 0.8604\n",
      "Epoch 137/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8450 - val_loss: 0.3413 - val_accuracy: 0.8506\n",
      "Epoch 138/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8506 - val_loss: 0.3433 - val_accuracy: 0.8539\n",
      "Epoch 139/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8464 - val_loss: 0.3417 - val_accuracy: 0.8506\n",
      "Epoch 140/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8464 - val_loss: 0.3400 - val_accuracy: 0.8604\n",
      "Epoch 141/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8450 - val_loss: 0.3401 - val_accuracy: 0.8604\n",
      "Epoch 142/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8450 - val_loss: 0.3391 - val_accuracy: 0.8604\n",
      "Epoch 143/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8492 - val_loss: 0.3406 - val_accuracy: 0.8604\n",
      "Epoch 144/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8450 - val_loss: 0.3383 - val_accuracy: 0.8604\n",
      "Epoch 145/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8450 - val_loss: 0.3394 - val_accuracy: 0.8604\n",
      "Epoch 146/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8450 - val_loss: 0.3405 - val_accuracy: 0.8636\n",
      "Epoch 147/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8450 - val_loss: 0.3400 - val_accuracy: 0.8636\n",
      "Epoch 148/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8450 - val_loss: 0.3388 - val_accuracy: 0.8604\n",
      "Epoch 149/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8478 - val_loss: 0.3415 - val_accuracy: 0.8571\n",
      "Epoch 150/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8436 - val_loss: 0.3389 - val_accuracy: 0.8604\n",
      "Epoch 151/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3582 - accuracy: 0.8464 - val_loss: 0.3405 - val_accuracy: 0.8604\n",
      "Epoch 152/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8450 - val_loss: 0.3381 - val_accuracy: 0.8604\n",
      "Epoch 153/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8464 - val_loss: 0.3404 - val_accuracy: 0.8636\n",
      "Epoch 154/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8464 - val_loss: 0.3388 - val_accuracy: 0.8604\n",
      "Epoch 155/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8464 - val_loss: 0.3396 - val_accuracy: 0.8604\n",
      "Epoch 156/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8464 - val_loss: 0.3406 - val_accuracy: 0.8636\n",
      "Epoch 157/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.8464 - val_loss: 0.3399 - val_accuracy: 0.8636\n",
      "Epoch 158/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8478 - val_loss: 0.3408 - val_accuracy: 0.8636\n",
      "Epoch 159/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8492 - val_loss: 0.3400 - val_accuracy: 0.8636\n",
      "Epoch 160/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8450 - val_loss: 0.3378 - val_accuracy: 0.8604\n",
      "Epoch 161/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8464 - val_loss: 0.3399 - val_accuracy: 0.8636\n",
      "Epoch 162/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8464 - val_loss: 0.3396 - val_accuracy: 0.8604\n",
      "Epoch 163/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.8464 - val_loss: 0.3380 - val_accuracy: 0.8604\n",
      "Epoch 164/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8450 - val_loss: 0.3401 - val_accuracy: 0.8636\n",
      "Epoch 165/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8478 - val_loss: 0.3392 - val_accuracy: 0.8604\n",
      "Epoch 166/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8450 - val_loss: 0.3395 - val_accuracy: 0.8636\n",
      "Epoch 167/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8478 - val_loss: 0.3402 - val_accuracy: 0.8636\n",
      "Epoch 168/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.8450 - val_loss: 0.3372 - val_accuracy: 0.8604\n",
      "Epoch 169/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3564 - accuracy: 0.8450 - val_loss: 0.3396 - val_accuracy: 0.8636\n",
      "Epoch 170/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8478 - val_loss: 0.3402 - val_accuracy: 0.8604\n",
      "Epoch 171/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8450 - val_loss: 0.3388 - val_accuracy: 0.8604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8436 - val_loss: 0.3405 - val_accuracy: 0.8636\n",
      "Epoch 173/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8534 - val_loss: 0.3399 - val_accuracy: 0.8604\n",
      "Epoch 174/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8450 - val_loss: 0.3378 - val_accuracy: 0.8604\n",
      "Epoch 175/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8520 - val_loss: 0.3400 - val_accuracy: 0.8636\n",
      "Epoch 176/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8520 - val_loss: 0.3398 - val_accuracy: 0.8636\n",
      "Epoch 177/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8492 - val_loss: 0.3369 - val_accuracy: 0.8604\n",
      "Epoch 178/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8450 - val_loss: 0.3371 - val_accuracy: 0.8604\n",
      "Epoch 179/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8450 - val_loss: 0.3376 - val_accuracy: 0.8604\n",
      "Epoch 180/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8520 - val_loss: 0.3402 - val_accuracy: 0.8636\n",
      "Epoch 181/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.8450 - val_loss: 0.3369 - val_accuracy: 0.8604\n",
      "Epoch 182/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8450 - val_loss: 0.3375 - val_accuracy: 0.8604\n",
      "Epoch 183/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8547 - val_loss: 0.3388 - val_accuracy: 0.8636\n",
      "Epoch 184/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8492 - val_loss: 0.3380 - val_accuracy: 0.8636\n",
      "Epoch 185/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8450 - val_loss: 0.3378 - val_accuracy: 0.8636\n",
      "Epoch 186/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8450 - val_loss: 0.3372 - val_accuracy: 0.8604\n",
      "Epoch 187/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8520 - val_loss: 0.3386 - val_accuracy: 0.8604\n",
      "Epoch 188/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8450 - val_loss: 0.3360 - val_accuracy: 0.8604\n",
      "Epoch 189/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8506 - val_loss: 0.3389 - val_accuracy: 0.8636\n",
      "Epoch 190/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8534 - val_loss: 0.3381 - val_accuracy: 0.8604\n",
      "Epoch 191/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8520 - val_loss: 0.3377 - val_accuracy: 0.8636\n",
      "Epoch 192/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3550 - accuracy: 0.8506 - val_loss: 0.3378 - val_accuracy: 0.8636\n",
      "Epoch 193/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3550 - accuracy: 0.8520 - val_loss: 0.3379 - val_accuracy: 0.8604\n",
      "Epoch 194/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8520 - val_loss: 0.3381 - val_accuracy: 0.8636\n",
      "Epoch 195/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8534 - val_loss: 0.3378 - val_accuracy: 0.8604\n",
      "Epoch 196/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8506 - val_loss: 0.3376 - val_accuracy: 0.8604\n",
      "Epoch 197/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8506 - val_loss: 0.3368 - val_accuracy: 0.8636\n",
      "Epoch 198/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8547 - val_loss: 0.3376 - val_accuracy: 0.8636\n",
      "Epoch 199/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8506 - val_loss: 0.3359 - val_accuracy: 0.8636\n",
      "Epoch 200/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8547 - val_loss: 0.3381 - val_accuracy: 0.8636\n",
      "Epoch 201/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8520 - val_loss: 0.3369 - val_accuracy: 0.8604\n",
      "Epoch 202/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8492 - val_loss: 0.3363 - val_accuracy: 0.8636\n",
      "Epoch 203/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8520 - val_loss: 0.3390 - val_accuracy: 0.8669\n",
      "Epoch 204/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8561 - val_loss: 0.3371 - val_accuracy: 0.8604\n",
      "Epoch 205/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8534 - val_loss: 0.3365 - val_accuracy: 0.8604\n",
      "Epoch 206/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8464 - val_loss: 0.3359 - val_accuracy: 0.8636\n",
      "Epoch 207/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8450 - val_loss: 0.3355 - val_accuracy: 0.8636\n",
      "Epoch 208/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8547 - val_loss: 0.3377 - val_accuracy: 0.8636\n",
      "Epoch 209/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3542 - accuracy: 0.8547 - val_loss: 0.3380 - val_accuracy: 0.8636\n",
      "Epoch 210/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8506 - val_loss: 0.3342 - val_accuracy: 0.8604\n",
      "Epoch 211/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8520 - val_loss: 0.3378 - val_accuracy: 0.8636\n",
      "Epoch 212/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8520 - val_loss: 0.3358 - val_accuracy: 0.8604\n",
      "Epoch 213/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8506 - val_loss: 0.3370 - val_accuracy: 0.8636\n",
      "Epoch 214/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8506 - val_loss: 0.3368 - val_accuracy: 0.8636\n",
      "Epoch 215/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8575 - val_loss: 0.3389 - val_accuracy: 0.8669\n",
      "Epoch 216/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8492 - val_loss: 0.3343 - val_accuracy: 0.8636\n",
      "Epoch 217/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3535 - accuracy: 0.8492 - val_loss: 0.3374 - val_accuracy: 0.8636\n",
      "Epoch 218/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.8506 - val_loss: 0.3370 - val_accuracy: 0.8636\n",
      "Epoch 219/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.8478 - val_loss: 0.3351 - val_accuracy: 0.8636\n",
      "Epoch 220/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3538 - accuracy: 0.8575 - val_loss: 0.3372 - val_accuracy: 0.8636\n",
      "Epoch 221/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8520 - val_loss: 0.3350 - val_accuracy: 0.8636\n",
      "Epoch 222/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8561 - val_loss: 0.3386 - val_accuracy: 0.8669\n",
      "Epoch 223/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3538 - accuracy: 0.8561 - val_loss: 0.3349 - val_accuracy: 0.8636\n",
      "Epoch 224/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8506 - val_loss: 0.3343 - val_accuracy: 0.8636\n",
      "Epoch 225/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.8547 - val_loss: 0.3366 - val_accuracy: 0.8604\n",
      "Epoch 226/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.8506 - val_loss: 0.3352 - val_accuracy: 0.8604\n",
      "Epoch 227/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8506 - val_loss: 0.3341 - val_accuracy: 0.8636\n",
      "Epoch 228/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8534 - val_loss: 0.3374 - val_accuracy: 0.8669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.8547 - val_loss: 0.3357 - val_accuracy: 0.8604\n",
      "Epoch 230/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.8492 - val_loss: 0.3337 - val_accuracy: 0.8636\n",
      "Epoch 231/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8534 - val_loss: 0.3363 - val_accuracy: 0.8636\n",
      "Epoch 232/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8534 - val_loss: 0.3352 - val_accuracy: 0.8604\n",
      "Epoch 233/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8506 - val_loss: 0.3339 - val_accuracy: 0.8636\n",
      "Epoch 234/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8520 - val_loss: 0.3338 - val_accuracy: 0.8636\n",
      "Epoch 235/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8492 - val_loss: 0.3340 - val_accuracy: 0.8636\n",
      "Epoch 236/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8520 - val_loss: 0.3348 - val_accuracy: 0.8604\n",
      "Epoch 237/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8575 - val_loss: 0.3376 - val_accuracy: 0.8604\n",
      "Epoch 238/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.8547 - val_loss: 0.3358 - val_accuracy: 0.8636\n",
      "Epoch 239/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3525 - accuracy: 0.8492 - val_loss: 0.3340 - val_accuracy: 0.8636\n",
      "Epoch 240/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8534 - val_loss: 0.3353 - val_accuracy: 0.8604\n",
      "Epoch 241/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.8520 - val_loss: 0.3365 - val_accuracy: 0.8636\n",
      "Epoch 242/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.8547 - val_loss: 0.3335 - val_accuracy: 0.8636\n",
      "Epoch 243/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8534 - val_loss: 0.3358 - val_accuracy: 0.8636\n",
      "Epoch 244/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.8506 - val_loss: 0.3340 - val_accuracy: 0.8604\n",
      "Epoch 245/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3525 - accuracy: 0.8547 - val_loss: 0.3337 - val_accuracy: 0.8604\n",
      "Epoch 246/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.8506 - val_loss: 0.3343 - val_accuracy: 0.8604\n",
      "Epoch 247/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.8492 - val_loss: 0.3325 - val_accuracy: 0.8636\n",
      "Epoch 248/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3521 - accuracy: 0.8520 - val_loss: 0.3336 - val_accuracy: 0.8604\n",
      "Epoch 249/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8534 - val_loss: 0.3346 - val_accuracy: 0.8604\n",
      "Epoch 250/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8506 - val_loss: 0.3334 - val_accuracy: 0.8604\n",
      "Epoch 251/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.8506 - val_loss: 0.3338 - val_accuracy: 0.8604\n",
      "Epoch 252/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8547 - val_loss: 0.3351 - val_accuracy: 0.8636\n",
      "Epoch 253/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8520 - val_loss: 0.3335 - val_accuracy: 0.8604\n",
      "Epoch 254/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8534 - val_loss: 0.3337 - val_accuracy: 0.8604\n",
      "Epoch 255/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8492 - val_loss: 0.3320 - val_accuracy: 0.8636\n",
      "Epoch 256/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.8506 - val_loss: 0.3345 - val_accuracy: 0.8636\n",
      "Epoch 257/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8520 - val_loss: 0.3325 - val_accuracy: 0.8604\n",
      "Epoch 258/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8547 - val_loss: 0.3342 - val_accuracy: 0.8604\n",
      "Epoch 259/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8520 - val_loss: 0.3332 - val_accuracy: 0.8604\n",
      "Epoch 260/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8506 - val_loss: 0.3335 - val_accuracy: 0.8604\n",
      "Epoch 261/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8506 - val_loss: 0.3329 - val_accuracy: 0.8604\n",
      "Epoch 262/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8506 - val_loss: 0.3340 - val_accuracy: 0.8604\n",
      "Epoch 263/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8589 - val_loss: 0.3348 - val_accuracy: 0.8604\n",
      "Epoch 264/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8575 - val_loss: 0.3308 - val_accuracy: 0.8636\n",
      "Epoch 265/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8534 - val_loss: 0.3318 - val_accuracy: 0.8604\n",
      "Epoch 266/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8561 - val_loss: 0.3344 - val_accuracy: 0.8604\n",
      "Epoch 267/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8506 - val_loss: 0.3320 - val_accuracy: 0.8604\n",
      "Epoch 268/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8506 - val_loss: 0.3318 - val_accuracy: 0.8604\n",
      "Epoch 269/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8575 - val_loss: 0.3312 - val_accuracy: 0.8604\n",
      "Epoch 270/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8506 - val_loss: 0.3331 - val_accuracy: 0.8604\n",
      "Epoch 271/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8506 - val_loss: 0.3324 - val_accuracy: 0.8604\n",
      "Epoch 272/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8506 - val_loss: 0.3332 - val_accuracy: 0.8604\n",
      "Epoch 273/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8534 - val_loss: 0.3309 - val_accuracy: 0.8604\n",
      "Epoch 274/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8506 - val_loss: 0.3328 - val_accuracy: 0.8604\n",
      "Epoch 275/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8575 - val_loss: 0.3342 - val_accuracy: 0.8604\n",
      "Epoch 276/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8506 - val_loss: 0.3318 - val_accuracy: 0.8604\n",
      "Epoch 277/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8506 - val_loss: 0.3321 - val_accuracy: 0.8604\n",
      "Epoch 278/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8506 - val_loss: 0.3338 - val_accuracy: 0.8604\n",
      "Epoch 279/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8506 - val_loss: 0.3318 - val_accuracy: 0.8604\n",
      "Epoch 280/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8506 - val_loss: 0.3312 - val_accuracy: 0.8604\n",
      "Epoch 281/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8506 - val_loss: 0.3320 - val_accuracy: 0.8604\n",
      "Epoch 282/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8534 - val_loss: 0.3309 - val_accuracy: 0.8604\n",
      "Epoch 283/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8506 - val_loss: 0.3326 - val_accuracy: 0.8604\n",
      "Epoch 284/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8520 - val_loss: 0.3302 - val_accuracy: 0.8604\n",
      "Epoch 285/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8506 - val_loss: 0.3330 - val_accuracy: 0.8604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8506 - val_loss: 0.3328 - val_accuracy: 0.8604\n",
      "Epoch 287/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8534 - val_loss: 0.3293 - val_accuracy: 0.8669\n",
      "Epoch 288/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3492 - accuracy: 0.8492 - val_loss: 0.3336 - val_accuracy: 0.8604\n",
      "Epoch 289/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3484 - accuracy: 0.8506 - val_loss: 0.3311 - val_accuracy: 0.8604\n",
      "Epoch 290/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8534 - val_loss: 0.3302 - val_accuracy: 0.8604\n",
      "Epoch 291/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8520 - val_loss: 0.3307 - val_accuracy: 0.8604\n",
      "Epoch 292/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8506 - val_loss: 0.3306 - val_accuracy: 0.8604\n",
      "Epoch 293/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8547 - val_loss: 0.3300 - val_accuracy: 0.8604\n",
      "Epoch 294/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8547 - val_loss: 0.3295 - val_accuracy: 0.8604\n",
      "Epoch 295/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8547 - val_loss: 0.3304 - val_accuracy: 0.8604\n",
      "Epoch 296/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8561 - val_loss: 0.3320 - val_accuracy: 0.8604\n",
      "Epoch 297/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8464 - val_loss: 0.3285 - val_accuracy: 0.8669\n",
      "Epoch 298/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8534 - val_loss: 0.3318 - val_accuracy: 0.8604\n",
      "Epoch 299/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8520 - val_loss: 0.3293 - val_accuracy: 0.8604\n",
      "Epoch 300/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8492 - val_loss: 0.3295 - val_accuracy: 0.8604\n",
      "Epoch 301/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8506 - val_loss: 0.3307 - val_accuracy: 0.8604\n",
      "Epoch 302/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8506 - val_loss: 0.3301 - val_accuracy: 0.8604\n",
      "Epoch 303/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8534 - val_loss: 0.3295 - val_accuracy: 0.8604\n",
      "Epoch 304/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3478 - accuracy: 0.8520 - val_loss: 0.3304 - val_accuracy: 0.8604\n",
      "Epoch 305/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8506 - val_loss: 0.3298 - val_accuracy: 0.8604\n",
      "Epoch 306/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8534 - val_loss: 0.3286 - val_accuracy: 0.8571\n",
      "Epoch 307/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.8520 - val_loss: 0.3293 - val_accuracy: 0.8604\n",
      "Epoch 308/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8575 - val_loss: 0.3342 - val_accuracy: 0.8604\n",
      "Epoch 309/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8478 - val_loss: 0.3278 - val_accuracy: 0.8669\n",
      "Epoch 310/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8547 - val_loss: 0.3291 - val_accuracy: 0.8604\n",
      "Epoch 311/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3470 - accuracy: 0.8506 - val_loss: 0.3297 - val_accuracy: 0.8604\n",
      "Epoch 312/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8492 - val_loss: 0.3295 - val_accuracy: 0.8604\n",
      "Epoch 313/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8506 - val_loss: 0.3293 - val_accuracy: 0.8604\n",
      "Epoch 314/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3484 - accuracy: 0.8436 - val_loss: 0.3282 - val_accuracy: 0.8571\n",
      "Epoch 315/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3467 - accuracy: 0.8547 - val_loss: 0.3288 - val_accuracy: 0.8604\n",
      "Epoch 316/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8575 - val_loss: 0.3296 - val_accuracy: 0.8604\n",
      "Epoch 317/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8506 - val_loss: 0.3285 - val_accuracy: 0.8571\n",
      "Epoch 318/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3464 - accuracy: 0.8547 - val_loss: 0.3285 - val_accuracy: 0.8604\n",
      "Epoch 319/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8520 - val_loss: 0.3294 - val_accuracy: 0.8604\n",
      "Epoch 320/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3464 - accuracy: 0.8561 - val_loss: 0.3269 - val_accuracy: 0.8669\n",
      "Epoch 321/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8520 - val_loss: 0.3284 - val_accuracy: 0.8571\n",
      "Epoch 322/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8547 - val_loss: 0.3264 - val_accuracy: 0.8701\n",
      "Epoch 323/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3464 - accuracy: 0.8492 - val_loss: 0.3286 - val_accuracy: 0.8604\n",
      "Epoch 324/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8534 - val_loss: 0.3286 - val_accuracy: 0.8604\n",
      "Epoch 325/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8534 - val_loss: 0.3295 - val_accuracy: 0.8604\n",
      "Epoch 326/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8492 - val_loss: 0.3292 - val_accuracy: 0.8636\n",
      "Epoch 327/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8561 - val_loss: 0.3265 - val_accuracy: 0.8669\n",
      "Epoch 328/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8589 - val_loss: 0.3276 - val_accuracy: 0.8571\n",
      "Epoch 329/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8561 - val_loss: 0.3273 - val_accuracy: 0.8669\n",
      "Epoch 330/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8492 - val_loss: 0.3303 - val_accuracy: 0.8539\n",
      "Epoch 331/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3464 - accuracy: 0.8506 - val_loss: 0.3265 - val_accuracy: 0.8669\n",
      "Epoch 332/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8589 - val_loss: 0.3267 - val_accuracy: 0.8669\n",
      "Epoch 333/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8492 - val_loss: 0.3284 - val_accuracy: 0.8636\n",
      "Epoch 334/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8534 - val_loss: 0.3263 - val_accuracy: 0.8669\n",
      "Epoch 335/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8589 - val_loss: 0.3269 - val_accuracy: 0.8669\n",
      "Epoch 336/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8547 - val_loss: 0.3272 - val_accuracy: 0.8669\n",
      "Epoch 337/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3449 - accuracy: 0.8589 - val_loss: 0.3268 - val_accuracy: 0.8669\n",
      "Epoch 338/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8589 - val_loss: 0.3262 - val_accuracy: 0.8669\n",
      "Epoch 339/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8589 - val_loss: 0.3263 - val_accuracy: 0.8669\n",
      "Epoch 340/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8561 - val_loss: 0.3274 - val_accuracy: 0.8701\n",
      "Epoch 341/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8506 - val_loss: 0.3252 - val_accuracy: 0.8669\n",
      "Epoch 342/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3443 - accuracy: 0.8575 - val_loss: 0.3271 - val_accuracy: 0.8701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8547 - val_loss: 0.3276 - val_accuracy: 0.8604\n",
      "Epoch 344/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8492 - val_loss: 0.3264 - val_accuracy: 0.8701\n",
      "Epoch 345/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8520 - val_loss: 0.3264 - val_accuracy: 0.8701\n",
      "Epoch 346/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8506 - val_loss: 0.3277 - val_accuracy: 0.8636\n",
      "Epoch 347/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8534 - val_loss: 0.3273 - val_accuracy: 0.8604\n",
      "Epoch 348/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8492 - val_loss: 0.3238 - val_accuracy: 0.8701\n",
      "Epoch 349/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8506 - val_loss: 0.3255 - val_accuracy: 0.8669\n",
      "Epoch 350/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8492 - val_loss: 0.3246 - val_accuracy: 0.8669\n",
      "Epoch 351/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8589 - val_loss: 0.3263 - val_accuracy: 0.8701\n",
      "Epoch 352/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8547 - val_loss: 0.3257 - val_accuracy: 0.8701\n",
      "Epoch 353/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8547 - val_loss: 0.3260 - val_accuracy: 0.8701\n",
      "Epoch 354/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8478 - val_loss: 0.3232 - val_accuracy: 0.8636\n",
      "Epoch 355/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8561 - val_loss: 0.3252 - val_accuracy: 0.8701\n",
      "Epoch 356/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8492 - val_loss: 0.3251 - val_accuracy: 0.8701\n",
      "Epoch 357/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8589 - val_loss: 0.3247 - val_accuracy: 0.8669\n",
      "Epoch 358/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.8561 - val_loss: 0.3260 - val_accuracy: 0.8701\n",
      "Epoch 359/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8575 - val_loss: 0.3236 - val_accuracy: 0.8636\n",
      "Epoch 360/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8520 - val_loss: 0.3239 - val_accuracy: 0.8669\n",
      "Epoch 361/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8506 - val_loss: 0.3237 - val_accuracy: 0.8669\n",
      "Epoch 362/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8547 - val_loss: 0.3243 - val_accuracy: 0.8669\n",
      "Epoch 363/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8575 - val_loss: 0.3250 - val_accuracy: 0.8701\n",
      "Epoch 364/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8520 - val_loss: 0.3243 - val_accuracy: 0.8701\n",
      "Epoch 365/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8561 - val_loss: 0.3249 - val_accuracy: 0.8701\n",
      "Epoch 366/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8561 - val_loss: 0.3241 - val_accuracy: 0.8701\n",
      "Epoch 367/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8547 - val_loss: 0.3221 - val_accuracy: 0.8701\n",
      "Epoch 368/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8506 - val_loss: 0.3228 - val_accuracy: 0.8669\n",
      "Epoch 369/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8534 - val_loss: 0.3228 - val_accuracy: 0.8669\n",
      "Epoch 370/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8561 - val_loss: 0.3237 - val_accuracy: 0.8701\n",
      "Epoch 371/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8575 - val_loss: 0.3227 - val_accuracy: 0.8701\n",
      "Epoch 372/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8520 - val_loss: 0.3220 - val_accuracy: 0.8669\n",
      "Epoch 373/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8547 - val_loss: 0.3225 - val_accuracy: 0.8701\n",
      "Epoch 374/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8492 - val_loss: 0.3219 - val_accuracy: 0.8636\n",
      "Epoch 375/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8478 - val_loss: 0.3216 - val_accuracy: 0.8636\n",
      "Epoch 376/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8561 - val_loss: 0.3245 - val_accuracy: 0.8701\n",
      "Epoch 377/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3412 - accuracy: 0.8534 - val_loss: 0.3221 - val_accuracy: 0.8701\n",
      "Epoch 378/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3408 - accuracy: 0.8534 - val_loss: 0.3216 - val_accuracy: 0.8701\n",
      "Epoch 379/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3408 - accuracy: 0.8464 - val_loss: 0.3214 - val_accuracy: 0.8701\n",
      "Epoch 380/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8534 - val_loss: 0.3229 - val_accuracy: 0.8701\n",
      "Epoch 381/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8547 - val_loss: 0.3224 - val_accuracy: 0.8701\n",
      "Epoch 382/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8478 - val_loss: 0.3203 - val_accuracy: 0.8701\n",
      "Epoch 383/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8492 - val_loss: 0.3231 - val_accuracy: 0.8701\n",
      "Epoch 384/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8492 - val_loss: 0.3220 - val_accuracy: 0.8701\n",
      "Epoch 385/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.8547 - val_loss: 0.3211 - val_accuracy: 0.8701\n",
      "Epoch 386/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8506 - val_loss: 0.3200 - val_accuracy: 0.8636\n",
      "Epoch 387/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8464 - val_loss: 0.3211 - val_accuracy: 0.8701\n",
      "Epoch 388/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8478 - val_loss: 0.3211 - val_accuracy: 0.8701\n",
      "Epoch 389/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8547 - val_loss: 0.3210 - val_accuracy: 0.8701\n",
      "Epoch 390/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8534 - val_loss: 0.3210 - val_accuracy: 0.8701\n",
      "Epoch 391/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8561 - val_loss: 0.3219 - val_accuracy: 0.8701\n",
      "Epoch 392/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8464 - val_loss: 0.3200 - val_accuracy: 0.8636\n",
      "Epoch 393/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8478 - val_loss: 0.3205 - val_accuracy: 0.8701\n",
      "Epoch 394/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8478 - val_loss: 0.3198 - val_accuracy: 0.8636\n",
      "Epoch 395/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8534 - val_loss: 0.3215 - val_accuracy: 0.8701\n",
      "Epoch 396/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8520 - val_loss: 0.3212 - val_accuracy: 0.8701\n",
      "Epoch 397/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8478 - val_loss: 0.3198 - val_accuracy: 0.8701\n",
      "Epoch 398/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8450 - val_loss: 0.3202 - val_accuracy: 0.8701\n",
      "Epoch 399/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8464 - val_loss: 0.3198 - val_accuracy: 0.8669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8520 - val_loss: 0.3206 - val_accuracy: 0.8701\n",
      "Epoch 401/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8589 - val_loss: 0.3228 - val_accuracy: 0.8701\n",
      "Epoch 402/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8492 - val_loss: 0.3168 - val_accuracy: 0.8701\n",
      "Epoch 403/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8492 - val_loss: 0.3201 - val_accuracy: 0.8701\n",
      "Epoch 404/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8506 - val_loss: 0.3187 - val_accuracy: 0.8636\n",
      "Epoch 405/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8464 - val_loss: 0.3190 - val_accuracy: 0.8701\n",
      "Epoch 406/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8478 - val_loss: 0.3186 - val_accuracy: 0.8669\n",
      "Epoch 407/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8506 - val_loss: 0.3189 - val_accuracy: 0.8701\n",
      "Epoch 408/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8478 - val_loss: 0.3177 - val_accuracy: 0.8636\n",
      "Epoch 409/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8506 - val_loss: 0.3199 - val_accuracy: 0.8701\n",
      "Epoch 410/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8478 - val_loss: 0.3180 - val_accuracy: 0.8636\n",
      "Epoch 411/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8547 - val_loss: 0.3202 - val_accuracy: 0.8701\n",
      "Epoch 412/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8534 - val_loss: 0.3176 - val_accuracy: 0.8669\n",
      "Epoch 413/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8506 - val_loss: 0.3182 - val_accuracy: 0.8701\n",
      "Epoch 414/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8478 - val_loss: 0.3176 - val_accuracy: 0.8669\n",
      "Epoch 415/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8561 - val_loss: 0.3194 - val_accuracy: 0.8701\n",
      "Epoch 416/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8520 - val_loss: 0.3165 - val_accuracy: 0.8701\n",
      "Epoch 417/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8464 - val_loss: 0.3161 - val_accuracy: 0.8701\n",
      "Epoch 418/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8492 - val_loss: 0.3187 - val_accuracy: 0.8701\n",
      "Epoch 419/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8631 - val_loss: 0.3194 - val_accuracy: 0.8701\n",
      "Epoch 420/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8534 - val_loss: 0.3151 - val_accuracy: 0.8701\n",
      "Epoch 421/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8506 - val_loss: 0.3168 - val_accuracy: 0.8669\n",
      "Epoch 422/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8478 - val_loss: 0.3167 - val_accuracy: 0.8669\n",
      "Epoch 423/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8561 - val_loss: 0.3191 - val_accuracy: 0.8701\n",
      "Epoch 424/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8506 - val_loss: 0.3155 - val_accuracy: 0.8734\n",
      "Epoch 425/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8506 - val_loss: 0.3166 - val_accuracy: 0.8701\n",
      "Epoch 426/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8478 - val_loss: 0.3156 - val_accuracy: 0.8734\n",
      "Epoch 427/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8492 - val_loss: 0.3164 - val_accuracy: 0.8701\n",
      "Epoch 428/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8506 - val_loss: 0.3144 - val_accuracy: 0.8701\n",
      "Epoch 429/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8478 - val_loss: 0.3145 - val_accuracy: 0.8701\n",
      "Epoch 430/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8506 - val_loss: 0.3165 - val_accuracy: 0.8701\n",
      "Epoch 431/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8659 - val_loss: 0.3170 - val_accuracy: 0.8701\n",
      "Epoch 432/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8561 - val_loss: 0.3149 - val_accuracy: 0.8734\n",
      "Epoch 433/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8492 - val_loss: 0.3145 - val_accuracy: 0.8734\n",
      "Epoch 434/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8492 - val_loss: 0.3149 - val_accuracy: 0.8734\n",
      "Epoch 435/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8534 - val_loss: 0.3155 - val_accuracy: 0.8701\n",
      "Epoch 436/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8506 - val_loss: 0.3137 - val_accuracy: 0.8734\n",
      "Epoch 437/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8561 - val_loss: 0.3152 - val_accuracy: 0.8701\n",
      "Epoch 438/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8492 - val_loss: 0.3143 - val_accuracy: 0.8734\n",
      "Epoch 439/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8492 - val_loss: 0.3138 - val_accuracy: 0.8734\n",
      "Epoch 440/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8520 - val_loss: 0.3145 - val_accuracy: 0.8766\n",
      "Epoch 441/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8575 - val_loss: 0.3146 - val_accuracy: 0.8701\n",
      "Epoch 442/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8561 - val_loss: 0.3133 - val_accuracy: 0.8734\n",
      "Epoch 443/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8492 - val_loss: 0.3122 - val_accuracy: 0.8734\n",
      "Epoch 444/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8492 - val_loss: 0.3131 - val_accuracy: 0.8734\n",
      "Epoch 445/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8492 - val_loss: 0.3125 - val_accuracy: 0.8734\n",
      "Epoch 446/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8645 - val_loss: 0.3144 - val_accuracy: 0.8701\n",
      "Epoch 447/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8547 - val_loss: 0.3126 - val_accuracy: 0.8734\n",
      "Epoch 448/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8492 - val_loss: 0.3121 - val_accuracy: 0.8734\n",
      "Epoch 449/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8506 - val_loss: 0.3143 - val_accuracy: 0.8701\n",
      "Epoch 450/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8492 - val_loss: 0.3125 - val_accuracy: 0.8734\n",
      "Epoch 451/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8492 - val_loss: 0.3114 - val_accuracy: 0.8734\n",
      "Epoch 452/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8492 - val_loss: 0.3120 - val_accuracy: 0.8734\n",
      "Epoch 453/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8492 - val_loss: 0.3127 - val_accuracy: 0.8734\n",
      "Epoch 454/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8575 - val_loss: 0.3137 - val_accuracy: 0.8701\n",
      "Epoch 455/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8520 - val_loss: 0.3120 - val_accuracy: 0.8734\n",
      "Epoch 456/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8561 - val_loss: 0.3128 - val_accuracy: 0.8701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8492 - val_loss: 0.3106 - val_accuracy: 0.8734\n",
      "Epoch 458/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8492 - val_loss: 0.3110 - val_accuracy: 0.8734\n",
      "Epoch 459/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8589 - val_loss: 0.3138 - val_accuracy: 0.8734\n",
      "Epoch 460/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8547 - val_loss: 0.3113 - val_accuracy: 0.8734\n",
      "Epoch 461/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8492 - val_loss: 0.3109 - val_accuracy: 0.8734\n",
      "Epoch 462/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8561 - val_loss: 0.3124 - val_accuracy: 0.8701\n",
      "Epoch 463/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8492 - val_loss: 0.3106 - val_accuracy: 0.8734\n",
      "Epoch 464/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8492 - val_loss: 0.3100 - val_accuracy: 0.8734\n",
      "Epoch 465/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8492 - val_loss: 0.3101 - val_accuracy: 0.8734\n",
      "Epoch 466/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8492 - val_loss: 0.3095 - val_accuracy: 0.8734\n",
      "Epoch 467/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8506 - val_loss: 0.3104 - val_accuracy: 0.8734\n",
      "Epoch 468/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8506 - val_loss: 0.3098 - val_accuracy: 0.8734\n",
      "Epoch 469/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8492 - val_loss: 0.3083 - val_accuracy: 0.8734\n",
      "Epoch 470/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8534 - val_loss: 0.3103 - val_accuracy: 0.8734\n",
      "Epoch 471/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8575 - val_loss: 0.3108 - val_accuracy: 0.8701\n",
      "Epoch 472/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8506 - val_loss: 0.3090 - val_accuracy: 0.8734\n",
      "Epoch 473/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8534 - val_loss: 0.3099 - val_accuracy: 0.8766\n",
      "Epoch 474/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8534 - val_loss: 0.3087 - val_accuracy: 0.8734\n",
      "Epoch 475/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8506 - val_loss: 0.3094 - val_accuracy: 0.8766\n",
      "Epoch 476/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8561 - val_loss: 0.3107 - val_accuracy: 0.8701\n",
      "Epoch 477/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8589 - val_loss: 0.3091 - val_accuracy: 0.8734\n",
      "Epoch 478/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8561 - val_loss: 0.3092 - val_accuracy: 0.8766\n",
      "Epoch 479/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8520 - val_loss: 0.3076 - val_accuracy: 0.8734\n",
      "Epoch 480/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8492 - val_loss: 0.3073 - val_accuracy: 0.8734\n",
      "Epoch 481/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8506 - val_loss: 0.3079 - val_accuracy: 0.8734\n",
      "Epoch 482/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8603 - val_loss: 0.3091 - val_accuracy: 0.8766\n",
      "Epoch 483/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8589 - val_loss: 0.3088 - val_accuracy: 0.8766\n",
      "Epoch 484/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8520 - val_loss: 0.3062 - val_accuracy: 0.8734\n",
      "Epoch 485/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8561 - val_loss: 0.3084 - val_accuracy: 0.8766\n",
      "Epoch 486/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8520 - val_loss: 0.3068 - val_accuracy: 0.8734\n",
      "Epoch 487/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8492 - val_loss: 0.3067 - val_accuracy: 0.8734\n",
      "Epoch 488/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8520 - val_loss: 0.3065 - val_accuracy: 0.8734\n",
      "Epoch 489/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8575 - val_loss: 0.3083 - val_accuracy: 0.8766\n",
      "Epoch 490/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8589 - val_loss: 0.3067 - val_accuracy: 0.8734\n",
      "Epoch 491/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8547 - val_loss: 0.3063 - val_accuracy: 0.8734\n",
      "Epoch 492/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8561 - val_loss: 0.3061 - val_accuracy: 0.8734\n",
      "Epoch 493/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8534 - val_loss: 0.3059 - val_accuracy: 0.8734\n",
      "Epoch 494/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8589 - val_loss: 0.3072 - val_accuracy: 0.8799\n",
      "Epoch 495/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8575 - val_loss: 0.3054 - val_accuracy: 0.8734\n",
      "Epoch 496/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8561 - val_loss: 0.3062 - val_accuracy: 0.8766\n",
      "Epoch 497/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8589 - val_loss: 0.3064 - val_accuracy: 0.8766\n",
      "Epoch 498/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8673 - val_loss: 0.3069 - val_accuracy: 0.8799\n",
      "Epoch 499/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8561 - val_loss: 0.3037 - val_accuracy: 0.8766\n",
      "Epoch 500/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8617 - val_loss: 0.3056 - val_accuracy: 0.8766\n",
      "Epoch 501/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8547 - val_loss: 0.3046 - val_accuracy: 0.8734\n",
      "Epoch 502/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8534 - val_loss: 0.3043 - val_accuracy: 0.8734\n",
      "Epoch 503/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8561 - val_loss: 0.3049 - val_accuracy: 0.8734\n",
      "Epoch 504/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3263 - accuracy: 0.8617 - val_loss: 0.3051 - val_accuracy: 0.8766\n",
      "Epoch 505/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8547 - val_loss: 0.3028 - val_accuracy: 0.8766\n",
      "Epoch 506/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8645 - val_loss: 0.3073 - val_accuracy: 0.8734\n",
      "Epoch 507/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8589 - val_loss: 0.3042 - val_accuracy: 0.8734\n",
      "Epoch 508/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8547 - val_loss: 0.3037 - val_accuracy: 0.8734\n",
      "Epoch 509/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3254 - accuracy: 0.8547 - val_loss: 0.3042 - val_accuracy: 0.8734\n",
      "Epoch 510/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8561 - val_loss: 0.3043 - val_accuracy: 0.8766\n",
      "Epoch 511/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3254 - accuracy: 0.8575 - val_loss: 0.3028 - val_accuracy: 0.8766\n",
      "Epoch 512/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3251 - accuracy: 0.8575 - val_loss: 0.3035 - val_accuracy: 0.8766\n",
      "Epoch 513/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8617 - val_loss: 0.3049 - val_accuracy: 0.8799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8603 - val_loss: 0.3031 - val_accuracy: 0.8766\n",
      "Epoch 515/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3263 - accuracy: 0.8589 - val_loss: 0.3043 - val_accuracy: 0.8799\n",
      "Epoch 516/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8589 - val_loss: 0.3021 - val_accuracy: 0.8766\n",
      "Epoch 517/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3008 - val_accuracy: 0.8766\n",
      "Epoch 518/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8575 - val_loss: 0.3028 - val_accuracy: 0.8766\n",
      "Epoch 519/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8561 - val_loss: 0.3016 - val_accuracy: 0.8766\n",
      "Epoch 520/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8575 - val_loss: 0.3028 - val_accuracy: 0.8766\n",
      "Epoch 521/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3239 - accuracy: 0.8575 - val_loss: 0.3019 - val_accuracy: 0.8766\n",
      "Epoch 522/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8589 - val_loss: 0.3014 - val_accuracy: 0.8766\n",
      "Epoch 523/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.8589 - val_loss: 0.3020 - val_accuracy: 0.8766\n",
      "Epoch 524/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3235 - accuracy: 0.8575 - val_loss: 0.3001 - val_accuracy: 0.8766\n",
      "Epoch 525/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8575 - val_loss: 0.3021 - val_accuracy: 0.8831\n",
      "Epoch 526/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8603 - val_loss: 0.3004 - val_accuracy: 0.8766\n",
      "Epoch 527/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8575 - val_loss: 0.2994 - val_accuracy: 0.8766\n",
      "Epoch 528/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8575 - val_loss: 0.3001 - val_accuracy: 0.8766\n",
      "Epoch 529/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8589 - val_loss: 0.3016 - val_accuracy: 0.8799\n",
      "Epoch 530/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8534 - val_loss: 0.2985 - val_accuracy: 0.8766\n",
      "Epoch 531/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8575 - val_loss: 0.3000 - val_accuracy: 0.8766\n",
      "Epoch 532/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8575 - val_loss: 0.3018 - val_accuracy: 0.8831\n",
      "Epoch 533/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.8575 - val_loss: 0.2989 - val_accuracy: 0.8766\n",
      "Epoch 534/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8631 - val_loss: 0.3012 - val_accuracy: 0.8831\n",
      "Epoch 535/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3220 - accuracy: 0.8631 - val_loss: 0.2994 - val_accuracy: 0.8766\n",
      "Epoch 536/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8561 - val_loss: 0.2978 - val_accuracy: 0.8734\n",
      "Epoch 537/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3222 - accuracy: 0.8603 - val_loss: 0.3012 - val_accuracy: 0.8831\n",
      "Epoch 538/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.8561 - val_loss: 0.2974 - val_accuracy: 0.8734\n",
      "Epoch 539/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8617 - val_loss: 0.3009 - val_accuracy: 0.8831\n",
      "Epoch 540/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8645 - val_loss: 0.2999 - val_accuracy: 0.8831\n",
      "Epoch 541/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8631 - val_loss: 0.2987 - val_accuracy: 0.8766\n",
      "Epoch 542/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8547 - val_loss: 0.2969 - val_accuracy: 0.8766\n",
      "Epoch 543/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3211 - accuracy: 0.8575 - val_loss: 0.2993 - val_accuracy: 0.8799\n",
      "Epoch 544/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3215 - accuracy: 0.8603 - val_loss: 0.2979 - val_accuracy: 0.8766\n",
      "Epoch 545/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3209 - accuracy: 0.8575 - val_loss: 0.2980 - val_accuracy: 0.8766\n",
      "Epoch 546/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3211 - accuracy: 0.8617 - val_loss: 0.2986 - val_accuracy: 0.8799\n",
      "Epoch 547/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8575 - val_loss: 0.2980 - val_accuracy: 0.8766\n",
      "Epoch 548/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.8575 - val_loss: 0.2977 - val_accuracy: 0.8766\n",
      "Epoch 549/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.8645 - val_loss: 0.2994 - val_accuracy: 0.8831\n",
      "Epoch 550/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8603 - val_loss: 0.2969 - val_accuracy: 0.8766\n",
      "Epoch 551/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3203 - accuracy: 0.8575 - val_loss: 0.2964 - val_accuracy: 0.8766\n",
      "Epoch 552/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.8575 - val_loss: 0.2973 - val_accuracy: 0.8799\n",
      "Epoch 553/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8575 - val_loss: 0.2963 - val_accuracy: 0.8766\n",
      "Epoch 554/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8631 - val_loss: 0.2974 - val_accuracy: 0.8831\n",
      "Epoch 555/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8589 - val_loss: 0.2968 - val_accuracy: 0.8799\n",
      "Epoch 556/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8603 - val_loss: 0.2958 - val_accuracy: 0.8766\n",
      "Epoch 557/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.8617 - val_loss: 0.2972 - val_accuracy: 0.8831\n",
      "Epoch 558/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.8617 - val_loss: 0.2967 - val_accuracy: 0.8831\n",
      "Epoch 559/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8575 - val_loss: 0.2966 - val_accuracy: 0.8831\n",
      "Epoch 560/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3189 - accuracy: 0.8645 - val_loss: 0.2978 - val_accuracy: 0.8831\n",
      "Epoch 561/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.8631 - val_loss: 0.2953 - val_accuracy: 0.8799\n",
      "Epoch 562/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3184 - accuracy: 0.8603 - val_loss: 0.2943 - val_accuracy: 0.8766\n",
      "Epoch 563/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3190 - accuracy: 0.8547 - val_loss: 0.2939 - val_accuracy: 0.8766\n",
      "Epoch 564/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3203 - accuracy: 0.8673 - val_loss: 0.2964 - val_accuracy: 0.8831\n",
      "Epoch 565/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3189 - accuracy: 0.8561 - val_loss: 0.2943 - val_accuracy: 0.8799\n",
      "Epoch 566/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8603 - val_loss: 0.2939 - val_accuracy: 0.8799\n",
      "Epoch 567/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3179 - accuracy: 0.8603 - val_loss: 0.2949 - val_accuracy: 0.8799\n",
      "Epoch 568/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3179 - accuracy: 0.8575 - val_loss: 0.2938 - val_accuracy: 0.8799\n",
      "Epoch 569/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8645 - val_loss: 0.2957 - val_accuracy: 0.8831\n",
      "Epoch 570/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3177 - accuracy: 0.8575 - val_loss: 0.2928 - val_accuracy: 0.8766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8603 - val_loss: 0.2944 - val_accuracy: 0.8799\n",
      "Epoch 572/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8603 - val_loss: 0.2928 - val_accuracy: 0.8799\n",
      "Epoch 573/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3171 - accuracy: 0.8589 - val_loss: 0.2927 - val_accuracy: 0.8799\n",
      "Epoch 574/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8645 - val_loss: 0.2941 - val_accuracy: 0.8831\n",
      "Epoch 575/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8603 - val_loss: 0.2936 - val_accuracy: 0.8799\n",
      "Epoch 576/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3168 - accuracy: 0.8603 - val_loss: 0.2924 - val_accuracy: 0.8799\n",
      "Epoch 577/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8659 - val_loss: 0.2953 - val_accuracy: 0.8864\n",
      "Epoch 578/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3164 - accuracy: 0.8631 - val_loss: 0.2924 - val_accuracy: 0.8799\n",
      "Epoch 579/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3167 - accuracy: 0.8547 - val_loss: 0.2909 - val_accuracy: 0.8766\n",
      "Epoch 580/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3164 - accuracy: 0.8617 - val_loss: 0.2929 - val_accuracy: 0.8799\n",
      "Epoch 581/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3159 - accuracy: 0.8589 - val_loss: 0.2914 - val_accuracy: 0.8799\n",
      "Epoch 582/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8617 - val_loss: 0.2934 - val_accuracy: 0.8831\n",
      "Epoch 583/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3158 - accuracy: 0.8617 - val_loss: 0.2907 - val_accuracy: 0.8766\n",
      "Epoch 584/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8617 - val_loss: 0.2927 - val_accuracy: 0.8831\n",
      "Epoch 585/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3153 - accuracy: 0.8645 - val_loss: 0.2922 - val_accuracy: 0.8799\n",
      "Epoch 586/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3157 - accuracy: 0.8589 - val_loss: 0.2901 - val_accuracy: 0.8734\n",
      "Epoch 587/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3149 - accuracy: 0.8547 - val_loss: 0.2912 - val_accuracy: 0.8799\n",
      "Epoch 588/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3154 - accuracy: 0.8617 - val_loss: 0.2947 - val_accuracy: 0.8929\n",
      "Epoch 589/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3147 - accuracy: 0.8603 - val_loss: 0.2893 - val_accuracy: 0.8734\n",
      "Epoch 590/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3149 - accuracy: 0.8561 - val_loss: 0.2910 - val_accuracy: 0.8799\n",
      "Epoch 591/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3147 - accuracy: 0.8659 - val_loss: 0.2923 - val_accuracy: 0.8831\n",
      "Epoch 592/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8547 - val_loss: 0.2889 - val_accuracy: 0.8734\n",
      "Epoch 593/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3140 - accuracy: 0.8575 - val_loss: 0.2910 - val_accuracy: 0.8831\n",
      "Epoch 594/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3140 - accuracy: 0.8645 - val_loss: 0.2906 - val_accuracy: 0.8831\n",
      "Epoch 595/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3142 - accuracy: 0.8631 - val_loss: 0.2913 - val_accuracy: 0.8831\n",
      "Epoch 596/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3134 - accuracy: 0.8631 - val_loss: 0.2889 - val_accuracy: 0.8766\n",
      "Epoch 597/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.8561 - val_loss: 0.2878 - val_accuracy: 0.8734\n",
      "Epoch 598/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.8603 - val_loss: 0.2914 - val_accuracy: 0.8864\n",
      "Epoch 599/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3144 - accuracy: 0.8645 - val_loss: 0.2893 - val_accuracy: 0.8799\n",
      "Epoch 600/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8673 - val_loss: 0.2909 - val_accuracy: 0.8864\n",
      "Epoch 601/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3131 - accuracy: 0.8603 - val_loss: 0.2878 - val_accuracy: 0.8766\n",
      "Epoch 602/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3127 - accuracy: 0.8589 - val_loss: 0.2892 - val_accuracy: 0.8831\n",
      "Epoch 603/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8603 - val_loss: 0.2886 - val_accuracy: 0.8799\n",
      "Epoch 604/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3136 - accuracy: 0.8645 - val_loss: 0.2878 - val_accuracy: 0.8766\n",
      "Epoch 605/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.8575 - val_loss: 0.2881 - val_accuracy: 0.8799\n",
      "Epoch 606/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8603 - val_loss: 0.2894 - val_accuracy: 0.8831\n",
      "Epoch 607/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3118 - accuracy: 0.8589 - val_loss: 0.2862 - val_accuracy: 0.8766\n",
      "Epoch 608/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8575 - val_loss: 0.2876 - val_accuracy: 0.8766\n",
      "Epoch 609/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3121 - accuracy: 0.8659 - val_loss: 0.2898 - val_accuracy: 0.8929\n",
      "Epoch 610/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3117 - accuracy: 0.8631 - val_loss: 0.2863 - val_accuracy: 0.8766\n",
      "Epoch 611/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3116 - accuracy: 0.8575 - val_loss: 0.2875 - val_accuracy: 0.8766\n",
      "Epoch 612/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.8575 - val_loss: 0.2866 - val_accuracy: 0.8766\n",
      "Epoch 613/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.8575 - val_loss: 0.2866 - val_accuracy: 0.8766\n",
      "Epoch 614/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3117 - accuracy: 0.8631 - val_loss: 0.2885 - val_accuracy: 0.8929\n",
      "Epoch 615/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3110 - accuracy: 0.8603 - val_loss: 0.2862 - val_accuracy: 0.8766\n",
      "Epoch 616/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.8575 - val_loss: 0.2865 - val_accuracy: 0.8766\n",
      "Epoch 617/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3105 - accuracy: 0.8575 - val_loss: 0.2870 - val_accuracy: 0.8831\n",
      "Epoch 618/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3107 - accuracy: 0.8603 - val_loss: 0.2869 - val_accuracy: 0.8799\n",
      "Epoch 619/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8589 - val_loss: 0.2865 - val_accuracy: 0.8766\n",
      "Epoch 620/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8589 - val_loss: 0.2852 - val_accuracy: 0.8766\n",
      "Epoch 621/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8575 - val_loss: 0.2851 - val_accuracy: 0.8766\n",
      "Epoch 622/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.8589 - val_loss: 0.2852 - val_accuracy: 0.8766\n",
      "Epoch 623/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.8575 - val_loss: 0.2846 - val_accuracy: 0.8766\n",
      "Epoch 624/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3098 - accuracy: 0.8603 - val_loss: 0.2860 - val_accuracy: 0.8799\n",
      "Epoch 625/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8603 - val_loss: 0.2842 - val_accuracy: 0.8766\n",
      "Epoch 626/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3095 - accuracy: 0.8575 - val_loss: 0.2845 - val_accuracy: 0.8766\n",
      "Epoch 627/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.8687 - val_loss: 0.2857 - val_accuracy: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3089 - accuracy: 0.8617 - val_loss: 0.2827 - val_accuracy: 0.8831\n",
      "Epoch 629/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.8589 - val_loss: 0.2844 - val_accuracy: 0.8766\n",
      "Epoch 630/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8617 - val_loss: 0.2835 - val_accuracy: 0.8766\n",
      "Epoch 631/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3089 - accuracy: 0.8603 - val_loss: 0.2847 - val_accuracy: 0.8896\n",
      "Epoch 632/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8631 - val_loss: 0.2833 - val_accuracy: 0.8766\n",
      "Epoch 633/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8561 - val_loss: 0.2828 - val_accuracy: 0.8766\n",
      "Epoch 634/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8561 - val_loss: 0.2828 - val_accuracy: 0.8766\n",
      "Epoch 635/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8575 - val_loss: 0.2822 - val_accuracy: 0.8766\n",
      "Epoch 636/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8561 - val_loss: 0.2826 - val_accuracy: 0.8766\n",
      "Epoch 637/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8575 - val_loss: 0.2840 - val_accuracy: 0.8896\n",
      "Epoch 638/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8589 - val_loss: 0.2820 - val_accuracy: 0.8766\n",
      "Epoch 639/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8617 - val_loss: 0.2828 - val_accuracy: 0.8896\n",
      "Epoch 640/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8645 - val_loss: 0.2818 - val_accuracy: 0.8766\n",
      "Epoch 641/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8589 - val_loss: 0.2811 - val_accuracy: 0.8831\n",
      "Epoch 642/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3069 - accuracy: 0.8617 - val_loss: 0.2811 - val_accuracy: 0.8831\n",
      "Epoch 643/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3068 - accuracy: 0.8589 - val_loss: 0.2825 - val_accuracy: 0.8896\n",
      "Epoch 644/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3068 - accuracy: 0.8617 - val_loss: 0.2823 - val_accuracy: 0.8896\n",
      "Epoch 645/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.8617 - val_loss: 0.2804 - val_accuracy: 0.8831\n",
      "Epoch 646/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8603 - val_loss: 0.2808 - val_accuracy: 0.8766\n",
      "Epoch 647/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.8631 - val_loss: 0.2830 - val_accuracy: 0.8929\n",
      "Epoch 648/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3061 - accuracy: 0.8617 - val_loss: 0.2798 - val_accuracy: 0.8831\n",
      "Epoch 649/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.8645 - val_loss: 0.2799 - val_accuracy: 0.8831\n",
      "Epoch 650/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3060 - accuracy: 0.8617 - val_loss: 0.2806 - val_accuracy: 0.8864\n",
      "Epoch 651/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.8617 - val_loss: 0.2790 - val_accuracy: 0.8831\n",
      "Epoch 652/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.8575 - val_loss: 0.2800 - val_accuracy: 0.8766\n",
      "Epoch 653/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.8589 - val_loss: 0.2800 - val_accuracy: 0.8864\n",
      "Epoch 654/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3051 - accuracy: 0.8645 - val_loss: 0.2799 - val_accuracy: 0.8896\n",
      "Epoch 655/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3051 - accuracy: 0.8631 - val_loss: 0.2784 - val_accuracy: 0.8831\n",
      "Epoch 656/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3049 - accuracy: 0.8645 - val_loss: 0.2786 - val_accuracy: 0.8831\n",
      "Epoch 657/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3057 - accuracy: 0.8631 - val_loss: 0.2791 - val_accuracy: 0.8896\n",
      "Epoch 658/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3046 - accuracy: 0.8589 - val_loss: 0.2795 - val_accuracy: 0.8929\n",
      "Epoch 659/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.8589 - val_loss: 0.2790 - val_accuracy: 0.8896\n",
      "Epoch 660/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3050 - accuracy: 0.8617 - val_loss: 0.2790 - val_accuracy: 0.8961\n",
      "Epoch 661/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3045 - accuracy: 0.8645 - val_loss: 0.2818 - val_accuracy: 0.8896\n",
      "Epoch 662/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3041 - accuracy: 0.8659 - val_loss: 0.2769 - val_accuracy: 0.8831\n",
      "Epoch 663/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3046 - accuracy: 0.8617 - val_loss: 0.2790 - val_accuracy: 0.8961\n",
      "Epoch 664/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3061 - accuracy: 0.8617 - val_loss: 0.2759 - val_accuracy: 0.8831\n",
      "Epoch 665/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3032 - accuracy: 0.8645 - val_loss: 0.2797 - val_accuracy: 0.8896\n",
      "Epoch 666/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3039 - accuracy: 0.8673 - val_loss: 0.2783 - val_accuracy: 0.8961\n",
      "Epoch 667/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3032 - accuracy: 0.8631 - val_loss: 0.2783 - val_accuracy: 0.8961\n",
      "Epoch 668/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3036 - accuracy: 0.8673 - val_loss: 0.2799 - val_accuracy: 0.8896\n",
      "Epoch 669/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3049 - accuracy: 0.8617 - val_loss: 0.2758 - val_accuracy: 0.8831\n",
      "Epoch 670/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8673 - val_loss: 0.2780 - val_accuracy: 0.8961\n",
      "Epoch 671/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3039 - accuracy: 0.8673 - val_loss: 0.2782 - val_accuracy: 0.8961\n",
      "Epoch 672/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3029 - accuracy: 0.8617 - val_loss: 0.2759 - val_accuracy: 0.8831\n",
      "Epoch 673/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3025 - accuracy: 0.8631 - val_loss: 0.2768 - val_accuracy: 0.8929\n",
      "Epoch 674/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3022 - accuracy: 0.8687 - val_loss: 0.2767 - val_accuracy: 0.8961\n",
      "Epoch 675/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.8687 - val_loss: 0.2754 - val_accuracy: 0.8896\n",
      "Epoch 676/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.8603 - val_loss: 0.2754 - val_accuracy: 0.8896\n",
      "Epoch 677/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.8603 - val_loss: 0.2753 - val_accuracy: 0.8896\n",
      "Epoch 678/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3014 - accuracy: 0.8701 - val_loss: 0.2769 - val_accuracy: 0.8961\n",
      "Epoch 679/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3016 - accuracy: 0.8701 - val_loss: 0.2757 - val_accuracy: 0.8961\n",
      "Epoch 680/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8687 - val_loss: 0.2750 - val_accuracy: 0.8929\n",
      "Epoch 681/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8659 - val_loss: 0.2744 - val_accuracy: 0.8929\n",
      "Epoch 682/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.8659 - val_loss: 0.2744 - val_accuracy: 0.8929\n",
      "Epoch 683/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3014 - accuracy: 0.8603 - val_loss: 0.2741 - val_accuracy: 0.8896\n",
      "Epoch 684/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3014 - accuracy: 0.8687 - val_loss: 0.2756 - val_accuracy: 0.8961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8631 - val_loss: 0.2743 - val_accuracy: 0.8929\n",
      "Epoch 686/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3006 - accuracy: 0.8715 - val_loss: 0.2734 - val_accuracy: 0.8929\n",
      "Epoch 687/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8645 - val_loss: 0.2753 - val_accuracy: 0.8961\n",
      "Epoch 688/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3001 - accuracy: 0.8715 - val_loss: 0.2743 - val_accuracy: 0.8961\n",
      "Epoch 689/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3000 - accuracy: 0.8701 - val_loss: 0.2741 - val_accuracy: 0.8961\n",
      "Epoch 690/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3001 - accuracy: 0.8687 - val_loss: 0.2729 - val_accuracy: 0.8896\n",
      "Epoch 691/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8687 - val_loss: 0.2734 - val_accuracy: 0.8929\n",
      "Epoch 692/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.8701 - val_loss: 0.2724 - val_accuracy: 0.8896\n",
      "Epoch 693/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3001 - accuracy: 0.8617 - val_loss: 0.2721 - val_accuracy: 0.8896\n",
      "Epoch 694/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.8715 - val_loss: 0.2740 - val_accuracy: 0.8961\n",
      "Epoch 695/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2997 - accuracy: 0.8631 - val_loss: 0.2715 - val_accuracy: 0.8831\n",
      "Epoch 696/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8617 - val_loss: 0.2732 - val_accuracy: 0.8961\n",
      "Epoch 697/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2996 - accuracy: 0.8701 - val_loss: 0.2735 - val_accuracy: 0.8961\n",
      "Epoch 698/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.8687 - val_loss: 0.2729 - val_accuracy: 0.8961\n",
      "Epoch 699/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8715 - val_loss: 0.2730 - val_accuracy: 0.8961\n",
      "Epoch 700/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8673 - val_loss: 0.2728 - val_accuracy: 0.8961\n",
      "Epoch 701/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8617 - val_loss: 0.2708 - val_accuracy: 0.8896\n",
      "Epoch 702/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8729 - val_loss: 0.2734 - val_accuracy: 0.8961\n",
      "Epoch 703/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2985 - accuracy: 0.8659 - val_loss: 0.2706 - val_accuracy: 0.8896\n",
      "Epoch 704/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8659 - val_loss: 0.2721 - val_accuracy: 0.8961\n",
      "Epoch 705/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2983 - accuracy: 0.8617 - val_loss: 0.2703 - val_accuracy: 0.8896\n",
      "Epoch 706/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.8631 - val_loss: 0.2716 - val_accuracy: 0.8961\n",
      "Epoch 707/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2975 - accuracy: 0.8715 - val_loss: 0.2712 - val_accuracy: 0.8961\n",
      "Epoch 708/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.8715 - val_loss: 0.2704 - val_accuracy: 0.8961\n",
      "Epoch 709/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.8715 - val_loss: 0.2701 - val_accuracy: 0.8961\n",
      "Epoch 710/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2971 - accuracy: 0.8645 - val_loss: 0.2692 - val_accuracy: 0.8896\n",
      "Epoch 711/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8631 - val_loss: 0.2703 - val_accuracy: 0.8961\n",
      "Epoch 712/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2967 - accuracy: 0.8715 - val_loss: 0.2700 - val_accuracy: 0.8961\n",
      "Epoch 713/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2965 - accuracy: 0.8673 - val_loss: 0.2687 - val_accuracy: 0.8929\n",
      "Epoch 714/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8631 - val_loss: 0.2702 - val_accuracy: 0.8961\n",
      "Epoch 715/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2969 - accuracy: 0.8715 - val_loss: 0.2703 - val_accuracy: 0.8961\n",
      "Epoch 716/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2965 - accuracy: 0.8673 - val_loss: 0.2697 - val_accuracy: 0.8961\n",
      "Epoch 717/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8701 - val_loss: 0.2697 - val_accuracy: 0.8961\n",
      "Epoch 718/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2962 - accuracy: 0.8701 - val_loss: 0.2698 - val_accuracy: 0.8961\n",
      "Epoch 719/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8673 - val_loss: 0.2683 - val_accuracy: 0.8961\n",
      "Epoch 720/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2957 - accuracy: 0.8701 - val_loss: 0.2687 - val_accuracy: 0.8961\n",
      "Epoch 721/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.8715 - val_loss: 0.2692 - val_accuracy: 0.8961\n",
      "Epoch 722/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2954 - accuracy: 0.8715 - val_loss: 0.2676 - val_accuracy: 0.8929\n",
      "Epoch 723/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2953 - accuracy: 0.8701 - val_loss: 0.2678 - val_accuracy: 0.8961\n",
      "Epoch 724/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8603 - val_loss: 0.2663 - val_accuracy: 0.8929\n",
      "Epoch 725/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2944 - accuracy: 0.8687 - val_loss: 0.2689 - val_accuracy: 0.8961\n",
      "Epoch 726/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2956 - accuracy: 0.8687 - val_loss: 0.2678 - val_accuracy: 0.8961\n",
      "Epoch 727/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.8687 - val_loss: 0.2686 - val_accuracy: 0.8961\n",
      "Epoch 728/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8701 - val_loss: 0.2676 - val_accuracy: 0.8961\n",
      "Epoch 729/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2952 - accuracy: 0.8729 - val_loss: 0.2679 - val_accuracy: 0.8961\n",
      "Epoch 730/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2942 - accuracy: 0.8715 - val_loss: 0.2670 - val_accuracy: 0.8961\n",
      "Epoch 731/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2962 - accuracy: 0.8631 - val_loss: 0.2665 - val_accuracy: 0.8961\n",
      "Epoch 732/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8729 - val_loss: 0.2703 - val_accuracy: 0.9026\n",
      "Epoch 733/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2934 - accuracy: 0.8687 - val_loss: 0.2646 - val_accuracy: 0.8896\n",
      "Epoch 734/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2947 - accuracy: 0.8631 - val_loss: 0.2654 - val_accuracy: 0.8929\n",
      "Epoch 735/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2943 - accuracy: 0.8673 - val_loss: 0.2656 - val_accuracy: 0.8929\n",
      "Epoch 736/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2942 - accuracy: 0.8701 - val_loss: 0.2689 - val_accuracy: 0.9026\n",
      "Epoch 737/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2937 - accuracy: 0.8687 - val_loss: 0.2656 - val_accuracy: 0.8961\n",
      "Epoch 738/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2931 - accuracy: 0.8687 - val_loss: 0.2655 - val_accuracy: 0.8961\n",
      "Epoch 739/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2933 - accuracy: 0.8687 - val_loss: 0.2666 - val_accuracy: 0.8961\n",
      "Epoch 740/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2933 - accuracy: 0.8687 - val_loss: 0.2646 - val_accuracy: 0.8929\n",
      "Epoch 741/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2932 - accuracy: 0.8715 - val_loss: 0.2649 - val_accuracy: 0.8961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2928 - accuracy: 0.8673 - val_loss: 0.2654 - val_accuracy: 0.8961\n",
      "Epoch 743/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2927 - accuracy: 0.8701 - val_loss: 0.2655 - val_accuracy: 0.8961\n",
      "Epoch 744/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2926 - accuracy: 0.8673 - val_loss: 0.2649 - val_accuracy: 0.8961\n",
      "Epoch 745/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2935 - accuracy: 0.8729 - val_loss: 0.2668 - val_accuracy: 0.8994\n",
      "Epoch 746/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2924 - accuracy: 0.8687 - val_loss: 0.2632 - val_accuracy: 0.8929\n",
      "Epoch 747/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2924 - accuracy: 0.8645 - val_loss: 0.2639 - val_accuracy: 0.8961\n",
      "Epoch 748/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.8673 - val_loss: 0.2647 - val_accuracy: 0.8961\n",
      "Epoch 749/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2924 - accuracy: 0.8673 - val_loss: 0.2630 - val_accuracy: 0.8929\n",
      "Epoch 750/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2920 - accuracy: 0.8715 - val_loss: 0.2650 - val_accuracy: 0.8961\n",
      "Epoch 751/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2916 - accuracy: 0.8701 - val_loss: 0.2644 - val_accuracy: 0.8961\n",
      "Epoch 752/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.8673 - val_loss: 0.2640 - val_accuracy: 0.8961\n",
      "Epoch 753/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2927 - accuracy: 0.8771 - val_loss: 0.2642 - val_accuracy: 0.8961\n",
      "Epoch 754/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2913 - accuracy: 0.8673 - val_loss: 0.2632 - val_accuracy: 0.8961\n",
      "Epoch 755/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2912 - accuracy: 0.8687 - val_loss: 0.2622 - val_accuracy: 0.8929\n",
      "Epoch 756/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.8673 - val_loss: 0.2640 - val_accuracy: 0.8961\n",
      "Epoch 757/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.8673 - val_loss: 0.2627 - val_accuracy: 0.8961\n",
      "Epoch 758/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2907 - accuracy: 0.8673 - val_loss: 0.2629 - val_accuracy: 0.8961\n",
      "Epoch 759/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.8673 - val_loss: 0.2637 - val_accuracy: 0.8994\n",
      "Epoch 760/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.8729 - val_loss: 0.2615 - val_accuracy: 0.8929\n",
      "Epoch 761/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.8659 - val_loss: 0.2619 - val_accuracy: 0.8961\n",
      "Epoch 762/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.8673 - val_loss: 0.2636 - val_accuracy: 0.8994\n",
      "Epoch 763/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2903 - accuracy: 0.8715 - val_loss: 0.2606 - val_accuracy: 0.8929\n",
      "Epoch 764/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2894 - accuracy: 0.8673 - val_loss: 0.2631 - val_accuracy: 0.8994\n",
      "Epoch 765/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8715 - val_loss: 0.2621 - val_accuracy: 0.8961\n",
      "Epoch 766/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8673 - val_loss: 0.2620 - val_accuracy: 0.8961\n",
      "Epoch 767/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8799 - val_loss: 0.2620 - val_accuracy: 0.8994\n",
      "Epoch 768/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.8687 - val_loss: 0.2600 - val_accuracy: 0.8929\n",
      "Epoch 769/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2900 - accuracy: 0.8687 - val_loss: 0.2623 - val_accuracy: 0.8994\n",
      "Epoch 770/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2892 - accuracy: 0.8687 - val_loss: 0.2610 - val_accuracy: 0.8961\n",
      "Epoch 771/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.8701 - val_loss: 0.2626 - val_accuracy: 0.9026\n",
      "Epoch 772/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2891 - accuracy: 0.8701 - val_loss: 0.2610 - val_accuracy: 0.8994\n",
      "Epoch 773/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2887 - accuracy: 0.8673 - val_loss: 0.2611 - val_accuracy: 0.8961\n",
      "Epoch 774/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2905 - accuracy: 0.8771 - val_loss: 0.2612 - val_accuracy: 0.8994\n",
      "Epoch 775/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 0.8673 - val_loss: 0.2595 - val_accuracy: 0.8961\n",
      "Epoch 776/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2888 - accuracy: 0.8631 - val_loss: 0.2597 - val_accuracy: 0.8961\n",
      "Epoch 777/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2890 - accuracy: 0.8729 - val_loss: 0.2617 - val_accuracy: 0.9026\n",
      "Epoch 778/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2888 - accuracy: 0.8659 - val_loss: 0.2589 - val_accuracy: 0.8961\n",
      "Epoch 779/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2881 - accuracy: 0.8743 - val_loss: 0.2607 - val_accuracy: 0.9026\n",
      "Epoch 780/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2888 - accuracy: 0.8715 - val_loss: 0.2587 - val_accuracy: 0.8961\n",
      "Epoch 781/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2883 - accuracy: 0.8785 - val_loss: 0.2618 - val_accuracy: 0.8994\n",
      "Epoch 782/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2880 - accuracy: 0.8701 - val_loss: 0.2580 - val_accuracy: 0.8929\n",
      "Epoch 783/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2880 - accuracy: 0.8757 - val_loss: 0.2597 - val_accuracy: 0.8994\n",
      "Epoch 784/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2879 - accuracy: 0.8687 - val_loss: 0.2586 - val_accuracy: 0.8994\n",
      "Epoch 785/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2871 - accuracy: 0.8743 - val_loss: 0.2591 - val_accuracy: 0.8994\n",
      "Epoch 786/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8729 - val_loss: 0.2596 - val_accuracy: 0.9026\n",
      "Epoch 787/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2871 - accuracy: 0.8771 - val_loss: 0.2591 - val_accuracy: 0.8994\n",
      "Epoch 788/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2867 - accuracy: 0.8771 - val_loss: 0.2588 - val_accuracy: 0.8994\n",
      "Epoch 789/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2866 - accuracy: 0.8673 - val_loss: 0.2579 - val_accuracy: 0.8994\n",
      "Epoch 790/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.8799 - val_loss: 0.2599 - val_accuracy: 0.9058\n",
      "Epoch 791/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2862 - accuracy: 0.8799 - val_loss: 0.2580 - val_accuracy: 0.8994\n",
      "Epoch 792/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2864 - accuracy: 0.8687 - val_loss: 0.2573 - val_accuracy: 0.8961\n",
      "Epoch 793/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2862 - accuracy: 0.8757 - val_loss: 0.2577 - val_accuracy: 0.8994\n",
      "Epoch 794/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 0.8645 - val_loss: 0.2572 - val_accuracy: 0.8994\n",
      "Epoch 795/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2856 - accuracy: 0.8771 - val_loss: 0.2587 - val_accuracy: 0.9026\n",
      "Epoch 796/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8799 - val_loss: 0.2593 - val_accuracy: 0.8994\n",
      "Epoch 797/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2861 - accuracy: 0.8729 - val_loss: 0.2563 - val_accuracy: 0.8994\n",
      "Epoch 798/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.8799 - val_loss: 0.2575 - val_accuracy: 0.8994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2852 - accuracy: 0.8771 - val_loss: 0.2573 - val_accuracy: 0.8994\n",
      "Epoch 800/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2856 - accuracy: 0.8743 - val_loss: 0.2573 - val_accuracy: 0.8994\n",
      "Epoch 801/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2853 - accuracy: 0.8771 - val_loss: 0.2574 - val_accuracy: 0.9026\n",
      "Epoch 802/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2854 - accuracy: 0.8813 - val_loss: 0.2572 - val_accuracy: 0.9026\n",
      "Epoch 803/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2850 - accuracy: 0.8771 - val_loss: 0.2553 - val_accuracy: 0.8994\n",
      "Epoch 804/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2849 - accuracy: 0.8757 - val_loss: 0.2565 - val_accuracy: 0.8994\n",
      "Epoch 805/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2852 - accuracy: 0.8757 - val_loss: 0.2551 - val_accuracy: 0.8994\n",
      "Epoch 806/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2844 - accuracy: 0.8701 - val_loss: 0.2559 - val_accuracy: 0.8994\n",
      "Epoch 807/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2845 - accuracy: 0.8757 - val_loss: 0.2565 - val_accuracy: 0.9026\n",
      "Epoch 808/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2849 - accuracy: 0.8757 - val_loss: 0.2564 - val_accuracy: 0.9026\n",
      "Epoch 809/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2849 - accuracy: 0.8799 - val_loss: 0.2581 - val_accuracy: 0.8994\n",
      "Epoch 810/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2847 - accuracy: 0.8673 - val_loss: 0.2542 - val_accuracy: 0.8929\n",
      "Epoch 811/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2840 - accuracy: 0.8757 - val_loss: 0.2561 - val_accuracy: 0.9026\n",
      "Epoch 812/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2847 - accuracy: 0.8701 - val_loss: 0.2552 - val_accuracy: 0.8994\n",
      "Epoch 813/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.8757 - val_loss: 0.2549 - val_accuracy: 0.8994\n",
      "Epoch 814/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2836 - accuracy: 0.8757 - val_loss: 0.2564 - val_accuracy: 0.8994\n",
      "Epoch 815/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.8813 - val_loss: 0.2552 - val_accuracy: 0.9026\n",
      "Epoch 816/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8757 - val_loss: 0.2545 - val_accuracy: 0.8994\n",
      "Epoch 817/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8785 - val_loss: 0.2544 - val_accuracy: 0.8994\n",
      "Epoch 818/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2834 - accuracy: 0.8729 - val_loss: 0.2534 - val_accuracy: 0.8994\n",
      "Epoch 819/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2835 - accuracy: 0.8799 - val_loss: 0.2556 - val_accuracy: 0.8994\n",
      "Epoch 820/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2827 - accuracy: 0.8785 - val_loss: 0.2534 - val_accuracy: 0.8961\n",
      "Epoch 821/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.8701 - val_loss: 0.2534 - val_accuracy: 0.8994\n",
      "Epoch 822/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2844 - accuracy: 0.8813 - val_loss: 0.2566 - val_accuracy: 0.8994\n",
      "Epoch 823/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2830 - accuracy: 0.8729 - val_loss: 0.2528 - val_accuracy: 0.8961\n",
      "Epoch 824/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2827 - accuracy: 0.8743 - val_loss: 0.2541 - val_accuracy: 0.8994\n",
      "Epoch 825/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2822 - accuracy: 0.8771 - val_loss: 0.2535 - val_accuracy: 0.8961\n",
      "Epoch 826/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2821 - accuracy: 0.8757 - val_loss: 0.2532 - val_accuracy: 0.8961\n",
      "Epoch 827/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2824 - accuracy: 0.8771 - val_loss: 0.2531 - val_accuracy: 0.8961\n",
      "Epoch 828/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2817 - accuracy: 0.8729 - val_loss: 0.2547 - val_accuracy: 0.8994\n",
      "Epoch 829/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2823 - accuracy: 0.8757 - val_loss: 0.2537 - val_accuracy: 0.8961\n",
      "Epoch 830/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2818 - accuracy: 0.8799 - val_loss: 0.2534 - val_accuracy: 0.8929\n",
      "Epoch 831/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.8729 - val_loss: 0.2524 - val_accuracy: 0.8961\n",
      "Epoch 832/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2822 - accuracy: 0.8785 - val_loss: 0.2537 - val_accuracy: 0.8961\n",
      "Epoch 833/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2816 - accuracy: 0.8729 - val_loss: 0.2519 - val_accuracy: 0.8961\n",
      "Epoch 834/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.8715 - val_loss: 0.2535 - val_accuracy: 0.8961\n",
      "Epoch 835/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.8729 - val_loss: 0.2520 - val_accuracy: 0.8961\n",
      "Epoch 836/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2810 - accuracy: 0.8729 - val_loss: 0.2518 - val_accuracy: 0.8961\n",
      "Epoch 837/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2808 - accuracy: 0.8701 - val_loss: 0.2528 - val_accuracy: 0.8994\n",
      "Epoch 838/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2811 - accuracy: 0.8813 - val_loss: 0.2526 - val_accuracy: 0.8961\n",
      "Epoch 839/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2818 - accuracy: 0.8715 - val_loss: 0.2515 - val_accuracy: 0.8961\n",
      "Epoch 840/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2813 - accuracy: 0.8799 - val_loss: 0.2532 - val_accuracy: 0.8961\n",
      "Epoch 841/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.8729 - val_loss: 0.2510 - val_accuracy: 0.8961\n",
      "Epoch 842/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2805 - accuracy: 0.8743 - val_loss: 0.2521 - val_accuracy: 0.8929\n",
      "Epoch 843/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2801 - accuracy: 0.8715 - val_loss: 0.2507 - val_accuracy: 0.8961\n",
      "Epoch 844/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2803 - accuracy: 0.8715 - val_loss: 0.2518 - val_accuracy: 0.8929\n",
      "Epoch 845/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2804 - accuracy: 0.8729 - val_loss: 0.2507 - val_accuracy: 0.8961\n",
      "Epoch 846/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2800 - accuracy: 0.8715 - val_loss: 0.2516 - val_accuracy: 0.8929\n",
      "Epoch 847/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2795 - accuracy: 0.8715 - val_loss: 0.2503 - val_accuracy: 0.8961\n",
      "Epoch 848/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2795 - accuracy: 0.8715 - val_loss: 0.2507 - val_accuracy: 0.8896\n",
      "Epoch 849/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2795 - accuracy: 0.8743 - val_loss: 0.2501 - val_accuracy: 0.8961\n",
      "Epoch 850/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2793 - accuracy: 0.8729 - val_loss: 0.2500 - val_accuracy: 0.8961\n",
      "Epoch 851/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2792 - accuracy: 0.8743 - val_loss: 0.2515 - val_accuracy: 0.8961\n",
      "Epoch 852/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2792 - accuracy: 0.8785 - val_loss: 0.2515 - val_accuracy: 0.8961\n",
      "Epoch 853/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2789 - accuracy: 0.8701 - val_loss: 0.2491 - val_accuracy: 0.8961\n",
      "Epoch 854/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2789 - accuracy: 0.8729 - val_loss: 0.2498 - val_accuracy: 0.8896\n",
      "Epoch 855/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2787 - accuracy: 0.8771 - val_loss: 0.2520 - val_accuracy: 0.8961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2789 - accuracy: 0.8757 - val_loss: 0.2504 - val_accuracy: 0.8929\n",
      "Epoch 857/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2787 - accuracy: 0.8715 - val_loss: 0.2488 - val_accuracy: 0.8961\n",
      "Epoch 858/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2788 - accuracy: 0.8771 - val_loss: 0.2518 - val_accuracy: 0.8961\n",
      "Epoch 859/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2787 - accuracy: 0.8785 - val_loss: 0.2505 - val_accuracy: 0.8961\n",
      "Epoch 860/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.8701 - val_loss: 0.2482 - val_accuracy: 0.8961\n",
      "Epoch 861/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2779 - accuracy: 0.8715 - val_loss: 0.2506 - val_accuracy: 0.8961\n",
      "Epoch 862/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2787 - accuracy: 0.8771 - val_loss: 0.2489 - val_accuracy: 0.8896\n",
      "Epoch 863/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2778 - accuracy: 0.8715 - val_loss: 0.2482 - val_accuracy: 0.8961\n",
      "Epoch 864/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.8757 - val_loss: 0.2507 - val_accuracy: 0.8961\n",
      "Epoch 865/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2772 - accuracy: 0.8757 - val_loss: 0.2486 - val_accuracy: 0.8896\n",
      "Epoch 866/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2785 - accuracy: 0.8687 - val_loss: 0.2472 - val_accuracy: 0.8929\n",
      "Epoch 867/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.8729 - val_loss: 0.2493 - val_accuracy: 0.8929\n",
      "Epoch 868/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2774 - accuracy: 0.8743 - val_loss: 0.2488 - val_accuracy: 0.8929\n",
      "Epoch 869/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.8701 - val_loss: 0.2485 - val_accuracy: 0.8896\n",
      "Epoch 870/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2774 - accuracy: 0.8701 - val_loss: 0.2486 - val_accuracy: 0.8929\n",
      "Epoch 871/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2775 - accuracy: 0.8715 - val_loss: 0.2472 - val_accuracy: 0.8961\n",
      "Epoch 872/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2785 - accuracy: 0.8757 - val_loss: 0.2481 - val_accuracy: 0.8929\n",
      "Epoch 873/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2771 - accuracy: 0.8785 - val_loss: 0.2475 - val_accuracy: 0.8896\n",
      "Epoch 874/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2767 - accuracy: 0.8701 - val_loss: 0.2473 - val_accuracy: 0.8896\n",
      "Epoch 875/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2766 - accuracy: 0.8701 - val_loss: 0.2468 - val_accuracy: 0.8961\n",
      "Epoch 876/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2768 - accuracy: 0.8715 - val_loss: 0.2481 - val_accuracy: 0.9026\n",
      "Epoch 877/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2761 - accuracy: 0.8701 - val_loss: 0.2468 - val_accuracy: 0.8896\n",
      "Epoch 878/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2765 - accuracy: 0.8743 - val_loss: 0.2477 - val_accuracy: 0.9026\n",
      "Epoch 879/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2765 - accuracy: 0.8771 - val_loss: 0.2474 - val_accuracy: 0.8929\n",
      "Epoch 880/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2763 - accuracy: 0.8701 - val_loss: 0.2459 - val_accuracy: 0.8961\n",
      "Epoch 881/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2757 - accuracy: 0.8743 - val_loss: 0.2480 - val_accuracy: 0.9058\n",
      "Epoch 882/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2758 - accuracy: 0.8785 - val_loss: 0.2479 - val_accuracy: 0.9058\n",
      "Epoch 883/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2768 - accuracy: 0.8729 - val_loss: 0.2457 - val_accuracy: 0.8896\n",
      "Epoch 884/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2757 - accuracy: 0.8771 - val_loss: 0.2489 - val_accuracy: 0.9058\n",
      "Epoch 885/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2759 - accuracy: 0.8785 - val_loss: 0.2473 - val_accuracy: 0.9058\n",
      "Epoch 886/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.8729 - val_loss: 0.2452 - val_accuracy: 0.8961\n",
      "Epoch 887/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2753 - accuracy: 0.8729 - val_loss: 0.2462 - val_accuracy: 0.8929\n",
      "Epoch 888/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2751 - accuracy: 0.8757 - val_loss: 0.2474 - val_accuracy: 0.9058\n",
      "Epoch 889/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2755 - accuracy: 0.8757 - val_loss: 0.2470 - val_accuracy: 0.9058\n",
      "Epoch 890/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2760 - accuracy: 0.8785 - val_loss: 0.2479 - val_accuracy: 0.9058\n",
      "Epoch 891/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2765 - accuracy: 0.8743 - val_loss: 0.2448 - val_accuracy: 0.8961\n",
      "Epoch 892/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2758 - accuracy: 0.8771 - val_loss: 0.2472 - val_accuracy: 0.9058\n",
      "Epoch 893/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2746 - accuracy: 0.8771 - val_loss: 0.2450 - val_accuracy: 0.8896\n",
      "Epoch 894/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2753 - accuracy: 0.8729 - val_loss: 0.2450 - val_accuracy: 0.8994\n",
      "Epoch 895/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.8757 - val_loss: 0.2437 - val_accuracy: 0.9026\n",
      "Epoch 896/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2744 - accuracy: 0.8757 - val_loss: 0.2462 - val_accuracy: 0.9026\n",
      "Epoch 897/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2740 - accuracy: 0.8743 - val_loss: 0.2453 - val_accuracy: 0.9026\n",
      "Epoch 898/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2752 - accuracy: 0.8757 - val_loss: 0.2445 - val_accuracy: 0.8994\n",
      "Epoch 899/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2744 - accuracy: 0.8743 - val_loss: 0.2464 - val_accuracy: 0.9058\n",
      "Epoch 900/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.8757 - val_loss: 0.2447 - val_accuracy: 0.9091\n",
      "Epoch 901/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2737 - accuracy: 0.8729 - val_loss: 0.2442 - val_accuracy: 0.9058\n",
      "Epoch 902/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2740 - accuracy: 0.8757 - val_loss: 0.2460 - val_accuracy: 0.9058\n",
      "Epoch 903/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2740 - accuracy: 0.8785 - val_loss: 0.2449 - val_accuracy: 0.9091\n",
      "Epoch 904/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2736 - accuracy: 0.8743 - val_loss: 0.2440 - val_accuracy: 0.9058\n",
      "Epoch 905/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.8729 - val_loss: 0.2435 - val_accuracy: 0.8961\n",
      "Epoch 906/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2744 - accuracy: 0.8785 - val_loss: 0.2442 - val_accuracy: 0.9058\n",
      "Epoch 907/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2744 - accuracy: 0.8757 - val_loss: 0.2447 - val_accuracy: 0.9123\n",
      "Epoch 908/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2730 - accuracy: 0.8771 - val_loss: 0.2438 - val_accuracy: 0.9091\n",
      "Epoch 909/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2732 - accuracy: 0.8729 - val_loss: 0.2438 - val_accuracy: 0.9058\n",
      "Epoch 910/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2736 - accuracy: 0.8785 - val_loss: 0.2448 - val_accuracy: 0.9123\n",
      "Epoch 911/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2732 - accuracy: 0.8785 - val_loss: 0.2434 - val_accuracy: 0.9058\n",
      "Epoch 912/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2730 - accuracy: 0.8771 - val_loss: 0.2444 - val_accuracy: 0.9123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2731 - accuracy: 0.8813 - val_loss: 0.2448 - val_accuracy: 0.9123\n",
      "Epoch 914/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2729 - accuracy: 0.8729 - val_loss: 0.2426 - val_accuracy: 0.9058\n",
      "Epoch 915/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2725 - accuracy: 0.8785 - val_loss: 0.2440 - val_accuracy: 0.9123\n",
      "Epoch 916/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2722 - accuracy: 0.8785 - val_loss: 0.2440 - val_accuracy: 0.9123\n",
      "Epoch 917/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.8771 - val_loss: 0.2427 - val_accuracy: 0.9058\n",
      "Epoch 918/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2731 - accuracy: 0.8757 - val_loss: 0.2425 - val_accuracy: 0.9058\n",
      "Epoch 919/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2745 - accuracy: 0.8687 - val_loss: 0.2454 - val_accuracy: 0.9123\n",
      "Epoch 920/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2724 - accuracy: 0.8757 - val_loss: 0.2427 - val_accuracy: 0.9058\n",
      "Epoch 921/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2728 - accuracy: 0.8785 - val_loss: 0.2443 - val_accuracy: 0.9123\n",
      "Epoch 922/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2716 - accuracy: 0.8785 - val_loss: 0.2428 - val_accuracy: 0.9091\n",
      "Epoch 923/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2726 - accuracy: 0.8757 - val_loss: 0.2421 - val_accuracy: 0.9058\n",
      "Epoch 924/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.8743 - val_loss: 0.2421 - val_accuracy: 0.9058\n",
      "Epoch 925/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2724 - accuracy: 0.8813 - val_loss: 0.2442 - val_accuracy: 0.9123\n",
      "Epoch 926/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2715 - accuracy: 0.8771 - val_loss: 0.2415 - val_accuracy: 0.9058\n",
      "Epoch 927/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2724 - accuracy: 0.8799 - val_loss: 0.2441 - val_accuracy: 0.9123\n",
      "Epoch 928/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2718 - accuracy: 0.8757 - val_loss: 0.2420 - val_accuracy: 0.9091\n",
      "Epoch 929/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2714 - accuracy: 0.8757 - val_loss: 0.2416 - val_accuracy: 0.9091\n",
      "Epoch 930/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2707 - accuracy: 0.8799 - val_loss: 0.2432 - val_accuracy: 0.9123\n",
      "Epoch 931/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2716 - accuracy: 0.8813 - val_loss: 0.2422 - val_accuracy: 0.9091\n",
      "Epoch 932/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2714 - accuracy: 0.8771 - val_loss: 0.2413 - val_accuracy: 0.9058\n",
      "Epoch 933/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2707 - accuracy: 0.8743 - val_loss: 0.2417 - val_accuracy: 0.9091\n",
      "Epoch 934/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.8799 - val_loss: 0.2422 - val_accuracy: 0.9091\n",
      "Epoch 935/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2709 - accuracy: 0.8785 - val_loss: 0.2417 - val_accuracy: 0.9091\n",
      "Epoch 936/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2708 - accuracy: 0.8757 - val_loss: 0.2419 - val_accuracy: 0.9091\n",
      "Epoch 937/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2703 - accuracy: 0.8771 - val_loss: 0.2412 - val_accuracy: 0.9058\n",
      "Epoch 938/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2705 - accuracy: 0.8785 - val_loss: 0.2423 - val_accuracy: 0.9123\n",
      "Epoch 939/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2700 - accuracy: 0.8785 - val_loss: 0.2405 - val_accuracy: 0.9058\n",
      "Epoch 940/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2701 - accuracy: 0.8743 - val_loss: 0.2421 - val_accuracy: 0.9123\n",
      "Epoch 941/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2699 - accuracy: 0.8785 - val_loss: 0.2412 - val_accuracy: 0.9091\n",
      "Epoch 942/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2705 - accuracy: 0.8813 - val_loss: 0.2420 - val_accuracy: 0.9123\n",
      "Epoch 943/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.8785 - val_loss: 0.2399 - val_accuracy: 0.9058\n",
      "Epoch 944/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2696 - accuracy: 0.8771 - val_loss: 0.2419 - val_accuracy: 0.9123\n",
      "Epoch 945/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2699 - accuracy: 0.8785 - val_loss: 0.2412 - val_accuracy: 0.9091\n",
      "Epoch 946/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2696 - accuracy: 0.8813 - val_loss: 0.2413 - val_accuracy: 0.9123\n",
      "Epoch 947/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2695 - accuracy: 0.8799 - val_loss: 0.2406 - val_accuracy: 0.9091\n",
      "Epoch 948/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2693 - accuracy: 0.8771 - val_loss: 0.2410 - val_accuracy: 0.9123\n",
      "Epoch 949/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2701 - accuracy: 0.8813 - val_loss: 0.2408 - val_accuracy: 0.9091\n",
      "Epoch 950/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2693 - accuracy: 0.8785 - val_loss: 0.2413 - val_accuracy: 0.9123\n",
      "Epoch 951/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2693 - accuracy: 0.8771 - val_loss: 0.2399 - val_accuracy: 0.9058\n",
      "Epoch 952/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2687 - accuracy: 0.8785 - val_loss: 0.2415 - val_accuracy: 0.9123\n",
      "Epoch 953/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2691 - accuracy: 0.8813 - val_loss: 0.2426 - val_accuracy: 0.9123\n",
      "Epoch 954/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2692 - accuracy: 0.8785 - val_loss: 0.2408 - val_accuracy: 0.9123\n",
      "Epoch 955/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2683 - accuracy: 0.8813 - val_loss: 0.2413 - val_accuracy: 0.9123\n",
      "Epoch 956/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.8799 - val_loss: 0.2406 - val_accuracy: 0.9123\n",
      "Epoch 957/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2683 - accuracy: 0.8771 - val_loss: 0.2403 - val_accuracy: 0.9091\n",
      "Epoch 958/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2682 - accuracy: 0.8785 - val_loss: 0.2415 - val_accuracy: 0.9123\n",
      "Epoch 959/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2705 - accuracy: 0.8813 - val_loss: 0.2436 - val_accuracy: 0.9123\n",
      "Epoch 960/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.8757 - val_loss: 0.2387 - val_accuracy: 0.8994\n",
      "Epoch 961/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2688 - accuracy: 0.8799 - val_loss: 0.2399 - val_accuracy: 0.9091\n",
      "Epoch 962/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2678 - accuracy: 0.8785 - val_loss: 0.2390 - val_accuracy: 0.9058\n",
      "Epoch 963/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2684 - accuracy: 0.8799 - val_loss: 0.2398 - val_accuracy: 0.9091\n",
      "Epoch 964/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2684 - accuracy: 0.8799 - val_loss: 0.2389 - val_accuracy: 0.9058\n",
      "Epoch 965/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.8771 - val_loss: 0.2396 - val_accuracy: 0.9091\n",
      "Epoch 966/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2677 - accuracy: 0.8799 - val_loss: 0.2387 - val_accuracy: 0.9058\n",
      "Epoch 967/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.8785 - val_loss: 0.2393 - val_accuracy: 0.9091\n",
      "Epoch 968/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.8813 - val_loss: 0.2407 - val_accuracy: 0.9123\n",
      "Epoch 969/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8813 - val_loss: 0.2387 - val_accuracy: 0.9058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.8813 - val_loss: 0.2385 - val_accuracy: 0.9058\n",
      "Epoch 971/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2679 - accuracy: 0.8785 - val_loss: 0.2394 - val_accuracy: 0.9091\n",
      "Epoch 972/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2682 - accuracy: 0.8743 - val_loss: 0.2383 - val_accuracy: 0.9058\n",
      "Epoch 973/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.8813 - val_loss: 0.2416 - val_accuracy: 0.9123\n",
      "Epoch 974/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2674 - accuracy: 0.8813 - val_loss: 0.2410 - val_accuracy: 0.9123\n",
      "Epoch 975/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.8799 - val_loss: 0.2377 - val_accuracy: 0.9058\n",
      "Epoch 976/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2669 - accuracy: 0.8771 - val_loss: 0.2383 - val_accuracy: 0.9058\n",
      "Epoch 977/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.8813 - val_loss: 0.2388 - val_accuracy: 0.9091\n",
      "Epoch 978/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.8841 - val_loss: 0.2391 - val_accuracy: 0.9123\n",
      "Epoch 979/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2668 - accuracy: 0.8841 - val_loss: 0.2385 - val_accuracy: 0.9091\n",
      "Epoch 980/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.8785 - val_loss: 0.2384 - val_accuracy: 0.9058\n",
      "Epoch 981/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.8841 - val_loss: 0.2385 - val_accuracy: 0.9091\n",
      "Epoch 982/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2671 - accuracy: 0.8757 - val_loss: 0.2377 - val_accuracy: 0.9058\n",
      "Epoch 983/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.8841 - val_loss: 0.2390 - val_accuracy: 0.9123\n",
      "Epoch 984/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2661 - accuracy: 0.8841 - val_loss: 0.2375 - val_accuracy: 0.9058\n",
      "Epoch 985/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.8785 - val_loss: 0.2387 - val_accuracy: 0.9123\n",
      "Epoch 986/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2654 - accuracy: 0.8785 - val_loss: 0.2369 - val_accuracy: 0.9058\n",
      "Epoch 987/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.8771 - val_loss: 0.2382 - val_accuracy: 0.9058\n",
      "Epoch 988/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.8771 - val_loss: 0.2371 - val_accuracy: 0.9058\n",
      "Epoch 989/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2660 - accuracy: 0.8841 - val_loss: 0.2384 - val_accuracy: 0.9123\n",
      "Epoch 990/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2655 - accuracy: 0.8771 - val_loss: 0.2378 - val_accuracy: 0.9058\n",
      "Epoch 991/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2657 - accuracy: 0.8771 - val_loss: 0.2386 - val_accuracy: 0.9123\n",
      "Epoch 992/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.8827 - val_loss: 0.2381 - val_accuracy: 0.9091\n",
      "Epoch 993/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2652 - accuracy: 0.8799 - val_loss: 0.2366 - val_accuracy: 0.9058\n",
      "Epoch 994/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.8771 - val_loss: 0.2368 - val_accuracy: 0.9058\n",
      "Epoch 995/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.8771 - val_loss: 0.2376 - val_accuracy: 0.9058\n",
      "Epoch 996/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.8813 - val_loss: 0.2379 - val_accuracy: 0.9091\n",
      "Epoch 997/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2647 - accuracy: 0.8771 - val_loss: 0.2367 - val_accuracy: 0.9058\n",
      "Epoch 998/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.8757 - val_loss: 0.2360 - val_accuracy: 0.9058\n",
      "Epoch 999/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.8813 - val_loss: 0.2377 - val_accuracy: 0.9091\n",
      "Epoch 1000/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.8785 - val_loss: 0.2367 - val_accuracy: 0.9058\n",
      "Epoch 1001/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2646 - accuracy: 0.8813 - val_loss: 0.2372 - val_accuracy: 0.9091\n",
      "Epoch 1002/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.8771 - val_loss: 0.2355 - val_accuracy: 0.9058\n",
      "Epoch 1003/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.8771 - val_loss: 0.2384 - val_accuracy: 0.9123\n",
      "Epoch 1004/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2642 - accuracy: 0.8827 - val_loss: 0.2366 - val_accuracy: 0.9091\n",
      "Epoch 1005/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.8827 - val_loss: 0.2355 - val_accuracy: 0.9058\n",
      "Epoch 1006/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.8827 - val_loss: 0.2367 - val_accuracy: 0.9091\n",
      "Epoch 1007/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.8827 - val_loss: 0.2355 - val_accuracy: 0.9058\n",
      "Epoch 1008/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.8771 - val_loss: 0.2357 - val_accuracy: 0.9058\n",
      "Epoch 1009/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.8813 - val_loss: 0.2367 - val_accuracy: 0.9091\n",
      "Epoch 1010/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.8785 - val_loss: 0.2360 - val_accuracy: 0.9091\n",
      "Epoch 1011/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.8757 - val_loss: 0.2374 - val_accuracy: 0.9123\n",
      "Epoch 1012/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.8855 - val_loss: 0.2359 - val_accuracy: 0.9091\n",
      "Epoch 1013/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.8785 - val_loss: 0.2359 - val_accuracy: 0.9058\n",
      "Epoch 1014/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.8771 - val_loss: 0.2351 - val_accuracy: 0.9058\n",
      "Epoch 1015/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.8771 - val_loss: 0.2361 - val_accuracy: 0.9058\n",
      "Epoch 1016/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.8855 - val_loss: 0.2365 - val_accuracy: 0.9091\n",
      "Epoch 1017/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2629 - accuracy: 0.8827 - val_loss: 0.2356 - val_accuracy: 0.9058\n",
      "Epoch 1018/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.8771 - val_loss: 0.2350 - val_accuracy: 0.9058\n",
      "Epoch 1019/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.8757 - val_loss: 0.2356 - val_accuracy: 0.9058\n",
      "Epoch 1020/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.8813 - val_loss: 0.2352 - val_accuracy: 0.9058\n",
      "Epoch 1021/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.8771 - val_loss: 0.2361 - val_accuracy: 0.9091\n",
      "Epoch 1022/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.8771 - val_loss: 0.2349 - val_accuracy: 0.9058\n",
      "Epoch 1023/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.8827 - val_loss: 0.2369 - val_accuracy: 0.9123\n",
      "Epoch 1024/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.8855 - val_loss: 0.2346 - val_accuracy: 0.9058\n",
      "Epoch 1025/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.8785 - val_loss: 0.2350 - val_accuracy: 0.9058\n",
      "Epoch 1026/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.8813 - val_loss: 0.2355 - val_accuracy: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2619 - accuracy: 0.8841 - val_loss: 0.2347 - val_accuracy: 0.9058\n",
      "Epoch 1028/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.8799 - val_loss: 0.2336 - val_accuracy: 0.8994\n",
      "Epoch 1029/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2619 - accuracy: 0.8785 - val_loss: 0.2365 - val_accuracy: 0.9123\n",
      "Epoch 1030/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2620 - accuracy: 0.8827 - val_loss: 0.2340 - val_accuracy: 0.9091\n",
      "Epoch 1031/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2626 - accuracy: 0.8841 - val_loss: 0.2351 - val_accuracy: 0.9091\n",
      "Epoch 1032/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2622 - accuracy: 0.8785 - val_loss: 0.2351 - val_accuracy: 0.9091\n",
      "Epoch 1033/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.8813 - val_loss: 0.2360 - val_accuracy: 0.9123\n",
      "Epoch 1034/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2614 - accuracy: 0.8827 - val_loss: 0.2349 - val_accuracy: 0.9091\n",
      "Epoch 1035/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8813 - val_loss: 0.2346 - val_accuracy: 0.9091\n",
      "Epoch 1036/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.8827 - val_loss: 0.2354 - val_accuracy: 0.9123\n",
      "Epoch 1037/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2617 - accuracy: 0.8757 - val_loss: 0.2342 - val_accuracy: 0.9058\n",
      "Epoch 1038/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2607 - accuracy: 0.8855 - val_loss: 0.2353 - val_accuracy: 0.9123\n",
      "Epoch 1039/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2616 - accuracy: 0.8869 - val_loss: 0.2340 - val_accuracy: 0.9091\n",
      "Epoch 1040/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2613 - accuracy: 0.8799 - val_loss: 0.2343 - val_accuracy: 0.9091\n",
      "Epoch 1041/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2607 - accuracy: 0.8813 - val_loss: 0.2339 - val_accuracy: 0.9091\n",
      "Epoch 1042/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2606 - accuracy: 0.8799 - val_loss: 0.2336 - val_accuracy: 0.9058\n",
      "Epoch 1043/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2605 - accuracy: 0.8799 - val_loss: 0.2336 - val_accuracy: 0.9091\n",
      "Epoch 1044/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2605 - accuracy: 0.8827 - val_loss: 0.2343 - val_accuracy: 0.9091\n",
      "Epoch 1045/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.8813 - val_loss: 0.2334 - val_accuracy: 0.9156\n",
      "Epoch 1046/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2609 - accuracy: 0.8841 - val_loss: 0.2338 - val_accuracy: 0.9091\n",
      "Epoch 1047/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2613 - accuracy: 0.8855 - val_loss: 0.2325 - val_accuracy: 0.9123\n",
      "Epoch 1048/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2607 - accuracy: 0.8813 - val_loss: 0.2345 - val_accuracy: 0.9123\n",
      "Epoch 1049/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.8813 - val_loss: 0.2335 - val_accuracy: 0.9058\n",
      "Epoch 1050/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.8785 - val_loss: 0.2346 - val_accuracy: 0.9091\n",
      "Epoch 1051/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.8799 - val_loss: 0.2331 - val_accuracy: 0.9058\n",
      "Epoch 1052/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.8855 - val_loss: 0.2347 - val_accuracy: 0.9123\n",
      "Epoch 1053/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2601 - accuracy: 0.8813 - val_loss: 0.2325 - val_accuracy: 0.9058\n",
      "Epoch 1054/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2599 - accuracy: 0.8785 - val_loss: 0.2336 - val_accuracy: 0.9091\n",
      "Epoch 1055/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2605 - accuracy: 0.8841 - val_loss: 0.2323 - val_accuracy: 0.9026\n",
      "Epoch 1056/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.8813 - val_loss: 0.2336 - val_accuracy: 0.9091\n",
      "Epoch 1057/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2600 - accuracy: 0.8771 - val_loss: 0.2332 - val_accuracy: 0.9058\n",
      "Epoch 1058/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.8785 - val_loss: 0.2322 - val_accuracy: 0.9091\n",
      "Epoch 1059/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.8771 - val_loss: 0.2332 - val_accuracy: 0.9091\n",
      "Epoch 1060/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2606 - accuracy: 0.8953 - val_loss: 0.2329 - val_accuracy: 0.9058\n",
      "Epoch 1061/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2591 - accuracy: 0.8827 - val_loss: 0.2315 - val_accuracy: 0.9091\n",
      "Epoch 1062/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2591 - accuracy: 0.8757 - val_loss: 0.2325 - val_accuracy: 0.9058\n",
      "Epoch 1063/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2592 - accuracy: 0.8911 - val_loss: 0.2337 - val_accuracy: 0.9091\n",
      "Epoch 1064/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.8799 - val_loss: 0.2315 - val_accuracy: 0.8994\n",
      "Epoch 1065/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2610 - accuracy: 0.8897 - val_loss: 0.2342 - val_accuracy: 0.9123\n",
      "Epoch 1066/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2586 - accuracy: 0.8785 - val_loss: 0.2318 - val_accuracy: 0.9026\n",
      "Epoch 1067/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2592 - accuracy: 0.8827 - val_loss: 0.2318 - val_accuracy: 0.9026\n",
      "Epoch 1068/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2586 - accuracy: 0.8757 - val_loss: 0.2332 - val_accuracy: 0.9091\n",
      "Epoch 1069/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2584 - accuracy: 0.8757 - val_loss: 0.2324 - val_accuracy: 0.9026\n",
      "Epoch 1070/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2582 - accuracy: 0.8799 - val_loss: 0.2313 - val_accuracy: 0.9091\n",
      "Epoch 1071/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2587 - accuracy: 0.8813 - val_loss: 0.2327 - val_accuracy: 0.9058\n",
      "Epoch 1072/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.8743 - val_loss: 0.2319 - val_accuracy: 0.8994\n",
      "Epoch 1073/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2587 - accuracy: 0.8869 - val_loss: 0.2319 - val_accuracy: 0.9026\n",
      "Epoch 1074/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.8771 - val_loss: 0.2322 - val_accuracy: 0.8994\n",
      "Epoch 1075/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.8743 - val_loss: 0.2315 - val_accuracy: 0.9026\n",
      "Epoch 1076/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2573 - accuracy: 0.8757 - val_loss: 0.2322 - val_accuracy: 0.8994\n",
      "Epoch 1077/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2586 - accuracy: 0.8883 - val_loss: 0.2327 - val_accuracy: 0.9091\n",
      "Epoch 1078/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2593 - accuracy: 0.8841 - val_loss: 0.2310 - val_accuracy: 0.9091\n",
      "Epoch 1079/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2575 - accuracy: 0.8897 - val_loss: 0.2332 - val_accuracy: 0.9156\n",
      "Epoch 1080/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2584 - accuracy: 0.8855 - val_loss: 0.2311 - val_accuracy: 0.9091\n",
      "Epoch 1081/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2574 - accuracy: 0.8771 - val_loss: 0.2319 - val_accuracy: 0.9091\n",
      "Epoch 1082/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.8855 - val_loss: 0.2327 - val_accuracy: 0.9123\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2573 - accuracy: 0.8785 - val_loss: 0.2319 - val_accuracy: 0.9026\n",
      "Epoch 1084/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.8799 - val_loss: 0.2308 - val_accuracy: 0.9123\n",
      "Epoch 1085/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2567 - accuracy: 0.8799 - val_loss: 0.2328 - val_accuracy: 0.9156\n",
      "Epoch 1086/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.8785 - val_loss: 0.2309 - val_accuracy: 0.9091\n",
      "Epoch 1087/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.8785 - val_loss: 0.2322 - val_accuracy: 0.9058\n",
      "Epoch 1088/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2572 - accuracy: 0.8813 - val_loss: 0.2312 - val_accuracy: 0.9058\n",
      "Epoch 1089/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.8785 - val_loss: 0.2307 - val_accuracy: 0.9026\n",
      "Epoch 1090/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.8785 - val_loss: 0.2304 - val_accuracy: 0.9026\n",
      "Epoch 1091/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2567 - accuracy: 0.8841 - val_loss: 0.2303 - val_accuracy: 0.9026\n",
      "Epoch 1092/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2566 - accuracy: 0.8855 - val_loss: 0.2321 - val_accuracy: 0.9123\n",
      "Epoch 1093/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2583 - accuracy: 0.8799 - val_loss: 0.2308 - val_accuracy: 0.9091\n",
      "Epoch 1094/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2563 - accuracy: 0.8883 - val_loss: 0.2320 - val_accuracy: 0.9123\n",
      "Epoch 1095/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.8911 - val_loss: 0.2308 - val_accuracy: 0.9123\n",
      "Epoch 1096/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.8841 - val_loss: 0.2317 - val_accuracy: 0.9123\n",
      "Epoch 1097/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2559 - accuracy: 0.8953 - val_loss: 0.2323 - val_accuracy: 0.9123\n",
      "Epoch 1098/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.8855 - val_loss: 0.2308 - val_accuracy: 0.9091\n",
      "Epoch 1099/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2574 - accuracy: 0.8994 - val_loss: 0.2319 - val_accuracy: 0.9221\n",
      "Epoch 1100/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2557 - accuracy: 0.8897 - val_loss: 0.2299 - val_accuracy: 0.9123\n",
      "Epoch 1101/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2559 - accuracy: 0.8883 - val_loss: 0.2314 - val_accuracy: 0.9221\n",
      "Epoch 1102/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.8994 - val_loss: 0.2315 - val_accuracy: 0.9156\n",
      "Epoch 1103/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2555 - accuracy: 0.8855 - val_loss: 0.2293 - val_accuracy: 0.9123\n",
      "Epoch 1104/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.8925 - val_loss: 0.2306 - val_accuracy: 0.9156\n",
      "Epoch 1105/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2554 - accuracy: 0.8841 - val_loss: 0.2304 - val_accuracy: 0.9156\n",
      "Epoch 1106/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2553 - accuracy: 0.8869 - val_loss: 0.2302 - val_accuracy: 0.9123\n",
      "Epoch 1107/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2557 - accuracy: 0.9008 - val_loss: 0.2334 - val_accuracy: 0.9156\n",
      "Epoch 1108/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.8897 - val_loss: 0.2291 - val_accuracy: 0.9123\n",
      "Epoch 1109/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2559 - accuracy: 0.8799 - val_loss: 0.2300 - val_accuracy: 0.9091\n",
      "Epoch 1110/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2549 - accuracy: 0.8855 - val_loss: 0.2310 - val_accuracy: 0.9156\n",
      "Epoch 1111/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2566 - accuracy: 0.8827 - val_loss: 0.2294 - val_accuracy: 0.9123\n",
      "Epoch 1112/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.8813 - val_loss: 0.2310 - val_accuracy: 0.9156\n",
      "Epoch 1113/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2559 - accuracy: 0.9022 - val_loss: 0.2316 - val_accuracy: 0.9188\n",
      "Epoch 1114/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2552 - accuracy: 0.8855 - val_loss: 0.2290 - val_accuracy: 0.9123\n",
      "Epoch 1115/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2556 - accuracy: 0.8925 - val_loss: 0.2313 - val_accuracy: 0.9123\n",
      "Epoch 1116/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2543 - accuracy: 0.8883 - val_loss: 0.2280 - val_accuracy: 0.9123\n",
      "Epoch 1117/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2544 - accuracy: 0.8855 - val_loss: 0.2297 - val_accuracy: 0.9123\n",
      "Epoch 1118/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2541 - accuracy: 0.8841 - val_loss: 0.2300 - val_accuracy: 0.9058\n",
      "Epoch 1119/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.8869 - val_loss: 0.2295 - val_accuracy: 0.9156\n",
      "Epoch 1120/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.8883 - val_loss: 0.2302 - val_accuracy: 0.9156\n",
      "Epoch 1121/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2546 - accuracy: 0.8855 - val_loss: 0.2283 - val_accuracy: 0.9123\n",
      "Epoch 1122/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2536 - accuracy: 0.8813 - val_loss: 0.2299 - val_accuracy: 0.9058\n",
      "Epoch 1123/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2541 - accuracy: 0.8925 - val_loss: 0.2295 - val_accuracy: 0.9123\n",
      "Epoch 1124/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2551 - accuracy: 0.8841 - val_loss: 0.2288 - val_accuracy: 0.9123\n",
      "Epoch 1125/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2548 - accuracy: 0.8966 - val_loss: 0.2309 - val_accuracy: 0.9156\n",
      "Epoch 1126/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.8897 - val_loss: 0.2279 - val_accuracy: 0.9123\n",
      "Epoch 1127/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.8855 - val_loss: 0.2293 - val_accuracy: 0.9123\n",
      "Epoch 1128/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 0.8966 - val_loss: 0.2315 - val_accuracy: 0.9156\n",
      "Epoch 1129/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.8855 - val_loss: 0.2272 - val_accuracy: 0.9123\n",
      "Epoch 1130/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2541 - accuracy: 0.8897 - val_loss: 0.2297 - val_accuracy: 0.9188\n",
      "Epoch 1131/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.8980 - val_loss: 0.2292 - val_accuracy: 0.9188\n",
      "Epoch 1132/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2530 - accuracy: 0.8897 - val_loss: 0.2286 - val_accuracy: 0.9123\n",
      "Epoch 1133/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2542 - accuracy: 0.8953 - val_loss: 0.2286 - val_accuracy: 0.9156\n",
      "Epoch 1134/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2527 - accuracy: 0.8869 - val_loss: 0.2278 - val_accuracy: 0.9123\n",
      "Epoch 1135/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2530 - accuracy: 0.8855 - val_loss: 0.2280 - val_accuracy: 0.9123\n",
      "Epoch 1136/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2529 - accuracy: 0.8897 - val_loss: 0.2275 - val_accuracy: 0.9123\n",
      "Epoch 1137/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2530 - accuracy: 0.8883 - val_loss: 0.2296 - val_accuracy: 0.9156\n",
      "Epoch 1138/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2525 - accuracy: 0.8980 - val_loss: 0.2279 - val_accuracy: 0.9156\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.8869 - val_loss: 0.2277 - val_accuracy: 0.9156\n",
      "Epoch 1140/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2527 - accuracy: 0.8855 - val_loss: 0.2287 - val_accuracy: 0.9091\n",
      "Epoch 1141/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2528 - accuracy: 0.8883 - val_loss: 0.2274 - val_accuracy: 0.9156\n",
      "Epoch 1142/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2523 - accuracy: 0.8883 - val_loss: 0.2280 - val_accuracy: 0.9156\n",
      "Epoch 1143/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2520 - accuracy: 0.8841 - val_loss: 0.2281 - val_accuracy: 0.9091\n",
      "Epoch 1144/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2522 - accuracy: 0.8855 - val_loss: 0.2270 - val_accuracy: 0.9156\n",
      "Epoch 1145/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2529 - accuracy: 0.8855 - val_loss: 0.2277 - val_accuracy: 0.9156\n",
      "Epoch 1146/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2523 - accuracy: 0.8953 - val_loss: 0.2297 - val_accuracy: 0.9156\n",
      "Epoch 1147/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2529 - accuracy: 0.8883 - val_loss: 0.2269 - val_accuracy: 0.9123\n",
      "Epoch 1148/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2513 - accuracy: 0.8939 - val_loss: 0.2307 - val_accuracy: 0.9188\n",
      "Epoch 1149/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2514 - accuracy: 0.8939 - val_loss: 0.2275 - val_accuracy: 0.9156\n",
      "Epoch 1150/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.8855 - val_loss: 0.2263 - val_accuracy: 0.9123\n",
      "Epoch 1151/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2518 - accuracy: 0.8925 - val_loss: 0.2281 - val_accuracy: 0.9188\n",
      "Epoch 1152/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2520 - accuracy: 0.8994 - val_loss: 0.2276 - val_accuracy: 0.9188\n",
      "Epoch 1153/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.8855 - val_loss: 0.2261 - val_accuracy: 0.9123\n",
      "Epoch 1154/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2527 - accuracy: 0.8855 - val_loss: 0.2284 - val_accuracy: 0.9058\n",
      "Epoch 1155/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2511 - accuracy: 0.8869 - val_loss: 0.2264 - val_accuracy: 0.9123\n",
      "Epoch 1156/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.8855 - val_loss: 0.2272 - val_accuracy: 0.9156\n",
      "Epoch 1157/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.8939 - val_loss: 0.2284 - val_accuracy: 0.9091\n",
      "Epoch 1158/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2519 - accuracy: 0.8897 - val_loss: 0.2269 - val_accuracy: 0.9156\n",
      "Epoch 1159/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2523 - accuracy: 0.8925 - val_loss: 0.2270 - val_accuracy: 0.9156\n",
      "Epoch 1160/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.8953 - val_loss: 0.2266 - val_accuracy: 0.9156\n",
      "Epoch 1161/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2515 - accuracy: 0.8869 - val_loss: 0.2275 - val_accuracy: 0.9091\n",
      "Epoch 1162/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.8925 - val_loss: 0.2276 - val_accuracy: 0.9091\n",
      "Epoch 1163/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.8897 - val_loss: 0.2255 - val_accuracy: 0.9156\n",
      "Epoch 1164/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.8869 - val_loss: 0.2269 - val_accuracy: 0.9156\n",
      "Epoch 1165/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.8980 - val_loss: 0.2287 - val_accuracy: 0.9156\n",
      "Epoch 1166/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.9008 - val_loss: 0.2260 - val_accuracy: 0.9156\n",
      "Epoch 1167/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.8869 - val_loss: 0.2256 - val_accuracy: 0.9156\n",
      "Epoch 1168/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.8953 - val_loss: 0.2272 - val_accuracy: 0.9188\n",
      "Epoch 1169/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.8980 - val_loss: 0.2266 - val_accuracy: 0.9156\n",
      "Epoch 1170/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.9022 - val_loss: 0.2273 - val_accuracy: 0.9253\n",
      "Epoch 1171/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.8897 - val_loss: 0.2267 - val_accuracy: 0.9156\n",
      "Epoch 1172/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.8897 - val_loss: 0.2285 - val_accuracy: 0.9188\n",
      "Epoch 1173/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.9008 - val_loss: 0.2263 - val_accuracy: 0.9156\n",
      "Epoch 1174/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.8855 - val_loss: 0.2268 - val_accuracy: 0.9156\n",
      "Epoch 1175/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.9050 - val_loss: 0.2272 - val_accuracy: 0.9188\n",
      "Epoch 1176/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.8994 - val_loss: 0.2257 - val_accuracy: 0.9156\n",
      "Epoch 1177/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.8869 - val_loss: 0.2265 - val_accuracy: 0.9156\n",
      "Epoch 1178/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.9022 - val_loss: 0.2267 - val_accuracy: 0.9156\n",
      "Epoch 1179/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.8897 - val_loss: 0.2265 - val_accuracy: 0.9156\n",
      "Epoch 1180/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.9008 - val_loss: 0.2263 - val_accuracy: 0.9156\n",
      "Epoch 1181/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.9050 - val_loss: 0.2274 - val_accuracy: 0.9253\n",
      "Epoch 1182/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.9022 - val_loss: 0.2257 - val_accuracy: 0.9156\n",
      "Epoch 1183/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.8994 - val_loss: 0.2260 - val_accuracy: 0.9156\n",
      "Epoch 1184/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.8827 - val_loss: 0.2251 - val_accuracy: 0.9123\n",
      "Epoch 1185/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.8911 - val_loss: 0.2286 - val_accuracy: 0.9156\n",
      "Epoch 1186/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.8966 - val_loss: 0.2250 - val_accuracy: 0.9156\n",
      "Epoch 1187/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.8939 - val_loss: 0.2270 - val_accuracy: 0.9156\n",
      "Epoch 1188/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.8911 - val_loss: 0.2252 - val_accuracy: 0.9156\n",
      "Epoch 1189/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.8911 - val_loss: 0.2262 - val_accuracy: 0.9091\n",
      "Epoch 1190/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.8966 - val_loss: 0.2254 - val_accuracy: 0.9156\n",
      "Epoch 1191/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.8911 - val_loss: 0.2256 - val_accuracy: 0.9156\n",
      "Epoch 1192/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.9036 - val_loss: 0.2270 - val_accuracy: 0.9188\n",
      "Epoch 1193/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.8911 - val_loss: 0.2248 - val_accuracy: 0.9156\n",
      "Epoch 1194/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.8911 - val_loss: 0.2258 - val_accuracy: 0.9156\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.8994 - val_loss: 0.2260 - val_accuracy: 0.9156\n",
      "Epoch 1196/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.9008 - val_loss: 0.2264 - val_accuracy: 0.9156\n",
      "Epoch 1197/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.8925 - val_loss: 0.2245 - val_accuracy: 0.9156\n",
      "Epoch 1198/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.8897 - val_loss: 0.2247 - val_accuracy: 0.9156\n",
      "Epoch 1199/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.8869 - val_loss: 0.2243 - val_accuracy: 0.9123\n",
      "Epoch 1200/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.8953 - val_loss: 0.2260 - val_accuracy: 0.9156\n",
      "Epoch 1201/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.8883 - val_loss: 0.2252 - val_accuracy: 0.9156\n",
      "Epoch 1202/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.8953 - val_loss: 0.2258 - val_accuracy: 0.9156\n",
      "Epoch 1203/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.9022 - val_loss: 0.2261 - val_accuracy: 0.9156\n",
      "Epoch 1204/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.8897 - val_loss: 0.2242 - val_accuracy: 0.9156\n",
      "Epoch 1205/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.8953 - val_loss: 0.2256 - val_accuracy: 0.9156\n",
      "Epoch 1206/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.9008 - val_loss: 0.2251 - val_accuracy: 0.9156\n",
      "Epoch 1207/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.8911 - val_loss: 0.2251 - val_accuracy: 0.9156\n",
      "Epoch 1208/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.8980 - val_loss: 0.2253 - val_accuracy: 0.9156\n",
      "Epoch 1209/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.8966 - val_loss: 0.2240 - val_accuracy: 0.9156\n",
      "Epoch 1210/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.8994 - val_loss: 0.2252 - val_accuracy: 0.9156\n",
      "Epoch 1211/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.8869 - val_loss: 0.2243 - val_accuracy: 0.9156\n",
      "Epoch 1212/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.8966 - val_loss: 0.2269 - val_accuracy: 0.9253\n",
      "Epoch 1213/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.9050 - val_loss: 0.2238 - val_accuracy: 0.9156\n",
      "Epoch 1214/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.8869 - val_loss: 0.2242 - val_accuracy: 0.9156\n",
      "Epoch 1215/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.8939 - val_loss: 0.2248 - val_accuracy: 0.9156\n",
      "Epoch 1216/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.9064 - val_loss: 0.2252 - val_accuracy: 0.9253\n",
      "Epoch 1217/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.8953 - val_loss: 0.2241 - val_accuracy: 0.9156\n",
      "Epoch 1218/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.8953 - val_loss: 0.2241 - val_accuracy: 0.9156\n",
      "Epoch 1219/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.8953 - val_loss: 0.2245 - val_accuracy: 0.9156\n",
      "Epoch 1220/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.9022 - val_loss: 0.2252 - val_accuracy: 0.9156\n",
      "Epoch 1221/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.9008 - val_loss: 0.2245 - val_accuracy: 0.9156\n",
      "Epoch 1222/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.8966 - val_loss: 0.2240 - val_accuracy: 0.9156\n",
      "Epoch 1223/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.8939 - val_loss: 0.2250 - val_accuracy: 0.9188\n",
      "Epoch 1224/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.9050 - val_loss: 0.2244 - val_accuracy: 0.9156\n",
      "Epoch 1225/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.8939 - val_loss: 0.2233 - val_accuracy: 0.9156\n",
      "Epoch 1226/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.9022 - val_loss: 0.2237 - val_accuracy: 0.9156\n",
      "Epoch 1227/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.9008 - val_loss: 0.2231 - val_accuracy: 0.9156\n",
      "Epoch 1228/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.8939 - val_loss: 0.2237 - val_accuracy: 0.9156\n",
      "Epoch 1229/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.9036 - val_loss: 0.2243 - val_accuracy: 0.9188\n",
      "Epoch 1230/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.9008 - val_loss: 0.2230 - val_accuracy: 0.9156\n",
      "Epoch 1231/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.8994 - val_loss: 0.2235 - val_accuracy: 0.9156\n",
      "Epoch 1232/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.9008 - val_loss: 0.2229 - val_accuracy: 0.9156\n",
      "Epoch 1233/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.8925 - val_loss: 0.2229 - val_accuracy: 0.9156\n",
      "Epoch 1234/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.9008 - val_loss: 0.2236 - val_accuracy: 0.9156\n",
      "Epoch 1235/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.8939 - val_loss: 0.2239 - val_accuracy: 0.9156\n",
      "Epoch 1236/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.8925 - val_loss: 0.2241 - val_accuracy: 0.9156\n",
      "Epoch 1237/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.9036 - val_loss: 0.2246 - val_accuracy: 0.9221\n",
      "Epoch 1238/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.8925 - val_loss: 0.2215 - val_accuracy: 0.9156\n",
      "Epoch 1239/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.8925 - val_loss: 0.2238 - val_accuracy: 0.9156\n",
      "Epoch 1240/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2439 - accuracy: 0.9064 - val_loss: 0.2251 - val_accuracy: 0.9221\n",
      "Epoch 1241/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.9036 - val_loss: 0.2219 - val_accuracy: 0.9156\n",
      "Epoch 1242/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.8939 - val_loss: 0.2246 - val_accuracy: 0.9221\n",
      "Epoch 1243/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.9050 - val_loss: 0.2227 - val_accuracy: 0.9156\n",
      "Epoch 1244/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.9008 - val_loss: 0.2227 - val_accuracy: 0.9156\n",
      "Epoch 1245/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.8883 - val_loss: 0.2226 - val_accuracy: 0.9156\n",
      "Epoch 1246/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.9064 - val_loss: 0.2237 - val_accuracy: 0.9156\n",
      "Epoch 1247/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.9064 - val_loss: 0.2237 - val_accuracy: 0.9188\n",
      "Epoch 1248/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.9022 - val_loss: 0.2222 - val_accuracy: 0.9156\n",
      "Epoch 1249/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.8911 - val_loss: 0.2227 - val_accuracy: 0.9156\n",
      "Epoch 1250/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9008 - val_loss: 0.2228 - val_accuracy: 0.9156\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.9036 - val_loss: 0.2226 - val_accuracy: 0.9156\n",
      "Epoch 1252/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.8980 - val_loss: 0.2221 - val_accuracy: 0.9156\n",
      "Epoch 1253/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.8911 - val_loss: 0.2223 - val_accuracy: 0.9156\n",
      "Epoch 1254/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.9064 - val_loss: 0.2243 - val_accuracy: 0.9188\n",
      "Epoch 1255/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.9050 - val_loss: 0.2220 - val_accuracy: 0.9156\n",
      "Epoch 1256/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.9036 - val_loss: 0.2226 - val_accuracy: 0.9188\n",
      "Epoch 1257/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2433 - accuracy: 0.8925 - val_loss: 0.2221 - val_accuracy: 0.9156\n",
      "Epoch 1258/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.9008 - val_loss: 0.2228 - val_accuracy: 0.9188\n",
      "Epoch 1259/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.8953 - val_loss: 0.2222 - val_accuracy: 0.9156\n",
      "Epoch 1260/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.9050 - val_loss: 0.2227 - val_accuracy: 0.9221\n",
      "Epoch 1261/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.8980 - val_loss: 0.2221 - val_accuracy: 0.9156\n",
      "Epoch 1262/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.9050 - val_loss: 0.2229 - val_accuracy: 0.9221\n",
      "Epoch 1263/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.8966 - val_loss: 0.2204 - val_accuracy: 0.9156\n",
      "Epoch 1264/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.8966 - val_loss: 0.2212 - val_accuracy: 0.9156\n",
      "Epoch 1265/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.8939 - val_loss: 0.2214 - val_accuracy: 0.9156\n",
      "Epoch 1266/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.9036 - val_loss: 0.2222 - val_accuracy: 0.9188\n",
      "Epoch 1267/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.8925 - val_loss: 0.2203 - val_accuracy: 0.9156\n",
      "Epoch 1268/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2411 - accuracy: 0.8925 - val_loss: 0.2224 - val_accuracy: 0.9188\n",
      "Epoch 1269/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9022 - val_loss: 0.2208 - val_accuracy: 0.9156\n",
      "Epoch 1270/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.8925 - val_loss: 0.2213 - val_accuracy: 0.9188\n",
      "Epoch 1271/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.8897 - val_loss: 0.2206 - val_accuracy: 0.9156\n",
      "Epoch 1272/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.9064 - val_loss: 0.2220 - val_accuracy: 0.9188\n",
      "Epoch 1273/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.9008 - val_loss: 0.2209 - val_accuracy: 0.9188\n",
      "Epoch 1274/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.8925 - val_loss: 0.2206 - val_accuracy: 0.9188\n",
      "Epoch 1275/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2407 - accuracy: 0.9036 - val_loss: 0.2217 - val_accuracy: 0.9188\n",
      "Epoch 1276/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.9078 - val_loss: 0.2205 - val_accuracy: 0.9188\n",
      "Epoch 1277/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2403 - accuracy: 0.9008 - val_loss: 0.2210 - val_accuracy: 0.9188\n",
      "Epoch 1278/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.8911 - val_loss: 0.2203 - val_accuracy: 0.9156\n",
      "Epoch 1279/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9036 - val_loss: 0.2224 - val_accuracy: 0.9221\n",
      "Epoch 1280/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.9050 - val_loss: 0.2214 - val_accuracy: 0.9188\n",
      "Epoch 1281/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.8994 - val_loss: 0.2195 - val_accuracy: 0.9156\n",
      "Epoch 1282/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2400 - accuracy: 0.9036 - val_loss: 0.2217 - val_accuracy: 0.9188\n",
      "Epoch 1283/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2404 - accuracy: 0.9008 - val_loss: 0.2209 - val_accuracy: 0.9188\n",
      "Epoch 1284/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2403 - accuracy: 0.8939 - val_loss: 0.2204 - val_accuracy: 0.9188\n",
      "Epoch 1285/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2399 - accuracy: 0.9036 - val_loss: 0.2200 - val_accuracy: 0.9156\n",
      "Epoch 1286/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.9036 - val_loss: 0.2206 - val_accuracy: 0.9188\n",
      "Epoch 1287/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9050 - val_loss: 0.2200 - val_accuracy: 0.9188\n",
      "Epoch 1288/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.8994 - val_loss: 0.2196 - val_accuracy: 0.9188\n",
      "Epoch 1289/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2393 - accuracy: 0.9036 - val_loss: 0.2216 - val_accuracy: 0.9188\n",
      "Epoch 1290/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9092 - val_loss: 0.2201 - val_accuracy: 0.9188\n",
      "Epoch 1291/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2390 - accuracy: 0.9036 - val_loss: 0.2198 - val_accuracy: 0.9188\n",
      "Epoch 1292/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.9022 - val_loss: 0.2204 - val_accuracy: 0.9188\n",
      "Epoch 1293/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2393 - accuracy: 0.8994 - val_loss: 0.2194 - val_accuracy: 0.9188\n",
      "Epoch 1294/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.9036 - val_loss: 0.2204 - val_accuracy: 0.9188\n",
      "Epoch 1295/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2393 - accuracy: 0.9050 - val_loss: 0.2208 - val_accuracy: 0.9188\n",
      "Epoch 1296/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.9022 - val_loss: 0.2184 - val_accuracy: 0.9156\n",
      "Epoch 1297/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.9008 - val_loss: 0.2196 - val_accuracy: 0.9188\n",
      "Epoch 1298/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.9022 - val_loss: 0.2201 - val_accuracy: 0.9188\n",
      "Epoch 1299/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.9022 - val_loss: 0.2199 - val_accuracy: 0.9188\n",
      "Epoch 1300/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2392 - accuracy: 0.8994 - val_loss: 0.2199 - val_accuracy: 0.9188\n",
      "Epoch 1301/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.8994 - val_loss: 0.2190 - val_accuracy: 0.9156\n",
      "Epoch 1302/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.8994 - val_loss: 0.2201 - val_accuracy: 0.9188\n",
      "Epoch 1303/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.9064 - val_loss: 0.2198 - val_accuracy: 0.9188\n",
      "Epoch 1304/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2383 - accuracy: 0.8980 - val_loss: 0.2191 - val_accuracy: 0.9188\n",
      "Epoch 1305/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 0.9064 - val_loss: 0.2187 - val_accuracy: 0.9188\n",
      "Epoch 1306/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2377 - accuracy: 0.9022 - val_loss: 0.2192 - val_accuracy: 0.9188\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.9036 - val_loss: 0.2193 - val_accuracy: 0.9188\n",
      "Epoch 1308/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9036 - val_loss: 0.2193 - val_accuracy: 0.9188\n",
      "Epoch 1309/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.9050 - val_loss: 0.2183 - val_accuracy: 0.9188\n",
      "Epoch 1310/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9022 - val_loss: 0.2193 - val_accuracy: 0.9188\n",
      "Epoch 1311/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2372 - accuracy: 0.9050 - val_loss: 0.2185 - val_accuracy: 0.9188\n",
      "Epoch 1312/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2375 - accuracy: 0.9036 - val_loss: 0.2182 - val_accuracy: 0.9188\n",
      "Epoch 1313/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.9036 - val_loss: 0.2185 - val_accuracy: 0.9188\n",
      "Epoch 1314/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.9036 - val_loss: 0.2187 - val_accuracy: 0.9188\n",
      "Epoch 1315/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2369 - accuracy: 0.9036 - val_loss: 0.2186 - val_accuracy: 0.9188\n",
      "Epoch 1316/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.9022 - val_loss: 0.2194 - val_accuracy: 0.9253\n",
      "Epoch 1317/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.9092 - val_loss: 0.2183 - val_accuracy: 0.9188\n",
      "Epoch 1318/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.9036 - val_loss: 0.2175 - val_accuracy: 0.9188\n",
      "Epoch 1319/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2371 - accuracy: 0.9036 - val_loss: 0.2182 - val_accuracy: 0.9188\n",
      "Epoch 1320/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2365 - accuracy: 0.9036 - val_loss: 0.2185 - val_accuracy: 0.9188\n",
      "Epoch 1321/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2372 - accuracy: 0.9036 - val_loss: 0.2184 - val_accuracy: 0.9188\n",
      "Epoch 1322/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2364 - accuracy: 0.9036 - val_loss: 0.2179 - val_accuracy: 0.9188\n",
      "Epoch 1323/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2365 - accuracy: 0.9022 - val_loss: 0.2185 - val_accuracy: 0.9188\n",
      "Epoch 1324/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.8966 - val_loss: 0.2179 - val_accuracy: 0.9188\n",
      "Epoch 1325/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2364 - accuracy: 0.9008 - val_loss: 0.2182 - val_accuracy: 0.9188\n",
      "Epoch 1326/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9036 - val_loss: 0.2195 - val_accuracy: 0.9253\n",
      "Epoch 1327/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9008 - val_loss: 0.2177 - val_accuracy: 0.9188\n",
      "Epoch 1328/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9022 - val_loss: 0.2183 - val_accuracy: 0.9188\n",
      "Epoch 1329/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9022 - val_loss: 0.2177 - val_accuracy: 0.9188\n",
      "Epoch 1330/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.8994 - val_loss: 0.2177 - val_accuracy: 0.9188\n",
      "Epoch 1331/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2355 - accuracy: 0.9022 - val_loss: 0.2188 - val_accuracy: 0.9221\n",
      "Epoch 1332/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.9022 - val_loss: 0.2178 - val_accuracy: 0.9188\n",
      "Epoch 1333/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9036 - val_loss: 0.2183 - val_accuracy: 0.9188\n",
      "Epoch 1334/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.9036 - val_loss: 0.2167 - val_accuracy: 0.9188\n",
      "Epoch 1335/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2349 - accuracy: 0.9050 - val_loss: 0.2194 - val_accuracy: 0.9253\n",
      "Epoch 1336/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9050 - val_loss: 0.2169 - val_accuracy: 0.9188\n",
      "Epoch 1337/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2347 - accuracy: 0.9036 - val_loss: 0.2173 - val_accuracy: 0.9188\n",
      "Epoch 1338/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.9036 - val_loss: 0.2175 - val_accuracy: 0.9188\n",
      "Epoch 1339/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2347 - accuracy: 0.9036 - val_loss: 0.2168 - val_accuracy: 0.9188\n",
      "Epoch 1340/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2346 - accuracy: 0.9036 - val_loss: 0.2175 - val_accuracy: 0.9188\n",
      "Epoch 1341/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.9022 - val_loss: 0.2165 - val_accuracy: 0.9188\n",
      "Epoch 1342/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2341 - accuracy: 0.9036 - val_loss: 0.2178 - val_accuracy: 0.9156\n",
      "Epoch 1343/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.9036 - val_loss: 0.2166 - val_accuracy: 0.9188\n",
      "Epoch 1344/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.9036 - val_loss: 0.2175 - val_accuracy: 0.9188\n",
      "Epoch 1345/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.9008 - val_loss: 0.2167 - val_accuracy: 0.9188\n",
      "Epoch 1346/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.9036 - val_loss: 0.2169 - val_accuracy: 0.9188\n",
      "Epoch 1347/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2341 - accuracy: 0.9036 - val_loss: 0.2169 - val_accuracy: 0.9188\n",
      "Epoch 1348/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2335 - accuracy: 0.9064 - val_loss: 0.2189 - val_accuracy: 0.9221\n",
      "Epoch 1349/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2336 - accuracy: 0.9050 - val_loss: 0.2174 - val_accuracy: 0.9253\n",
      "Epoch 1350/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.9022 - val_loss: 0.2163 - val_accuracy: 0.9188\n",
      "Epoch 1351/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2346 - accuracy: 0.8925 - val_loss: 0.2161 - val_accuracy: 0.9188\n",
      "Epoch 1352/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2334 - accuracy: 0.9022 - val_loss: 0.2173 - val_accuracy: 0.9253\n",
      "Epoch 1353/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.9064 - val_loss: 0.2169 - val_accuracy: 0.9188\n",
      "Epoch 1354/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.8980 - val_loss: 0.2189 - val_accuracy: 0.9253\n",
      "Epoch 1355/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2355 - accuracy: 0.8897 - val_loss: 0.2152 - val_accuracy: 0.9188\n",
      "Epoch 1356/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2339 - accuracy: 0.9064 - val_loss: 0.2194 - val_accuracy: 0.9221\n",
      "Epoch 1357/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.8939 - val_loss: 0.2151 - val_accuracy: 0.9188\n",
      "Epoch 1358/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.9036 - val_loss: 0.2181 - val_accuracy: 0.9221\n",
      "Epoch 1359/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9022 - val_loss: 0.2151 - val_accuracy: 0.9188\n",
      "Epoch 1360/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9036 - val_loss: 0.2154 - val_accuracy: 0.9188\n",
      "Epoch 1361/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.9036 - val_loss: 0.2168 - val_accuracy: 0.9221\n",
      "Epoch 1362/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.9008 - val_loss: 0.2181 - val_accuracy: 0.9253\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.9036 - val_loss: 0.2153 - val_accuracy: 0.9188\n",
      "Epoch 1364/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.9008 - val_loss: 0.2166 - val_accuracy: 0.9221\n",
      "Epoch 1365/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9022 - val_loss: 0.2153 - val_accuracy: 0.9188\n",
      "Epoch 1366/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9036 - val_loss: 0.2158 - val_accuracy: 0.9253\n",
      "Epoch 1367/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9064 - val_loss: 0.2152 - val_accuracy: 0.9188\n",
      "Epoch 1368/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2328 - accuracy: 0.9050 - val_loss: 0.2156 - val_accuracy: 0.9188\n",
      "Epoch 1369/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2317 - accuracy: 0.9036 - val_loss: 0.2160 - val_accuracy: 0.9221\n",
      "Epoch 1370/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.9036 - val_loss: 0.2163 - val_accuracy: 0.9156\n",
      "Epoch 1371/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9022 - val_loss: 0.2172 - val_accuracy: 0.9253\n",
      "Epoch 1372/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9008 - val_loss: 0.2166 - val_accuracy: 0.9253\n",
      "Epoch 1373/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2335 - accuracy: 0.9078 - val_loss: 0.2150 - val_accuracy: 0.9188\n",
      "Epoch 1374/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9036 - val_loss: 0.2140 - val_accuracy: 0.9188\n",
      "Epoch 1375/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.8939 - val_loss: 0.2146 - val_accuracy: 0.9188\n",
      "Epoch 1376/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9036 - val_loss: 0.2159 - val_accuracy: 0.9221\n",
      "Epoch 1377/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.9050 - val_loss: 0.2173 - val_accuracy: 0.9253\n",
      "Epoch 1378/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9064 - val_loss: 0.2155 - val_accuracy: 0.9188\n",
      "Epoch 1379/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.8911 - val_loss: 0.2142 - val_accuracy: 0.9188\n",
      "Epoch 1380/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9008 - val_loss: 0.2184 - val_accuracy: 0.9156\n",
      "Epoch 1381/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9036 - val_loss: 0.2139 - val_accuracy: 0.9188\n",
      "Epoch 1382/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.9050 - val_loss: 0.2150 - val_accuracy: 0.9221\n",
      "Epoch 1383/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9078 - val_loss: 0.2149 - val_accuracy: 0.9253\n",
      "Epoch 1384/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.9050 - val_loss: 0.2136 - val_accuracy: 0.9188\n",
      "Epoch 1385/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.8953 - val_loss: 0.2153 - val_accuracy: 0.9253\n",
      "Epoch 1386/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9078 - val_loss: 0.2147 - val_accuracy: 0.9253\n",
      "Epoch 1387/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.9092 - val_loss: 0.2162 - val_accuracy: 0.9253\n",
      "Epoch 1388/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.9050 - val_loss: 0.2139 - val_accuracy: 0.9253\n",
      "Epoch 1389/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.9036 - val_loss: 0.2138 - val_accuracy: 0.9188\n",
      "Epoch 1390/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.9050 - val_loss: 0.2144 - val_accuracy: 0.9253\n",
      "Epoch 1391/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.9064 - val_loss: 0.2135 - val_accuracy: 0.9253\n",
      "Epoch 1392/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 0.9064 - val_loss: 0.2143 - val_accuracy: 0.9253\n",
      "Epoch 1393/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.9078 - val_loss: 0.2135 - val_accuracy: 0.9253\n",
      "Epoch 1394/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9064 - val_loss: 0.2145 - val_accuracy: 0.9221\n",
      "Epoch 1395/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.9050 - val_loss: 0.2131 - val_accuracy: 0.9188\n",
      "Epoch 1396/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9036 - val_loss: 0.2139 - val_accuracy: 0.9253\n",
      "Epoch 1397/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2294 - accuracy: 0.9036 - val_loss: 0.2132 - val_accuracy: 0.9188\n",
      "Epoch 1398/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 0.9036 - val_loss: 0.2151 - val_accuracy: 0.9253\n",
      "Epoch 1399/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9050 - val_loss: 0.2148 - val_accuracy: 0.9253\n",
      "Epoch 1400/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9022 - val_loss: 0.2118 - val_accuracy: 0.9188\n",
      "Epoch 1401/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9050 - val_loss: 0.2147 - val_accuracy: 0.9253\n",
      "Epoch 1402/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9064 - val_loss: 0.2142 - val_accuracy: 0.9221\n",
      "Epoch 1403/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9120 - val_loss: 0.2142 - val_accuracy: 0.9221\n",
      "Epoch 1404/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2288 - accuracy: 0.9078 - val_loss: 0.2146 - val_accuracy: 0.9253\n",
      "Epoch 1405/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.9036 - val_loss: 0.2132 - val_accuracy: 0.9221\n",
      "Epoch 1406/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2283 - accuracy: 0.9064 - val_loss: 0.2132 - val_accuracy: 0.9221\n",
      "Epoch 1407/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.9050 - val_loss: 0.2134 - val_accuracy: 0.9221\n",
      "Epoch 1408/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.9022 - val_loss: 0.2137 - val_accuracy: 0.9221\n",
      "Epoch 1409/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.9050 - val_loss: 0.2122 - val_accuracy: 0.9188\n",
      "Epoch 1410/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9050 - val_loss: 0.2133 - val_accuracy: 0.9221\n",
      "Epoch 1411/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9064 - val_loss: 0.2116 - val_accuracy: 0.9188\n",
      "Epoch 1412/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9064 - val_loss: 0.2120 - val_accuracy: 0.9188\n",
      "Epoch 1413/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.9050 - val_loss: 0.2144 - val_accuracy: 0.9253\n",
      "Epoch 1414/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.8994 - val_loss: 0.2115 - val_accuracy: 0.9188\n",
      "Epoch 1415/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9078 - val_loss: 0.2141 - val_accuracy: 0.9253\n",
      "Epoch 1416/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9078 - val_loss: 0.2122 - val_accuracy: 0.9221\n",
      "Epoch 1417/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2275 - accuracy: 0.9092 - val_loss: 0.2133 - val_accuracy: 0.9253\n",
      "Epoch 1418/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9036 - val_loss: 0.2107 - val_accuracy: 0.9188\n",
      "Epoch 1419/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2263 - accuracy: 0.9092 - val_loss: 0.2136 - val_accuracy: 0.9253\n",
      "Epoch 1420/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9092 - val_loss: 0.2120 - val_accuracy: 0.9221\n",
      "Epoch 1421/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9008 - val_loss: 0.2120 - val_accuracy: 0.9156\n",
      "Epoch 1422/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 0.9050 - val_loss: 0.2119 - val_accuracy: 0.9221\n",
      "Epoch 1423/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.9120 - val_loss: 0.2124 - val_accuracy: 0.9253\n",
      "Epoch 1424/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9120 - val_loss: 0.2137 - val_accuracy: 0.9253\n",
      "Epoch 1425/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9106 - val_loss: 0.2115 - val_accuracy: 0.9221\n",
      "Epoch 1426/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.9064 - val_loss: 0.2114 - val_accuracy: 0.9221\n",
      "Epoch 1427/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.9064 - val_loss: 0.2122 - val_accuracy: 0.9253\n",
      "Epoch 1428/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2275 - accuracy: 0.9078 - val_loss: 0.2127 - val_accuracy: 0.9221\n",
      "Epoch 1429/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9064 - val_loss: 0.2125 - val_accuracy: 0.9253\n",
      "Epoch 1430/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.9064 - val_loss: 0.2097 - val_accuracy: 0.9188\n",
      "Epoch 1431/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.9092 - val_loss: 0.2126 - val_accuracy: 0.9253\n",
      "Epoch 1432/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.9050 - val_loss: 0.2112 - val_accuracy: 0.9221\n",
      "Epoch 1433/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9064 - val_loss: 0.2112 - val_accuracy: 0.9221\n",
      "Epoch 1434/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9092 - val_loss: 0.2099 - val_accuracy: 0.9188\n",
      "Epoch 1435/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9106 - val_loss: 0.2126 - val_accuracy: 0.9253\n",
      "Epoch 1436/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.9092 - val_loss: 0.2106 - val_accuracy: 0.9221\n",
      "Epoch 1437/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9078 - val_loss: 0.2105 - val_accuracy: 0.9221\n",
      "Epoch 1438/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.9092 - val_loss: 0.2105 - val_accuracy: 0.9221\n",
      "Epoch 1439/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.9036 - val_loss: 0.2103 - val_accuracy: 0.9221\n",
      "Epoch 1440/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9106 - val_loss: 0.2126 - val_accuracy: 0.9253\n",
      "Epoch 1441/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.8994 - val_loss: 0.2095 - val_accuracy: 0.9188\n",
      "Epoch 1442/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.9064 - val_loss: 0.2112 - val_accuracy: 0.9221\n",
      "Epoch 1443/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9050 - val_loss: 0.2097 - val_accuracy: 0.9253\n",
      "Epoch 1444/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9092 - val_loss: 0.2113 - val_accuracy: 0.9221\n",
      "Epoch 1445/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9092 - val_loss: 0.2103 - val_accuracy: 0.9221\n",
      "Epoch 1446/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9120 - val_loss: 0.2104 - val_accuracy: 0.9221\n",
      "Epoch 1447/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9092 - val_loss: 0.2122 - val_accuracy: 0.9188\n",
      "Epoch 1448/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9092 - val_loss: 0.2098 - val_accuracy: 0.9253\n",
      "Epoch 1449/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9036 - val_loss: 0.2118 - val_accuracy: 0.9221\n",
      "Epoch 1450/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9120 - val_loss: 0.2097 - val_accuracy: 0.9221\n",
      "Epoch 1451/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9134 - val_loss: 0.2097 - val_accuracy: 0.9221\n",
      "Epoch 1452/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9092 - val_loss: 0.2103 - val_accuracy: 0.9253\n",
      "Epoch 1453/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.9092 - val_loss: 0.2103 - val_accuracy: 0.9221\n",
      "Epoch 1454/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.9148 - val_loss: 0.2091 - val_accuracy: 0.9253\n",
      "Epoch 1455/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9134 - val_loss: 0.2110 - val_accuracy: 0.9253\n",
      "Epoch 1456/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.9106 - val_loss: 0.2094 - val_accuracy: 0.9221\n",
      "Epoch 1457/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9134 - val_loss: 0.2097 - val_accuracy: 0.9221\n",
      "Epoch 1458/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9120 - val_loss: 0.2091 - val_accuracy: 0.9221\n",
      "Epoch 1459/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.9092 - val_loss: 0.2087 - val_accuracy: 0.9221\n",
      "Epoch 1460/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.9106 - val_loss: 0.2091 - val_accuracy: 0.9221\n",
      "Epoch 1461/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9092 - val_loss: 0.2099 - val_accuracy: 0.9221\n",
      "Epoch 1462/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9120 - val_loss: 0.2089 - val_accuracy: 0.9221\n",
      "Epoch 1463/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.9092 - val_loss: 0.2082 - val_accuracy: 0.9253\n",
      "Epoch 1464/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9092 - val_loss: 0.2098 - val_accuracy: 0.9221\n",
      "Epoch 1465/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9106 - val_loss: 0.2090 - val_accuracy: 0.9221\n",
      "Epoch 1466/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9078 - val_loss: 0.2104 - val_accuracy: 0.9253\n",
      "Epoch 1467/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9106 - val_loss: 0.2099 - val_accuracy: 0.9221\n",
      "Epoch 1468/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.9092 - val_loss: 0.2082 - val_accuracy: 0.9188\n",
      "Epoch 1469/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9120 - val_loss: 0.2090 - val_accuracy: 0.9221\n",
      "Epoch 1470/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9092 - val_loss: 0.2084 - val_accuracy: 0.9221\n",
      "Epoch 1471/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9134 - val_loss: 0.2093 - val_accuracy: 0.9221\n",
      "Epoch 1472/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.9078 - val_loss: 0.2081 - val_accuracy: 0.9253\n",
      "Epoch 1473/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.9148 - val_loss: 0.2087 - val_accuracy: 0.9221\n",
      "Epoch 1474/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.9078 - val_loss: 0.2080 - val_accuracy: 0.9221\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2208 - accuracy: 0.9134 - val_loss: 0.2085 - val_accuracy: 0.9221\n",
      "Epoch 1476/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2208 - accuracy: 0.9134 - val_loss: 0.2079 - val_accuracy: 0.9221\n",
      "Epoch 1477/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9120 - val_loss: 0.2095 - val_accuracy: 0.9221\n",
      "Epoch 1478/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9120 - val_loss: 0.2073 - val_accuracy: 0.9253\n",
      "Epoch 1479/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9106 - val_loss: 0.2096 - val_accuracy: 0.9253\n",
      "Epoch 1480/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.9134 - val_loss: 0.2072 - val_accuracy: 0.9253\n",
      "Epoch 1481/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9134 - val_loss: 0.2091 - val_accuracy: 0.9253\n",
      "Epoch 1482/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9148 - val_loss: 0.2080 - val_accuracy: 0.9221\n",
      "Epoch 1483/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9120 - val_loss: 0.2072 - val_accuracy: 0.9221\n",
      "Epoch 1484/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.9134 - val_loss: 0.2089 - val_accuracy: 0.9253\n",
      "Epoch 1485/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9120 - val_loss: 0.2081 - val_accuracy: 0.9221\n",
      "Epoch 1486/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9148 - val_loss: 0.2072 - val_accuracy: 0.9221\n",
      "Epoch 1487/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9134 - val_loss: 0.2092 - val_accuracy: 0.9253\n",
      "Epoch 1488/1500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9134 - val_loss: 0.2069 - val_accuracy: 0.9221\n",
      "Epoch 1489/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9120 - val_loss: 0.2074 - val_accuracy: 0.9221\n",
      "Epoch 1490/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.9120 - val_loss: 0.2068 - val_accuracy: 0.9221\n",
      "Epoch 1491/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.9120 - val_loss: 0.2066 - val_accuracy: 0.9221\n",
      "Epoch 1492/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9134 - val_loss: 0.2083 - val_accuracy: 0.9253\n",
      "Epoch 1493/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.9176 - val_loss: 0.2075 - val_accuracy: 0.9221\n",
      "Epoch 1494/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.9120 - val_loss: 0.2067 - val_accuracy: 0.9221\n",
      "Epoch 1495/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.9134 - val_loss: 0.2068 - val_accuracy: 0.9221\n",
      "Epoch 1496/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9134 - val_loss: 0.2067 - val_accuracy: 0.9221\n",
      "Epoch 1497/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.9120 - val_loss: 0.2074 - val_accuracy: 0.9221\n",
      "Epoch 1498/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9120 - val_loss: 0.2065 - val_accuracy: 0.9221\n",
      "Epoch 1499/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.9120 - val_loss: 0.2065 - val_accuracy: 0.9221\n",
      "Epoch 1500/1500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9120 - val_loss: 0.2071 - val_accuracy: 0.9221\n",
      "23/23 [==============================] - 0s 478us/step - loss: 0.2173 - accuracy: 0.9120\n",
      "Accuracy: 91.20\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       148\n",
      "           1       1.00      0.96      0.98       160\n",
      "\n",
      "    accuracy                           0.98       308\n",
      "   macro avg       0.98      0.98      0.98       308\n",
      "weighted avg       0.98      0.98      0.98       308\n",
      "\n",
      "[[148   0]\n",
      " [  6 154]]\n"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "#Read target column as y\n",
    "y=dataset.target\n",
    "\n",
    "#Take all of column and drop target column as x\n",
    "x=dataset.drop('target',axis=1)\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler() #Normalizing data to value from 0-1\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "# Split data into training and test \n",
    "X_train,X_test,y_train,y_test=train_test_split(x_scaled,y,test_size=0.3,random_state=4)\n",
    "\n",
    "\n",
    "\n",
    "# Define the keras model\n",
    "model = Sequential()\n",
    "\n",
    "#First hidden layer with 10 neuron, 13 input (using sigmoid activation function)\n",
    "model.add(Dense(10, input_shape=(13,), activation='sigmoid'))\n",
    "\n",
    "#Second hidden layer with 10 neuron (using sigmoid activation function)\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "#Output layer with 1 neuron (using sigmoid activation function)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained = model.fit(X_train, y_train, epochs=1500, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "#evaluate the keras model\n",
    "_,accuracy = model.evaluate(X_train, y_train)\n",
    "\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "#Plotting accuracy and loss chart\n",
    "plt.plot(trained.history['accuracy'] )\n",
    "plt.plot(trained.history['val_accuracy'])\n",
    "\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training Accuracy' , 'Test Accuracy'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(trained.history['loss'])\n",
    "plt.plot(trained.history['val_loss'])\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training Loss' , 'Test Loss'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Tak faham coding ni tapi aku rembat lol\n",
    "classifier_tree = DecisionTreeClassifier()\n",
    "y_predict = classifier_tree.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#belummmmmmmmmmmmmmmmm\n",
    "predictions = (model.predict(X_test) > 0.5).astype(int)\n",
    "true=0\n",
    "false=0\n",
    "for i in range(200):\n",
    "    if predictions[i] == y_test[i]:\n",
    "        true = true +1\n",
    "        print('[%d] %s => %d (expected %d) BETUL' % (i,X_test[i].tolist(), predictions[i], y_test[i]))\n",
    "    else:\n",
    "        false = false +1\n",
    "        print('[%d] %s => %d (expected %d) SALAH' % (i,X_test[i].tolist(), predictions[i], y_test[i]))\n",
    "        \n",
    "print(\"Total false prediction : \" , false)\n",
    "print(\"Total true prediction : \" , true)\n",
    "print(\"Accuracy : \" , true/200*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd8a729e9011353bea70d827c4a883ab4de60514c57adf329a667d269e868491"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
